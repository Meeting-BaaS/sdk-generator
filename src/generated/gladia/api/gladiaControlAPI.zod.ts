/**
 * Generated by orval v7.9.0 üç∫
 * Do not edit manually.
 * Gladia Control API
 * OpenAPI spec version: 1.0
 */
import { z as zod } from "zod"

/**
 * @summary Upload an audio file or provide an audio URL for processing
 */
export const fileControllerUploadV2Body = zod.object({
  audio_url: zod.string().optional().describe("The URL of the audio or video file to be uploaded.")
})

export const fileControllerUploadV2Response = zod.object({
  audio_url: zod.string().url().describe("Uploaded audio file Gladia URL"),
  audio_metadata: zod
    .object({
      id: zod.string().uuid().describe("Uploaded audio file ID"),
      filename: zod.string().describe("Uploaded audio filename"),
      source: zod.string().url().optional().describe("Uploaded audio source"),
      extension: zod.string().uuid().describe("Uploaded audio detected extension"),
      size: zod.number().describe("Uploaded audio size"),
      audio_duration: zod.number().describe("Uploaded audio duration"),
      number_of_channels: zod.number().describe("Uploaded audio channel numbers")
    })
    .describe("Uploaded audio file detected metadata")
})

/**
 * @summary Initiate a new pre recorded job
 */
export const preRecordedControllerInitPreRecordedJobV2BodyCustomVocabularyDefault = false
export const preRecordedControllerInitPreRecordedJobV2BodyCustomVocabularyConfigVocabularyItemIntensityMin = 0

export const preRecordedControllerInitPreRecordedJobV2BodyCustomVocabularyConfigVocabularyItemIntensityMax = 1
export const preRecordedControllerInitPreRecordedJobV2BodyCustomVocabularyConfigDefaultIntensityMin = 0

export const preRecordedControllerInitPreRecordedJobV2BodyCustomVocabularyConfigDefaultIntensityMax = 1
export const preRecordedControllerInitPreRecordedJobV2BodyDetectLanguageDefault = true
export const preRecordedControllerInitPreRecordedJobV2BodyEnableCodeSwitchingDefault = false
export const preRecordedControllerInitPreRecordedJobV2BodyCodeSwitchingConfigLanguagesDefault = []
export const preRecordedControllerInitPreRecordedJobV2BodyCallbackDefault = false
export const preRecordedControllerInitPreRecordedJobV2BodyCallbackConfigMethodDefault = "POST"
export const preRecordedControllerInitPreRecordedJobV2BodySubtitlesDefault = false
export const preRecordedControllerInitPreRecordedJobV2BodySubtitlesConfigFormatsDefault: string[] = ["srt"]
export const preRecordedControllerInitPreRecordedJobV2BodySubtitlesConfigMinimumDurationMin = 0
export const preRecordedControllerInitPreRecordedJobV2BodySubtitlesConfigMaximumDurationMax = 30
export const preRecordedControllerInitPreRecordedJobV2BodySubtitlesConfigMaximumRowsPerCaptionMax = 5
export const preRecordedControllerInitPreRecordedJobV2BodySubtitlesConfigStyleDefault = "default"
export const preRecordedControllerInitPreRecordedJobV2BodyDiarizationDefault = false
export const preRecordedControllerInitPreRecordedJobV2BodyDiarizationConfigMinSpeakersMin = 0
export const preRecordedControllerInitPreRecordedJobV2BodyDiarizationConfigMaxSpeakersMin = 0
export const preRecordedControllerInitPreRecordedJobV2BodyTranslationDefault = false
export const preRecordedControllerInitPreRecordedJobV2BodyTranslationConfigModelDefault = "base"
export const preRecordedControllerInitPreRecordedJobV2BodyTranslationConfigMatchOriginalUtterancesDefault = true
export const preRecordedControllerInitPreRecordedJobV2BodyTranslationConfigLipsyncDefault = true
export const preRecordedControllerInitPreRecordedJobV2BodyTranslationConfigContextAdaptationDefault = true
export const preRecordedControllerInitPreRecordedJobV2BodyTranslationConfigInformalDefault = false
export const preRecordedControllerInitPreRecordedJobV2BodySummarizationDefault = false
export const preRecordedControllerInitPreRecordedJobV2BodySummarizationConfigTypeDefault = "general"
export const preRecordedControllerInitPreRecordedJobV2BodyModerationDefault = false
export const preRecordedControllerInitPreRecordedJobV2BodyNamedEntityRecognitionDefault = false
export const preRecordedControllerInitPreRecordedJobV2BodyChapterizationDefault = false
export const preRecordedControllerInitPreRecordedJobV2BodyNameConsistencyDefault = false
export const preRecordedControllerInitPreRecordedJobV2BodyCustomSpellingDefault = false
export const preRecordedControllerInitPreRecordedJobV2BodyStructuredDataExtractionDefault = false
export const preRecordedControllerInitPreRecordedJobV2BodySentimentAnalysisDefault = false
export const preRecordedControllerInitPreRecordedJobV2BodyAudioToLlmDefault = false
export const preRecordedControllerInitPreRecordedJobV2BodySentencesDefault = false
export const preRecordedControllerInitPreRecordedJobV2BodyDisplayModeDefault = false
export const preRecordedControllerInitPreRecordedJobV2BodyPunctuationEnhancedDefault = false
export const preRecordedControllerInitPreRecordedJobV2BodyLanguageConfigLanguagesDefault = []
export const preRecordedControllerInitPreRecordedJobV2BodyLanguageConfigCodeSwitchingDefault = false

export const preRecordedControllerInitPreRecordedJobV2Body = zod.object({
  context_prompt: zod
    .string()
    .optional()
    .describe(
      "**[Deprecated]** Context to feed the transcription model with for possible better accuracy"
    ),
  custom_vocabulary: zod
    .boolean()
    .optional()
    .describe(
      "**[Beta]** Can be either boolean to enable custom_vocabulary for this audio or an array with specific vocabulary list to feed the transcription model with"
    ),
  custom_vocabulary_config: zod
    .object({
      vocabulary: zod
        .array(
          zod
            .object({
              value: zod.string().describe("The text used to replace in the transcription."),
              intensity: zod
                .number()
                .min(
                  preRecordedControllerInitPreRecordedJobV2BodyCustomVocabularyConfigVocabularyItemIntensityMin
                )
                .max(
                  preRecordedControllerInitPreRecordedJobV2BodyCustomVocabularyConfigVocabularyItemIntensityMax
                )
                .optional()
                .describe("The global intensity of the feature."),
              pronunciations: zod
                .array(zod.string())
                .optional()
                .describe("The pronunciations used in the transcription."),
              language: zod
                .enum([
                  "af",
                  "am",
                  "ar",
                  "as",
                  "az",
                  "ba",
                  "be",
                  "bg",
                  "bn",
                  "bo",
                  "br",
                  "bs",
                  "ca",
                  "cs",
                  "cy",
                  "da",
                  "de",
                  "el",
                  "en",
                  "es",
                  "et",
                  "eu",
                  "fa",
                  "fi",
                  "fo",
                  "fr",
                  "gl",
                  "gu",
                  "ha",
                  "haw",
                  "he",
                  "hi",
                  "hr",
                  "ht",
                  "hu",
                  "hy",
                  "id",
                  "is",
                  "it",
                  "ja",
                  "jw",
                  "ka",
                  "kk",
                  "km",
                  "kn",
                  "ko",
                  "la",
                  "lb",
                  "ln",
                  "lo",
                  "lt",
                  "lv",
                  "mg",
                  "mi",
                  "mk",
                  "ml",
                  "mn",
                  "mr",
                  "ms",
                  "mt",
                  "my",
                  "ne",
                  "nl",
                  "nn",
                  "no",
                  "oc",
                  "pa",
                  "pl",
                  "ps",
                  "pt",
                  "ro",
                  "ru",
                  "sa",
                  "sd",
                  "si",
                  "sk",
                  "sl",
                  "sn",
                  "so",
                  "sq",
                  "sr",
                  "su",
                  "sv",
                  "sw",
                  "ta",
                  "te",
                  "tg",
                  "th",
                  "tk",
                  "tl",
                  "tr",
                  "tt",
                  "uk",
                  "ur",
                  "uz",
                  "vi",
                  "yi",
                  "yo",
                  "zh"
                ])
                .describe(
                  "Specify the language in which it will be pronounced when sound comparison occurs. Default to transcription language."
                )
                .optional()
                .describe(
                  "Specify the language in which it will be pronounced when sound comparison occurs. Default to transcription language."
                )
            })
            .or(zod.string())
        )
        .describe(
          "Specific vocabulary list to feed the transcription model with. Each item can be a string or an object with the following properties: value, intensity, pronunciations, language."
        ),
      default_intensity: zod
        .number()
        .min(preRecordedControllerInitPreRecordedJobV2BodyCustomVocabularyConfigDefaultIntensityMin)
        .max(preRecordedControllerInitPreRecordedJobV2BodyCustomVocabularyConfigDefaultIntensityMax)
        .optional()
        .describe("Default intensity for the custom vocabulary")
    })
    .optional()
    .describe("**[Beta]** Custom vocabulary configuration, if `custom_vocabulary` is enabled"),
  detect_language: zod
    .boolean()
    .default(preRecordedControllerInitPreRecordedJobV2BodyDetectLanguageDefault)
    .describe(
      "**[Deprecated]** Use `language_config` instead. Detect the language from the given audio"
    ),
  enable_code_switching: zod
    .boolean()
    .optional()
    .describe(
      "**[Deprecated]** Use `language_config` instead.Detect multiple languages in the given audio"
    ),
  code_switching_config: zod
    .object({
      languages: zod
        .array(
          zod
            .enum([
              "af",
              "am",
              "ar",
              "as",
              "az",
              "ba",
              "be",
              "bg",
              "bn",
              "bo",
              "br",
              "bs",
              "ca",
              "cs",
              "cy",
              "da",
              "de",
              "el",
              "en",
              "es",
              "et",
              "eu",
              "fa",
              "fi",
              "fo",
              "fr",
              "gl",
              "gu",
              "ha",
              "haw",
              "he",
              "hi",
              "hr",
              "ht",
              "hu",
              "hy",
              "id",
              "is",
              "it",
              "ja",
              "jw",
              "ka",
              "kk",
              "km",
              "kn",
              "ko",
              "la",
              "lb",
              "ln",
              "lo",
              "lt",
              "lv",
              "mg",
              "mi",
              "mk",
              "ml",
              "mn",
              "mr",
              "ms",
              "mt",
              "my",
              "ne",
              "nl",
              "nn",
              "no",
              "oc",
              "pa",
              "pl",
              "ps",
              "pt",
              "ro",
              "ru",
              "sa",
              "sd",
              "si",
              "sk",
              "sl",
              "sn",
              "so",
              "sq",
              "sr",
              "su",
              "sv",
              "sw",
              "ta",
              "te",
              "tg",
              "th",
              "tk",
              "tl",
              "tr",
              "tt",
              "uk",
              "ur",
              "uz",
              "vi",
              "yi",
              "yo",
              "zh"
            ])
            .describe(
              "Specify the language in which it will be pronounced when sound comparison occurs. Default to transcription language."
            )
        )
        .default(preRecordedControllerInitPreRecordedJobV2BodyCodeSwitchingConfigLanguagesDefault)
        .describe("Specify the languages you want to use when detecting multiple languages")
    })
    .optional()
    .describe(
      "**[Deprecated]** Use `language_config` instead. Specify the configuration for code switching"
    ),
  language: zod
    .enum([
      "af",
      "am",
      "ar",
      "as",
      "az",
      "ba",
      "be",
      "bg",
      "bn",
      "bo",
      "br",
      "bs",
      "ca",
      "cs",
      "cy",
      "da",
      "de",
      "el",
      "en",
      "es",
      "et",
      "eu",
      "fa",
      "fi",
      "fo",
      "fr",
      "gl",
      "gu",
      "ha",
      "haw",
      "he",
      "hi",
      "hr",
      "ht",
      "hu",
      "hy",
      "id",
      "is",
      "it",
      "ja",
      "jw",
      "ka",
      "kk",
      "km",
      "kn",
      "ko",
      "la",
      "lb",
      "ln",
      "lo",
      "lt",
      "lv",
      "mg",
      "mi",
      "mk",
      "ml",
      "mn",
      "mr",
      "ms",
      "mt",
      "my",
      "ne",
      "nl",
      "nn",
      "no",
      "oc",
      "pa",
      "pl",
      "ps",
      "pt",
      "ro",
      "ru",
      "sa",
      "sd",
      "si",
      "sk",
      "sl",
      "sn",
      "so",
      "sq",
      "sr",
      "su",
      "sv",
      "sw",
      "ta",
      "te",
      "tg",
      "th",
      "tk",
      "tl",
      "tr",
      "tt",
      "uk",
      "ur",
      "uz",
      "vi",
      "yi",
      "yo",
      "zh"
    ])
    .describe(
      "Specify the language in which it will be pronounced when sound comparison occurs. Default to transcription language."
    )
    .optional()
    .describe(
      "**[Deprecated]** Use `language_config` instead. Set the spoken language for the given audio (ISO 639 standard)"
    ),
  callback_url: zod
    .string()
    .url()
    .optional()
    .describe(
      "**[Deprecated]** Use `callback`/`callback_config` instead. Callback URL we will do a `POST` request to with the result of the transcription"
    ),
  callback: zod
    .boolean()
    .optional()
    .describe(
      "Enable callback for this transcription. If true, the `callback_config` property will be used to customize the callback behaviour"
    ),
  callback_config: zod
    .object({
      url: zod.string().url().describe("The URL to be called with the result of the transcription"),
      method: zod
        .enum(["POST", "PUT"])
        .describe(
          "The HTTP method to be used. Allowed values are `POST` or `PUT` (default: `POST`)"
        )
        .default(preRecordedControllerInitPreRecordedJobV2BodyCallbackConfigMethodDefault)
        .describe(
          "The HTTP method to be used. Allowed values are `POST` or `PUT` (default: `POST`)"
        )
    })
    .optional()
    .describe("Customize the callback behaviour (url and http method)"),
  subtitles: zod
    .boolean()
    .optional()
    .describe("Enable subtitles generation for this transcription"),
  subtitles_config: zod
    .object({
      formats: zod
        .array(
          zod
            .enum(["srt", "vtt"])
            .describe("Subtitles formats you want your transcription to be formatted to")
        )
        .min(1)
        .default(preRecordedControllerInitPreRecordedJobV2BodySubtitlesConfigFormatsDefault)
        .describe("Subtitles formats you want your transcription to be formatted to"),
      minimum_duration: zod
        .number()
        .min(preRecordedControllerInitPreRecordedJobV2BodySubtitlesConfigMinimumDurationMin)
        .optional()
        .describe("Minimum duration of a subtitle in seconds"),
      maximum_duration: zod
        .number()
        .min(1)
        .max(preRecordedControllerInitPreRecordedJobV2BodySubtitlesConfigMaximumDurationMax)
        .optional()
        .describe("Maximum duration of a subtitle in seconds"),
      maximum_characters_per_row: zod
        .number()
        .min(1)
        .optional()
        .describe("Maximum number of characters per row in a subtitle"),
      maximum_rows_per_caption: zod
        .number()
        .min(1)
        .max(preRecordedControllerInitPreRecordedJobV2BodySubtitlesConfigMaximumRowsPerCaptionMax)
        .optional()
        .describe("Maximum number of rows per caption"),
      style: zod
        .enum(["default", "compliance"])
        .describe(
          "Style of the subtitles. Compliance mode refers to : https://loc.gov/preservation/digital/formats//fdd/fdd000569.shtml#:~:text=SRT%20files%20are%20basic%20text,alongside%2C%20example%3A%20%22MyVideo123 "
        )
        .default(preRecordedControllerInitPreRecordedJobV2BodySubtitlesConfigStyleDefault)
        .describe(
          "Style of the subtitles. Compliance mode refers to : https://loc.gov/preservation/digital/formats//fdd/fdd000569.shtml#:~:text=SRT%20files%20are%20basic%20text,alongside%2C%20example%3A%20%22MyVideo123 "
        )
    })
    .optional()
    .describe("Configuration for subtitles generation if `subtitles` is enabled"),
  diarization: zod
    .boolean()
    .optional()
    .describe("Enable speaker recognition (diarization) for this audio"),
  diarization_config: zod
    .object({
      number_of_speakers: zod
        .number()
        .min(1)
        .optional()
        .describe("Exact number of speakers in the audio"),
      min_speakers: zod
        .number()
        .min(preRecordedControllerInitPreRecordedJobV2BodyDiarizationConfigMinSpeakersMin)
        .optional()
        .describe("Minimum number of speakers in the audio"),
      max_speakers: zod
        .number()
        .min(preRecordedControllerInitPreRecordedJobV2BodyDiarizationConfigMaxSpeakersMin)
        .optional()
        .describe("Maximum number of speakers in the audio")
    })
    .optional()
    .describe("Speaker recognition configuration, if `diarization` is enabled"),
  translation: zod.boolean().optional().describe("**[Beta]** Enable translation for this audio"),
  translation_config: zod
    .object({
      target_languages: zod
        .array(
          zod
            .enum([
              "af",
              "am",
              "ar",
              "as",
              "az",
              "ba",
              "be",
              "bg",
              "bn",
              "bo",
              "br",
              "bs",
              "ca",
              "cs",
              "cy",
              "da",
              "de",
              "el",
              "en",
              "es",
              "et",
              "eu",
              "fa",
              "fi",
              "fo",
              "fr",
              "gl",
              "gu",
              "ha",
              "haw",
              "he",
              "hi",
              "hr",
              "ht",
              "hu",
              "hy",
              "id",
              "is",
              "it",
              "ja",
              "jw",
              "ka",
              "kk",
              "km",
              "kn",
              "ko",
              "la",
              "lb",
              "ln",
              "lo",
              "lt",
              "lv",
              "mg",
              "mi",
              "mk",
              "ml",
              "mn",
              "mr",
              "ms",
              "mt",
              "my",
              "ne",
              "nl",
              "nn",
              "no",
              "oc",
              "pa",
              "pl",
              "ps",
              "pt",
              "ro",
              "ru",
              "sa",
              "sd",
              "si",
              "sk",
              "sl",
              "sn",
              "so",
              "sq",
              "sr",
              "su",
              "sv",
              "sw",
              "ta",
              "te",
              "tg",
              "th",
              "tk",
              "tl",
              "tr",
              "tt",
              "uk",
              "ur",
              "uz",
              "vi",
              "wo",
              "yi",
              "yo",
              "zh"
            ])
            .describe(
              "Target language in `iso639-1` format you want the transcription translated to"
            )
        )
        .min(1)
        .describe("Target language in `iso639-1` format you want the transcription translated to"),
      model: zod
        .enum(["base", "enhanced"])
        .describe("Model you want the translation model to use to translate")
        .default(preRecordedControllerInitPreRecordedJobV2BodyTranslationConfigModelDefault)
        .describe("Model you want the translation model to use to translate"),
      match_original_utterances: zod
        .boolean()
        .default(
          preRecordedControllerInitPreRecordedJobV2BodyTranslationConfigMatchOriginalUtterancesDefault
        )
        .describe("Align translated utterances with the original ones"),
      lipsync: zod
        .boolean()
        .default(preRecordedControllerInitPreRecordedJobV2BodyTranslationConfigLipsyncDefault)
        .describe("Whether to apply lipsync to the translated transcription. "),
      context_adaptation: zod
        .boolean()
        .default(
          preRecordedControllerInitPreRecordedJobV2BodyTranslationConfigContextAdaptationDefault
        )
        .describe(
          "Enables or disables context-aware translation features that allow the model to adapt translations based on provided context."
        ),
      context: zod
        .string()
        .optional()
        .describe("Context information to improve translation accuracy"),
      informal: zod
        .boolean()
        .optional()
        .describe(
          "Forces the translation to use informal language forms when available in the target language."
        )
    })
    .optional()
    .describe("**[Beta]** Translation configuration, if `translation` is enabled"),
  summarization: zod
    .boolean()
    .optional()
    .describe("**[Beta]** Enable summarization for this audio"),
  summarization_config: zod
    .object({
      type: zod
        .enum(["general", "bullet_points", "concise"])
        .describe("The type of summarization to apply")
        .default(preRecordedControllerInitPreRecordedJobV2BodySummarizationConfigTypeDefault)
        .describe("The type of summarization to apply")
    })
    .optional()
    .describe("**[Beta]** Summarization configuration, if `summarization` is enabled"),
  moderation: zod.boolean().optional().describe("**[Alpha]** Enable moderation for this audio"),
  named_entity_recognition: zod
    .boolean()
    .optional()
    .describe("**[Alpha]** Enable named entity recognition for this audio"),
  chapterization: zod
    .boolean()
    .optional()
    .describe("**[Alpha]** Enable chapterization for this audio"),
  name_consistency: zod
    .boolean()
    .optional()
    .describe("**[Alpha]** Enable names consistency for this audio"),
  custom_spelling: zod
    .boolean()
    .optional()
    .describe("**[Alpha]** Enable custom spelling for this audio"),
  custom_spelling_config: zod
    .object({
      spelling_dictionary: zod
        .record(zod.string(), zod.array(zod.string()))
        .describe("The list of spelling applied on the audio transcription")
    })
    .optional()
    .describe("**[Alpha]** Custom spelling configuration, if `custom_spelling` is enabled"),
  structured_data_extraction: zod
    .boolean()
    .optional()
    .describe("**[Alpha]** Enable structured data extraction for this audio"),
  structured_data_extraction_config: zod
    .object({
      classes: zod
        .array(zod.array(zod.unknown()))
        .min(1)
        .describe("The list of classes to extract from the audio transcription")
    })
    .optional()
    .describe(
      "**[Alpha]** Structured data extraction configuration, if `structured_data_extraction` is enabled"
    ),
  sentiment_analysis: zod.boolean().optional().describe("Enable sentiment analysis for this audio"),
  audio_to_llm: zod
    .boolean()
    .optional()
    .describe("**[Alpha]** Enable audio to llm processing for this audio"),
  audio_to_llm_config: zod
    .object({
      prompts: zod
        .array(zod.array(zod.unknown()))
        .min(1)
        .describe("The list of prompts applied on the audio transcription")
    })
    .optional()
    .describe("**[Alpha]** Audio to llm configuration, if `audio_to_llm` is enabled"),
  custom_metadata: zod
    .record(zod.string(), zod.any())
    .optional()
    .describe("Custom metadata you can attach to this transcription"),
  sentences: zod.boolean().optional().describe("Enable sentences for this audio"),
  display_mode: zod
    .boolean()
    .optional()
    .describe(
      "**[Alpha]** Allows to change the output display_mode for this audio. The output will be reordered, creating new utterances when speakers overlapped"
    ),
  punctuation_enhanced: zod
    .boolean()
    .optional()
    .describe("**[Alpha]** Use enhanced punctuation for this audio"),
  language_config: zod
    .object({
      languages: zod
        .array(
          zod
            .enum([
              "af",
              "am",
              "ar",
              "as",
              "az",
              "ba",
              "be",
              "bg",
              "bn",
              "bo",
              "br",
              "bs",
              "ca",
              "cs",
              "cy",
              "da",
              "de",
              "el",
              "en",
              "es",
              "et",
              "eu",
              "fa",
              "fi",
              "fo",
              "fr",
              "gl",
              "gu",
              "ha",
              "haw",
              "he",
              "hi",
              "hr",
              "ht",
              "hu",
              "hy",
              "id",
              "is",
              "it",
              "ja",
              "jw",
              "ka",
              "kk",
              "km",
              "kn",
              "ko",
              "la",
              "lb",
              "ln",
              "lo",
              "lt",
              "lv",
              "mg",
              "mi",
              "mk",
              "ml",
              "mn",
              "mr",
              "ms",
              "mt",
              "my",
              "ne",
              "nl",
              "nn",
              "no",
              "oc",
              "pa",
              "pl",
              "ps",
              "pt",
              "ro",
              "ru",
              "sa",
              "sd",
              "si",
              "sk",
              "sl",
              "sn",
              "so",
              "sq",
              "sr",
              "su",
              "sv",
              "sw",
              "ta",
              "te",
              "tg",
              "th",
              "tk",
              "tl",
              "tr",
              "tt",
              "uk",
              "ur",
              "uz",
              "vi",
              "yi",
              "yo",
              "zh"
            ])
            .describe(
              "Specify the language in which it will be pronounced when sound comparison occurs. Default to transcription language."
            )
        )
        .default(preRecordedControllerInitPreRecordedJobV2BodyLanguageConfigLanguagesDefault)
        .describe(
          "If one language is set, it will be used for the transcription. Otherwise, language will be auto-detected by the model."
        ),
      code_switching: zod
        .boolean()
        .optional()
        .describe(
          "If true, language will be auto-detected on each utterance. Otherwise, language will be auto-detected on first utterance and then used for the rest of the transcription. If one language is set, this option will be ignored."
        )
    })
    .optional()
    .describe("Specify the language configuration"),
  audio_url: zod
    .string()
    .url()
    .describe("URL to a Gladia file or to an external audio or video file")
})

/**
 * @summary Get pre recorded jobs based on query parameters
 */
export const preRecordedControllerGetPreRecordedJobsV2QueryOffsetDefault = 0
export const preRecordedControllerGetPreRecordedJobsV2QueryOffsetMin = 0
export const preRecordedControllerGetPreRecordedJobsV2QueryLimitDefault = 20

export const preRecordedControllerGetPreRecordedJobsV2QueryParams = zod.object({
  offset: zod
    .number()
    .min(preRecordedControllerGetPreRecordedJobsV2QueryOffsetMin)
    .optional()
    .describe("The starting point for pagination. A value of 0 starts from the first item."),
  limit: zod
    .number()
    .min(1)
    .default(preRecordedControllerGetPreRecordedJobsV2QueryLimitDefault)
    .describe(
      "The maximum number of items to return. Useful for pagination and controlling data payload size."
    ),
  date: zod
    .string()
    .datetime({})
    .optional()
    .describe("Filter items relevant to a specific date in ISO format (YYYY-MM-DD)."),
  before_date: zod
    .string()
    .datetime({})
    .optional()
    .describe("Include items that occurred before the specified date in ISO format."),
  after_date: zod
    .string()
    .datetime({})
    .optional()
    .describe(
      "Filter for items after the specified date. Use with `before_date` for a range. Date in ISO format."
    ),
  status: zod
    .array(zod.enum(["queued", "processing", "done", "error"]))
    .optional()
    .describe(
      "Filter the list based on item status. Accepts multiple values from the predefined list."
    ),
  custom_metadata: zod.record(zod.string(), zod.any()).optional()
})

export const preRecordedControllerGetPreRecordedJobsV2ResponseItemsItemErrorCodeMin = 400

export const preRecordedControllerGetPreRecordedJobsV2ResponseItemsItemErrorCodeMax = 599
export const preRecordedControllerGetPreRecordedJobsV2ResponseItemsItemKindDefault = "pre-recorded"
export const preRecordedControllerGetPreRecordedJobsV2ResponseItemsItemRequestParamsCustomVocabularyDefault = false
export const preRecordedControllerGetPreRecordedJobsV2ResponseItemsItemRequestParamsCustomVocabularyConfigVocabularyItemIntensityMin = 0

export const preRecordedControllerGetPreRecordedJobsV2ResponseItemsItemRequestParamsCustomVocabularyConfigVocabularyItemIntensityMax = 1
export const preRecordedControllerGetPreRecordedJobsV2ResponseItemsItemRequestParamsCustomVocabularyConfigDefaultIntensityMin = 0

export const preRecordedControllerGetPreRecordedJobsV2ResponseItemsItemRequestParamsCustomVocabularyConfigDefaultIntensityMax = 1
export const preRecordedControllerGetPreRecordedJobsV2ResponseItemsItemRequestParamsDetectLanguageDefault = true
export const preRecordedControllerGetPreRecordedJobsV2ResponseItemsItemRequestParamsEnableCodeSwitchingDefault = false
export const preRecordedControllerGetPreRecordedJobsV2ResponseItemsItemRequestParamsCodeSwitchingConfigLanguagesDefault =
  []
export const preRecordedControllerGetPreRecordedJobsV2ResponseItemsItemRequestParamsCallbackDefault = false
export const preRecordedControllerGetPreRecordedJobsV2ResponseItemsItemRequestParamsCallbackConfigMethodDefault =
  "POST"
export const preRecordedControllerGetPreRecordedJobsV2ResponseItemsItemRequestParamsSubtitlesDefault = false
export const preRecordedControllerGetPreRecordedJobsV2ResponseItemsItemRequestParamsSubtitlesConfigFormatsDefault: string[] =
  ["srt"]
export const preRecordedControllerGetPreRecordedJobsV2ResponseItemsItemRequestParamsSubtitlesConfigMinimumDurationMin = 0
export const preRecordedControllerGetPreRecordedJobsV2ResponseItemsItemRequestParamsSubtitlesConfigMaximumDurationMax = 30
export const preRecordedControllerGetPreRecordedJobsV2ResponseItemsItemRequestParamsSubtitlesConfigMaximumRowsPerCaptionMax = 5
export const preRecordedControllerGetPreRecordedJobsV2ResponseItemsItemRequestParamsSubtitlesConfigStyleDefault =
  "default"
export const preRecordedControllerGetPreRecordedJobsV2ResponseItemsItemRequestParamsDiarizationDefault = false
export const preRecordedControllerGetPreRecordedJobsV2ResponseItemsItemRequestParamsDiarizationConfigMinSpeakersMin = 0
export const preRecordedControllerGetPreRecordedJobsV2ResponseItemsItemRequestParamsDiarizationConfigMaxSpeakersMin = 0
export const preRecordedControllerGetPreRecordedJobsV2ResponseItemsItemRequestParamsTranslationDefault = false
export const preRecordedControllerGetPreRecordedJobsV2ResponseItemsItemRequestParamsTranslationConfigModelDefault =
  "base"
export const preRecordedControllerGetPreRecordedJobsV2ResponseItemsItemRequestParamsTranslationConfigMatchOriginalUtterancesDefault = true
export const preRecordedControllerGetPreRecordedJobsV2ResponseItemsItemRequestParamsTranslationConfigLipsyncDefault = true
export const preRecordedControllerGetPreRecordedJobsV2ResponseItemsItemRequestParamsTranslationConfigContextAdaptationDefault = true
export const preRecordedControllerGetPreRecordedJobsV2ResponseItemsItemRequestParamsTranslationConfigInformalDefault = false
export const preRecordedControllerGetPreRecordedJobsV2ResponseItemsItemRequestParamsSummarizationDefault = false
export const preRecordedControllerGetPreRecordedJobsV2ResponseItemsItemRequestParamsSummarizationConfigTypeDefault =
  "general"
export const preRecordedControllerGetPreRecordedJobsV2ResponseItemsItemRequestParamsModerationDefault = false
export const preRecordedControllerGetPreRecordedJobsV2ResponseItemsItemRequestParamsNamedEntityRecognitionDefault = false
export const preRecordedControllerGetPreRecordedJobsV2ResponseItemsItemRequestParamsChapterizationDefault = false
export const preRecordedControllerGetPreRecordedJobsV2ResponseItemsItemRequestParamsNameConsistencyDefault = false
export const preRecordedControllerGetPreRecordedJobsV2ResponseItemsItemRequestParamsCustomSpellingDefault = false
export const preRecordedControllerGetPreRecordedJobsV2ResponseItemsItemRequestParamsStructuredDataExtractionDefault = false
export const preRecordedControllerGetPreRecordedJobsV2ResponseItemsItemRequestParamsSentimentAnalysisDefault = false
export const preRecordedControllerGetPreRecordedJobsV2ResponseItemsItemRequestParamsAudioToLlmDefault = false
export const preRecordedControllerGetPreRecordedJobsV2ResponseItemsItemRequestParamsSentencesDefault = false
export const preRecordedControllerGetPreRecordedJobsV2ResponseItemsItemRequestParamsDisplayModeDefault = false
export const preRecordedControllerGetPreRecordedJobsV2ResponseItemsItemRequestParamsPunctuationEnhancedDefault = false
export const preRecordedControllerGetPreRecordedJobsV2ResponseItemsItemRequestParamsLanguageConfigLanguagesDefault =
  []
export const preRecordedControllerGetPreRecordedJobsV2ResponseItemsItemRequestParamsLanguageConfigCodeSwitchingDefault = false
export const preRecordedControllerGetPreRecordedJobsV2ResponseItemsItemResultTranscriptionUtterancesItemChannelMin = 0
export const preRecordedControllerGetPreRecordedJobsV2ResponseItemsItemResultTranscriptionUtterancesItemSpeakerMin = 0
export const preRecordedControllerGetPreRecordedJobsV2ResponseItemsItemResultTranslationResultsItemUtterancesItemChannelMin = 0
export const preRecordedControllerGetPreRecordedJobsV2ResponseItemsItemResultTranslationResultsItemUtterancesItemSpeakerMin = 0
export const preRecordedControllerGetPreRecordedJobsV2ResponseItemsItemResultDiarizationResultsItemChannelMin = 0
export const preRecordedControllerGetPreRecordedJobsV2ResponseItemsItemResultDiarizationResultsItemSpeakerMin = 0

export const preRecordedControllerGetPreRecordedJobsV2Response = zod.object({
  first: zod.string().url().describe("URL to fetch the first page"),
  current: zod.string().url().describe("URL to fetch the current page"),
  next: zod.string().url().nullable().describe("URL to fetch the next page"),
  items: zod
    .array(
      zod.object({
        id: zod.string().uuid().describe("Id of the job"),
        request_id: zod.string().describe("Debug id"),
        version: zod.number().describe("API version"),
        status: zod
          .enum(["queued", "processing", "done", "error"])
          .describe(
            '\"queued\": the job has been queued. \"processing\": the job is being processed. \"done\": the job has been processed and the result is available. \"error\": an error occurred during the job\'s processing.'
          ),
        created_at: zod.string().datetime({}).describe("Creation date"),
        completed_at: zod
          .string()
          .datetime({})
          .nullish()
          .describe('Completion date when status is \"done\" or \"error\"'),
        custom_metadata: zod
          .record(zod.string(), zod.any())
          .optional()
          .describe("Custom metadata given in the initial request"),
        error_code: zod
          .number()
          .min(preRecordedControllerGetPreRecordedJobsV2ResponseItemsItemErrorCodeMin)
          .max(preRecordedControllerGetPreRecordedJobsV2ResponseItemsItemErrorCodeMax)
          .nullish()
          .describe('HTTP status code of the error if status is \"error\"'),
        post_session_metadata: zod
          .object({})
          .describe("For debugging purposes, send data that could help to identify issues"),
        kind: zod.enum(["pre-recorded"]),
        file: zod
          .object({
            id: zod.string().describe("The file id"),
            filename: zod.string().nullable().describe("The name of the uploaded file"),
            source: zod
              .string()
              .nullable()
              .describe("The link used to download the file if audio_url was used"),
            audio_duration: zod.number().nullable().describe("Duration of the audio file"),
            number_of_channels: zod
              .number()
              .min(1)
              .nullable()
              .describe("Number of channels in the audio file")
          })
          .nullish()
          .describe('The file data you uploaded. Can be null if status is \"error\"'),
        request_params: zod
          .object({
            context_prompt: zod
              .string()
              .optional()
              .describe(
                "**[Deprecated]** Context to feed the transcription model with for possible better accuracy"
              ),
            custom_vocabulary: zod
              .boolean()
              .optional()
              .describe(
                "**[Beta]** Can be either boolean to enable custom_vocabulary for this audio or an array with specific vocabulary list to feed the transcription model with"
              ),
            custom_vocabulary_config: zod
              .object({
                vocabulary: zod
                  .array(
                    zod
                      .object({
                        value: zod
                          .string()
                          .describe("The text used to replace in the transcription."),
                        intensity: zod
                          .number()
                          .min(
                            preRecordedControllerGetPreRecordedJobsV2ResponseItemsItemRequestParamsCustomVocabularyConfigVocabularyItemIntensityMin
                          )
                          .max(
                            preRecordedControllerGetPreRecordedJobsV2ResponseItemsItemRequestParamsCustomVocabularyConfigVocabularyItemIntensityMax
                          )
                          .optional()
                          .describe("The global intensity of the feature."),
                        pronunciations: zod
                          .array(zod.string())
                          .optional()
                          .describe("The pronunciations used in the transcription."),
                        language: zod
                          .enum([
                            "af",
                            "am",
                            "ar",
                            "as",
                            "az",
                            "ba",
                            "be",
                            "bg",
                            "bn",
                            "bo",
                            "br",
                            "bs",
                            "ca",
                            "cs",
                            "cy",
                            "da",
                            "de",
                            "el",
                            "en",
                            "es",
                            "et",
                            "eu",
                            "fa",
                            "fi",
                            "fo",
                            "fr",
                            "gl",
                            "gu",
                            "ha",
                            "haw",
                            "he",
                            "hi",
                            "hr",
                            "ht",
                            "hu",
                            "hy",
                            "id",
                            "is",
                            "it",
                            "ja",
                            "jw",
                            "ka",
                            "kk",
                            "km",
                            "kn",
                            "ko",
                            "la",
                            "lb",
                            "ln",
                            "lo",
                            "lt",
                            "lv",
                            "mg",
                            "mi",
                            "mk",
                            "ml",
                            "mn",
                            "mr",
                            "ms",
                            "mt",
                            "my",
                            "ne",
                            "nl",
                            "nn",
                            "no",
                            "oc",
                            "pa",
                            "pl",
                            "ps",
                            "pt",
                            "ro",
                            "ru",
                            "sa",
                            "sd",
                            "si",
                            "sk",
                            "sl",
                            "sn",
                            "so",
                            "sq",
                            "sr",
                            "su",
                            "sv",
                            "sw",
                            "ta",
                            "te",
                            "tg",
                            "th",
                            "tk",
                            "tl",
                            "tr",
                            "tt",
                            "uk",
                            "ur",
                            "uz",
                            "vi",
                            "yi",
                            "yo",
                            "zh"
                          ])
                          .describe(
                            "Specify the language in which it will be pronounced when sound comparison occurs. Default to transcription language."
                          )
                          .optional()
                          .describe(
                            "Specify the language in which it will be pronounced when sound comparison occurs. Default to transcription language."
                          )
                      })
                      .or(zod.string())
                  )
                  .describe(
                    "Specific vocabulary list to feed the transcription model with. Each item can be a string or an object with the following properties: value, intensity, pronunciations, language."
                  ),
                default_intensity: zod
                  .number()
                  .min(
                    preRecordedControllerGetPreRecordedJobsV2ResponseItemsItemRequestParamsCustomVocabularyConfigDefaultIntensityMin
                  )
                  .max(
                    preRecordedControllerGetPreRecordedJobsV2ResponseItemsItemRequestParamsCustomVocabularyConfigDefaultIntensityMax
                  )
                  .optional()
                  .describe("Default intensity for the custom vocabulary")
              })
              .optional()
              .describe(
                "**[Beta]** Custom vocabulary configuration, if `custom_vocabulary` is enabled"
              ),
            detect_language: zod
              .boolean()
              .default(
                preRecordedControllerGetPreRecordedJobsV2ResponseItemsItemRequestParamsDetectLanguageDefault
              )
              .describe(
                "**[Deprecated]** Use `language_config` instead. Detect the language from the given audio"
              ),
            enable_code_switching: zod
              .boolean()
              .optional()
              .describe(
                "**[Deprecated]** Use `language_config` instead.Detect multiple languages in the given audio"
              ),
            code_switching_config: zod
              .object({
                languages: zod
                  .array(
                    zod
                      .enum([
                        "af",
                        "am",
                        "ar",
                        "as",
                        "az",
                        "ba",
                        "be",
                        "bg",
                        "bn",
                        "bo",
                        "br",
                        "bs",
                        "ca",
                        "cs",
                        "cy",
                        "da",
                        "de",
                        "el",
                        "en",
                        "es",
                        "et",
                        "eu",
                        "fa",
                        "fi",
                        "fo",
                        "fr",
                        "gl",
                        "gu",
                        "ha",
                        "haw",
                        "he",
                        "hi",
                        "hr",
                        "ht",
                        "hu",
                        "hy",
                        "id",
                        "is",
                        "it",
                        "ja",
                        "jw",
                        "ka",
                        "kk",
                        "km",
                        "kn",
                        "ko",
                        "la",
                        "lb",
                        "ln",
                        "lo",
                        "lt",
                        "lv",
                        "mg",
                        "mi",
                        "mk",
                        "ml",
                        "mn",
                        "mr",
                        "ms",
                        "mt",
                        "my",
                        "ne",
                        "nl",
                        "nn",
                        "no",
                        "oc",
                        "pa",
                        "pl",
                        "ps",
                        "pt",
                        "ro",
                        "ru",
                        "sa",
                        "sd",
                        "si",
                        "sk",
                        "sl",
                        "sn",
                        "so",
                        "sq",
                        "sr",
                        "su",
                        "sv",
                        "sw",
                        "ta",
                        "te",
                        "tg",
                        "th",
                        "tk",
                        "tl",
                        "tr",
                        "tt",
                        "uk",
                        "ur",
                        "uz",
                        "vi",
                        "yi",
                        "yo",
                        "zh"
                      ])
                      .describe(
                        "Specify the language in which it will be pronounced when sound comparison occurs. Default to transcription language."
                      )
                  )
                  .default(
                    preRecordedControllerGetPreRecordedJobsV2ResponseItemsItemRequestParamsCodeSwitchingConfigLanguagesDefault
                  )
                  .describe(
                    "Specify the languages you want to use when detecting multiple languages"
                  )
              })
              .optional()
              .describe(
                "**[Deprecated]** Use `language_config` instead. Specify the configuration for code switching"
              ),
            language: zod
              .enum([
                "af",
                "am",
                "ar",
                "as",
                "az",
                "ba",
                "be",
                "bg",
                "bn",
                "bo",
                "br",
                "bs",
                "ca",
                "cs",
                "cy",
                "da",
                "de",
                "el",
                "en",
                "es",
                "et",
                "eu",
                "fa",
                "fi",
                "fo",
                "fr",
                "gl",
                "gu",
                "ha",
                "haw",
                "he",
                "hi",
                "hr",
                "ht",
                "hu",
                "hy",
                "id",
                "is",
                "it",
                "ja",
                "jw",
                "ka",
                "kk",
                "km",
                "kn",
                "ko",
                "la",
                "lb",
                "ln",
                "lo",
                "lt",
                "lv",
                "mg",
                "mi",
                "mk",
                "ml",
                "mn",
                "mr",
                "ms",
                "mt",
                "my",
                "ne",
                "nl",
                "nn",
                "no",
                "oc",
                "pa",
                "pl",
                "ps",
                "pt",
                "ro",
                "ru",
                "sa",
                "sd",
                "si",
                "sk",
                "sl",
                "sn",
                "so",
                "sq",
                "sr",
                "su",
                "sv",
                "sw",
                "ta",
                "te",
                "tg",
                "th",
                "tk",
                "tl",
                "tr",
                "tt",
                "uk",
                "ur",
                "uz",
                "vi",
                "yi",
                "yo",
                "zh"
              ])
              .describe(
                "Specify the language in which it will be pronounced when sound comparison occurs. Default to transcription language."
              )
              .optional()
              .describe(
                "**[Deprecated]** Use `language_config` instead. Set the spoken language for the given audio (ISO 639 standard)"
              ),
            callback_url: zod
              .string()
              .url()
              .optional()
              .describe(
                "**[Deprecated]** Use `callback`/`callback_config` instead. Callback URL we will do a `POST` request to with the result of the transcription"
              ),
            callback: zod
              .boolean()
              .optional()
              .describe(
                "Enable callback for this transcription. If true, the `callback_config` property will be used to customize the callback behaviour"
              ),
            callback_config: zod
              .object({
                url: zod
                  .string()
                  .url()
                  .describe("The URL to be called with the result of the transcription"),
                method: zod
                  .enum(["POST", "PUT"])
                  .describe(
                    "The HTTP method to be used. Allowed values are `POST` or `PUT` (default: `POST`)"
                  )
                  .default(
                    preRecordedControllerGetPreRecordedJobsV2ResponseItemsItemRequestParamsCallbackConfigMethodDefault
                  )
                  .describe(
                    "The HTTP method to be used. Allowed values are `POST` or `PUT` (default: `POST`)"
                  )
              })
              .optional()
              .describe("Customize the callback behaviour (url and http method)"),
            subtitles: zod
              .boolean()
              .optional()
              .describe("Enable subtitles generation for this transcription"),
            subtitles_config: zod
              .object({
                formats: zod
                  .array(
                    zod
                      .enum(["srt", "vtt"])
                      .describe("Subtitles formats you want your transcription to be formatted to")
                  )
                  .min(1)
                  .default(
                    preRecordedControllerGetPreRecordedJobsV2ResponseItemsItemRequestParamsSubtitlesConfigFormatsDefault
                  )
                  .describe("Subtitles formats you want your transcription to be formatted to"),
                minimum_duration: zod
                  .number()
                  .min(
                    preRecordedControllerGetPreRecordedJobsV2ResponseItemsItemRequestParamsSubtitlesConfigMinimumDurationMin
                  )
                  .optional()
                  .describe("Minimum duration of a subtitle in seconds"),
                maximum_duration: zod
                  .number()
                  .min(1)
                  .max(
                    preRecordedControllerGetPreRecordedJobsV2ResponseItemsItemRequestParamsSubtitlesConfigMaximumDurationMax
                  )
                  .optional()
                  .describe("Maximum duration of a subtitle in seconds"),
                maximum_characters_per_row: zod
                  .number()
                  .min(1)
                  .optional()
                  .describe("Maximum number of characters per row in a subtitle"),
                maximum_rows_per_caption: zod
                  .number()
                  .min(1)
                  .max(
                    preRecordedControllerGetPreRecordedJobsV2ResponseItemsItemRequestParamsSubtitlesConfigMaximumRowsPerCaptionMax
                  )
                  .optional()
                  .describe("Maximum number of rows per caption"),
                style: zod
                  .enum(["default", "compliance"])
                  .describe(
                    "Style of the subtitles. Compliance mode refers to : https://loc.gov/preservation/digital/formats//fdd/fdd000569.shtml#:~:text=SRT%20files%20are%20basic%20text,alongside%2C%20example%3A%20%22MyVideo123 "
                  )
                  .default(
                    preRecordedControllerGetPreRecordedJobsV2ResponseItemsItemRequestParamsSubtitlesConfigStyleDefault
                  )
                  .describe(
                    "Style of the subtitles. Compliance mode refers to : https://loc.gov/preservation/digital/formats//fdd/fdd000569.shtml#:~:text=SRT%20files%20are%20basic%20text,alongside%2C%20example%3A%20%22MyVideo123 "
                  )
              })
              .optional()
              .describe("Configuration for subtitles generation if `subtitles` is enabled"),
            diarization: zod
              .boolean()
              .optional()
              .describe("Enable speaker recognition (diarization) for this audio"),
            diarization_config: zod
              .object({
                number_of_speakers: zod
                  .number()
                  .min(1)
                  .optional()
                  .describe("Exact number of speakers in the audio"),
                min_speakers: zod
                  .number()
                  .min(
                    preRecordedControllerGetPreRecordedJobsV2ResponseItemsItemRequestParamsDiarizationConfigMinSpeakersMin
                  )
                  .optional()
                  .describe("Minimum number of speakers in the audio"),
                max_speakers: zod
                  .number()
                  .min(
                    preRecordedControllerGetPreRecordedJobsV2ResponseItemsItemRequestParamsDiarizationConfigMaxSpeakersMin
                  )
                  .optional()
                  .describe("Maximum number of speakers in the audio")
              })
              .optional()
              .describe("Speaker recognition configuration, if `diarization` is enabled"),
            translation: zod
              .boolean()
              .optional()
              .describe("**[Beta]** Enable translation for this audio"),
            translation_config: zod
              .object({
                target_languages: zod
                  .array(
                    zod
                      .enum([
                        "af",
                        "am",
                        "ar",
                        "as",
                        "az",
                        "ba",
                        "be",
                        "bg",
                        "bn",
                        "bo",
                        "br",
                        "bs",
                        "ca",
                        "cs",
                        "cy",
                        "da",
                        "de",
                        "el",
                        "en",
                        "es",
                        "et",
                        "eu",
                        "fa",
                        "fi",
                        "fo",
                        "fr",
                        "gl",
                        "gu",
                        "ha",
                        "haw",
                        "he",
                        "hi",
                        "hr",
                        "ht",
                        "hu",
                        "hy",
                        "id",
                        "is",
                        "it",
                        "ja",
                        "jw",
                        "ka",
                        "kk",
                        "km",
                        "kn",
                        "ko",
                        "la",
                        "lb",
                        "ln",
                        "lo",
                        "lt",
                        "lv",
                        "mg",
                        "mi",
                        "mk",
                        "ml",
                        "mn",
                        "mr",
                        "ms",
                        "mt",
                        "my",
                        "ne",
                        "nl",
                        "nn",
                        "no",
                        "oc",
                        "pa",
                        "pl",
                        "ps",
                        "pt",
                        "ro",
                        "ru",
                        "sa",
                        "sd",
                        "si",
                        "sk",
                        "sl",
                        "sn",
                        "so",
                        "sq",
                        "sr",
                        "su",
                        "sv",
                        "sw",
                        "ta",
                        "te",
                        "tg",
                        "th",
                        "tk",
                        "tl",
                        "tr",
                        "tt",
                        "uk",
                        "ur",
                        "uz",
                        "vi",
                        "wo",
                        "yi",
                        "yo",
                        "zh"
                      ])
                      .describe(
                        "Target language in `iso639-1` format you want the transcription translated to"
                      )
                  )
                  .min(1)
                  .describe(
                    "Target language in `iso639-1` format you want the transcription translated to"
                  ),
                model: zod
                  .enum(["base", "enhanced"])
                  .describe("Model you want the translation model to use to translate")
                  .default(
                    preRecordedControllerGetPreRecordedJobsV2ResponseItemsItemRequestParamsTranslationConfigModelDefault
                  )
                  .describe("Model you want the translation model to use to translate"),
                match_original_utterances: zod
                  .boolean()
                  .default(
                    preRecordedControllerGetPreRecordedJobsV2ResponseItemsItemRequestParamsTranslationConfigMatchOriginalUtterancesDefault
                  )
                  .describe("Align translated utterances with the original ones"),
                lipsync: zod
                  .boolean()
                  .default(
                    preRecordedControllerGetPreRecordedJobsV2ResponseItemsItemRequestParamsTranslationConfigLipsyncDefault
                  )
                  .describe("Whether to apply lipsync to the translated transcription. "),
                context_adaptation: zod
                  .boolean()
                  .default(
                    preRecordedControllerGetPreRecordedJobsV2ResponseItemsItemRequestParamsTranslationConfigContextAdaptationDefault
                  )
                  .describe(
                    "Enables or disables context-aware translation features that allow the model to adapt translations based on provided context."
                  ),
                context: zod
                  .string()
                  .optional()
                  .describe("Context information to improve translation accuracy"),
                informal: zod
                  .boolean()
                  .optional()
                  .describe(
                    "Forces the translation to use informal language forms when available in the target language."
                  )
              })
              .optional()
              .describe("**[Beta]** Translation configuration, if `translation` is enabled"),
            summarization: zod
              .boolean()
              .optional()
              .describe("**[Beta]** Enable summarization for this audio"),
            summarization_config: zod
              .object({
                type: zod
                  .enum(["general", "bullet_points", "concise"])
                  .describe("The type of summarization to apply")
                  .default(
                    preRecordedControllerGetPreRecordedJobsV2ResponseItemsItemRequestParamsSummarizationConfigTypeDefault
                  )
                  .describe("The type of summarization to apply")
              })
              .optional()
              .describe("**[Beta]** Summarization configuration, if `summarization` is enabled"),
            moderation: zod
              .boolean()
              .optional()
              .describe("**[Alpha]** Enable moderation for this audio"),
            named_entity_recognition: zod
              .boolean()
              .optional()
              .describe("**[Alpha]** Enable named entity recognition for this audio"),
            chapterization: zod
              .boolean()
              .optional()
              .describe("**[Alpha]** Enable chapterization for this audio"),
            name_consistency: zod
              .boolean()
              .optional()
              .describe("**[Alpha]** Enable names consistency for this audio"),
            custom_spelling: zod
              .boolean()
              .optional()
              .describe("**[Alpha]** Enable custom spelling for this audio"),
            custom_spelling_config: zod
              .object({
                spelling_dictionary: zod
                  .record(zod.string(), zod.array(zod.string()))
                  .describe("The list of spelling applied on the audio transcription")
              })
              .optional()
              .describe(
                "**[Alpha]** Custom spelling configuration, if `custom_spelling` is enabled"
              ),
            structured_data_extraction: zod
              .boolean()
              .optional()
              .describe("**[Alpha]** Enable structured data extraction for this audio"),
            structured_data_extraction_config: zod
              .object({
                classes: zod
                  .array(zod.array(zod.unknown()))
                  .min(1)
                  .describe("The list of classes to extract from the audio transcription")
              })
              .optional()
              .describe(
                "**[Alpha]** Structured data extraction configuration, if `structured_data_extraction` is enabled"
              ),
            sentiment_analysis: zod
              .boolean()
              .optional()
              .describe("Enable sentiment analysis for this audio"),
            audio_to_llm: zod
              .boolean()
              .optional()
              .describe("**[Alpha]** Enable audio to llm processing for this audio"),
            audio_to_llm_config: zod
              .object({
                prompts: zod
                  .array(zod.array(zod.unknown()))
                  .min(1)
                  .describe("The list of prompts applied on the audio transcription")
              })
              .optional()
              .describe("**[Alpha]** Audio to llm configuration, if `audio_to_llm` is enabled"),
            sentences: zod.boolean().optional().describe("Enable sentences for this audio"),
            display_mode: zod
              .boolean()
              .optional()
              .describe(
                "**[Alpha]** Allows to change the output display_mode for this audio. The output will be reordered, creating new utterances when speakers overlapped"
              ),
            punctuation_enhanced: zod
              .boolean()
              .optional()
              .describe("**[Alpha]** Use enhanced punctuation for this audio"),
            language_config: zod
              .object({
                languages: zod
                  .array(
                    zod
                      .enum([
                        "af",
                        "am",
                        "ar",
                        "as",
                        "az",
                        "ba",
                        "be",
                        "bg",
                        "bn",
                        "bo",
                        "br",
                        "bs",
                        "ca",
                        "cs",
                        "cy",
                        "da",
                        "de",
                        "el",
                        "en",
                        "es",
                        "et",
                        "eu",
                        "fa",
                        "fi",
                        "fo",
                        "fr",
                        "gl",
                        "gu",
                        "ha",
                        "haw",
                        "he",
                        "hi",
                        "hr",
                        "ht",
                        "hu",
                        "hy",
                        "id",
                        "is",
                        "it",
                        "ja",
                        "jw",
                        "ka",
                        "kk",
                        "km",
                        "kn",
                        "ko",
                        "la",
                        "lb",
                        "ln",
                        "lo",
                        "lt",
                        "lv",
                        "mg",
                        "mi",
                        "mk",
                        "ml",
                        "mn",
                        "mr",
                        "ms",
                        "mt",
                        "my",
                        "ne",
                        "nl",
                        "nn",
                        "no",
                        "oc",
                        "pa",
                        "pl",
                        "ps",
                        "pt",
                        "ro",
                        "ru",
                        "sa",
                        "sd",
                        "si",
                        "sk",
                        "sl",
                        "sn",
                        "so",
                        "sq",
                        "sr",
                        "su",
                        "sv",
                        "sw",
                        "ta",
                        "te",
                        "tg",
                        "th",
                        "tk",
                        "tl",
                        "tr",
                        "tt",
                        "uk",
                        "ur",
                        "uz",
                        "vi",
                        "yi",
                        "yo",
                        "zh"
                      ])
                      .describe(
                        "Specify the language in which it will be pronounced when sound comparison occurs. Default to transcription language."
                      )
                  )
                  .default(
                    preRecordedControllerGetPreRecordedJobsV2ResponseItemsItemRequestParamsLanguageConfigLanguagesDefault
                  )
                  .describe(
                    "If one language is set, it will be used for the transcription. Otherwise, language will be auto-detected by the model."
                  ),
                code_switching: zod
                  .boolean()
                  .optional()
                  .describe(
                    "If true, language will be auto-detected on each utterance. Otherwise, language will be auto-detected on first utterance and then used for the rest of the transcription. If one language is set, this option will be ignored."
                  )
              })
              .optional()
              .describe("Specify the language configuration"),
            audio_url: zod.string().url().nullable()
          })
          .nullish()
          .describe(
            'Parameters used for this pre-recorded transcription. Can be null if status is \"error\"'
          ),
        result: zod
          .object({
            metadata: zod
              .object({
                audio_duration: zod.number().describe("Duration of the transcribed audio file"),
                number_of_distinct_channels: zod
                  .number()
                  .min(1)
                  .describe("Number of distinct channels in the transcribed audio file"),
                billing_time: zod
                  .number()
                  .describe(
                    "Billed duration in seconds (audio_duration * number_of_distinct_channels)"
                  ),
                transcription_time: zod
                  .number()
                  .describe("Duration of the transcription in seconds")
              })
              .describe("Metadata for the given transcription & audio file"),
            transcription: zod
              .object({
                full_transcript: zod
                  .string()
                  .describe("All transcription on text format without any other information"),
                languages: zod
                  .array(
                    zod
                      .enum([
                        "af",
                        "am",
                        "ar",
                        "as",
                        "az",
                        "ba",
                        "be",
                        "bg",
                        "bn",
                        "bo",
                        "br",
                        "bs",
                        "ca",
                        "cs",
                        "cy",
                        "da",
                        "de",
                        "el",
                        "en",
                        "es",
                        "et",
                        "eu",
                        "fa",
                        "fi",
                        "fo",
                        "fr",
                        "gl",
                        "gu",
                        "ha",
                        "haw",
                        "he",
                        "hi",
                        "hr",
                        "ht",
                        "hu",
                        "hy",
                        "id",
                        "is",
                        "it",
                        "ja",
                        "jw",
                        "ka",
                        "kk",
                        "km",
                        "kn",
                        "ko",
                        "la",
                        "lb",
                        "ln",
                        "lo",
                        "lt",
                        "lv",
                        "mg",
                        "mi",
                        "mk",
                        "ml",
                        "mn",
                        "mr",
                        "ms",
                        "mt",
                        "my",
                        "ne",
                        "nl",
                        "nn",
                        "no",
                        "oc",
                        "pa",
                        "pl",
                        "ps",
                        "pt",
                        "ro",
                        "ru",
                        "sa",
                        "sd",
                        "si",
                        "sk",
                        "sl",
                        "sn",
                        "so",
                        "sq",
                        "sr",
                        "su",
                        "sv",
                        "sw",
                        "ta",
                        "te",
                        "tg",
                        "th",
                        "tk",
                        "tl",
                        "tr",
                        "tt",
                        "uk",
                        "ur",
                        "uz",
                        "vi",
                        "yi",
                        "yo",
                        "zh"
                      ])
                      .describe(
                        "Specify the language in which it will be pronounced when sound comparison occurs. Default to transcription language."
                      )
                  )
                  .describe(
                    "All the detected languages in the audio sorted from the most detected to the less detected"
                  ),
                sentences: zod
                  .array(
                    zod.object({
                      success: zod
                        .boolean()
                        .describe("The audio intelligence model succeeded to get a valid output"),
                      is_empty: zod
                        .boolean()
                        .describe("The audio intelligence model returned an empty value"),
                      exec_time: zod
                        .number()
                        .describe("Time audio intelligence model took to complete the task"),
                      error: zod
                        .object({
                          status_code: zod.number().describe("Status code of the addon error"),
                          exception: zod.string().describe("Reason of the addon error"),
                          message: zod.string().describe("Detailed message of the addon error")
                        })
                        .nullable()
                        .describe(
                          "`null` if `success` is `true`. Contains the error details of the failed model"
                        ),
                      results: zod
                        .array(zod.string())
                        .nullable()
                        .describe("If `sentences` has been enabled, transcription as sentences.")
                    })
                  )
                  .optional()
                  .describe("If `sentences` has been enabled, sentences results"),
                subtitles: zod
                  .array(
                    zod.object({
                      format: zod
                        .enum(["srt", "vtt"])
                        .describe(
                          "Subtitles formats you want your transcription to be formatted to"
                        )
                        .describe("Format of the current subtitle"),
                      subtitles: zod.string().describe("Transcription on the asked subtitle format")
                    })
                  )
                  .optional()
                  .describe("If `subtitles` has been enabled, subtitles results"),
                utterances: zod
                  .array(
                    zod.object({
                      start: zod.number().describe("Start timestamp in seconds of this utterance"),
                      end: zod.number().describe("End timestamp in seconds of this utterance"),
                      confidence: zod
                        .number()
                        .describe("Confidence on the transcribed utterance (1 = 100% confident)"),
                      channel: zod
                        .number()
                        .min(
                          preRecordedControllerGetPreRecordedJobsV2ResponseItemsItemResultTranscriptionUtterancesItemChannelMin
                        )
                        .describe(
                          "Audio channel of where this utterance has been transcribed from"
                        ),
                      speaker: zod
                        .number()
                        .min(
                          preRecordedControllerGetPreRecordedJobsV2ResponseItemsItemResultTranscriptionUtterancesItemSpeakerMin
                        )
                        .optional()
                        .describe("If `diarization` enabled, speaker identification number"),
                      words: zod
                        .array(
                          zod.object({
                            word: zod.string().describe("Spoken word"),
                            start: zod
                              .number()
                              .describe("Start timestamps in seconds of the spoken word"),
                            end: zod
                              .number()
                              .describe("End timestamps in seconds of the spoken word"),
                            confidence: zod
                              .number()
                              .describe("Confidence on the transcribed word (1 = 100% confident)")
                          })
                        )
                        .describe("List of words of the utterance, split by timestamp"),
                      text: zod.string().describe("Transcription for this utterance"),
                      language: zod
                        .enum([
                          "af",
                          "am",
                          "ar",
                          "as",
                          "az",
                          "ba",
                          "be",
                          "bg",
                          "bn",
                          "bo",
                          "br",
                          "bs",
                          "ca",
                          "cs",
                          "cy",
                          "da",
                          "de",
                          "el",
                          "en",
                          "es",
                          "et",
                          "eu",
                          "fa",
                          "fi",
                          "fo",
                          "fr",
                          "gl",
                          "gu",
                          "ha",
                          "haw",
                          "he",
                          "hi",
                          "hr",
                          "ht",
                          "hu",
                          "hy",
                          "id",
                          "is",
                          "it",
                          "ja",
                          "jw",
                          "ka",
                          "kk",
                          "km",
                          "kn",
                          "ko",
                          "la",
                          "lb",
                          "ln",
                          "lo",
                          "lt",
                          "lv",
                          "mg",
                          "mi",
                          "mk",
                          "ml",
                          "mn",
                          "mr",
                          "ms",
                          "mt",
                          "my",
                          "ne",
                          "nl",
                          "nn",
                          "no",
                          "oc",
                          "pa",
                          "pl",
                          "ps",
                          "pt",
                          "ro",
                          "ru",
                          "sa",
                          "sd",
                          "si",
                          "sk",
                          "sl",
                          "sn",
                          "so",
                          "sq",
                          "sr",
                          "su",
                          "sv",
                          "sw",
                          "ta",
                          "te",
                          "tg",
                          "th",
                          "tk",
                          "tl",
                          "tr",
                          "tt",
                          "uk",
                          "ur",
                          "uz",
                          "vi",
                          "yi",
                          "yo",
                          "zh"
                        ])
                        .describe(
                          "Specify the language in which it will be pronounced when sound comparison occurs. Default to transcription language."
                        )
                        .describe("Spoken language in this utterance")
                    })
                  )
                  .describe("Transcribed speech utterances present in the audio")
              })
              .optional()
              .describe("Transcription of the audio speech"),
            translation: zod
              .object({
                success: zod
                  .boolean()
                  .describe("The audio intelligence model succeeded to get a valid output"),
                is_empty: zod
                  .boolean()
                  .describe("The audio intelligence model returned an empty value"),
                exec_time: zod
                  .number()
                  .describe("Time audio intelligence model took to complete the task"),
                error: zod
                  .object({
                    status_code: zod.number().describe("Status code of the addon error"),
                    exception: zod.string().describe("Reason of the addon error"),
                    message: zod.string().describe("Detailed message of the addon error")
                  })
                  .nullable()
                  .describe(
                    "`null` if `success` is `true`. Contains the error details of the failed model"
                  ),
                results: zod
                  .array(
                    zod.object({
                      error: zod
                        .object({
                          status_code: zod.number().describe("Status code of the addon error"),
                          exception: zod.string().describe("Reason of the addon error"),
                          message: zod.string().describe("Detailed message of the addon error")
                        })
                        .nullable()
                        .describe("Contains the error details of the failed addon"),
                      full_transcript: zod
                        .string()
                        .describe("All transcription on text format without any other information"),
                      languages: zod
                        .array(
                          zod
                            .enum([
                              "af",
                              "am",
                              "ar",
                              "as",
                              "az",
                              "ba",
                              "be",
                              "bg",
                              "bn",
                              "bo",
                              "br",
                              "bs",
                              "ca",
                              "cs",
                              "cy",
                              "da",
                              "de",
                              "el",
                              "en",
                              "es",
                              "et",
                              "eu",
                              "fa",
                              "fi",
                              "fo",
                              "fr",
                              "gl",
                              "gu",
                              "ha",
                              "haw",
                              "he",
                              "hi",
                              "hr",
                              "ht",
                              "hu",
                              "hy",
                              "id",
                              "is",
                              "it",
                              "ja",
                              "jw",
                              "ka",
                              "kk",
                              "km",
                              "kn",
                              "ko",
                              "la",
                              "lb",
                              "ln",
                              "lo",
                              "lt",
                              "lv",
                              "mg",
                              "mi",
                              "mk",
                              "ml",
                              "mn",
                              "mr",
                              "ms",
                              "mt",
                              "my",
                              "ne",
                              "nl",
                              "nn",
                              "no",
                              "oc",
                              "pa",
                              "pl",
                              "ps",
                              "pt",
                              "ro",
                              "ru",
                              "sa",
                              "sd",
                              "si",
                              "sk",
                              "sl",
                              "sn",
                              "so",
                              "sq",
                              "sr",
                              "su",
                              "sv",
                              "sw",
                              "ta",
                              "te",
                              "tg",
                              "th",
                              "tk",
                              "tl",
                              "tr",
                              "tt",
                              "uk",
                              "ur",
                              "uz",
                              "vi",
                              "wo",
                              "yi",
                              "yo",
                              "zh"
                            ])
                            .describe(
                              "Target language in `iso639-1` format you want the transcription translated to"
                            )
                        )
                        .describe(
                          "All the detected languages in the audio sorted from the most detected to the less detected"
                        ),
                      sentences: zod
                        .array(
                          zod.object({
                            success: zod
                              .boolean()
                              .describe(
                                "The audio intelligence model succeeded to get a valid output"
                              ),
                            is_empty: zod
                              .boolean()
                              .describe("The audio intelligence model returned an empty value"),
                            exec_time: zod
                              .number()
                              .describe("Time audio intelligence model took to complete the task"),
                            error: zod
                              .object({
                                status_code: zod
                                  .number()
                                  .describe("Status code of the addon error"),
                                exception: zod.string().describe("Reason of the addon error"),
                                message: zod
                                  .string()
                                  .describe("Detailed message of the addon error")
                              })
                              .nullable()
                              .describe(
                                "`null` if `success` is `true`. Contains the error details of the failed model"
                              ),
                            results: zod
                              .array(zod.string())
                              .nullable()
                              .describe(
                                "If `sentences` has been enabled, transcription as sentences."
                              )
                          })
                        )
                        .optional()
                        .describe(
                          "If `sentences` has been enabled, sentences results for this translation"
                        ),
                      subtitles: zod
                        .array(
                          zod.object({
                            format: zod
                              .enum(["srt", "vtt"])
                              .describe(
                                "Subtitles formats you want your transcription to be formatted to"
                              )
                              .describe("Format of the current subtitle"),
                            subtitles: zod
                              .string()
                              .describe("Transcription on the asked subtitle format")
                          })
                        )
                        .optional()
                        .describe(
                          "If `subtitles` has been enabled, subtitles results for this translation"
                        ),
                      utterances: zod
                        .array(
                          zod.object({
                            start: zod
                              .number()
                              .describe("Start timestamp in seconds of this utterance"),
                            end: zod
                              .number()
                              .describe("End timestamp in seconds of this utterance"),
                            confidence: zod
                              .number()
                              .describe(
                                "Confidence on the transcribed utterance (1 = 100% confident)"
                              ),
                            channel: zod
                              .number()
                              .min(
                                preRecordedControllerGetPreRecordedJobsV2ResponseItemsItemResultTranslationResultsItemUtterancesItemChannelMin
                              )
                              .describe(
                                "Audio channel of where this utterance has been transcribed from"
                              ),
                            speaker: zod
                              .number()
                              .min(
                                preRecordedControllerGetPreRecordedJobsV2ResponseItemsItemResultTranslationResultsItemUtterancesItemSpeakerMin
                              )
                              .optional()
                              .describe("If `diarization` enabled, speaker identification number"),
                            words: zod
                              .array(
                                zod.object({
                                  word: zod.string().describe("Spoken word"),
                                  start: zod
                                    .number()
                                    .describe("Start timestamps in seconds of the spoken word"),
                                  end: zod
                                    .number()
                                    .describe("End timestamps in seconds of the spoken word"),
                                  confidence: zod
                                    .number()
                                    .describe(
                                      "Confidence on the transcribed word (1 = 100% confident)"
                                    )
                                })
                              )
                              .describe("List of words of the utterance, split by timestamp"),
                            text: zod.string().describe("Transcription for this utterance"),
                            language: zod
                              .enum([
                                "af",
                                "am",
                                "ar",
                                "as",
                                "az",
                                "ba",
                                "be",
                                "bg",
                                "bn",
                                "bo",
                                "br",
                                "bs",
                                "ca",
                                "cs",
                                "cy",
                                "da",
                                "de",
                                "el",
                                "en",
                                "es",
                                "et",
                                "eu",
                                "fa",
                                "fi",
                                "fo",
                                "fr",
                                "gl",
                                "gu",
                                "ha",
                                "haw",
                                "he",
                                "hi",
                                "hr",
                                "ht",
                                "hu",
                                "hy",
                                "id",
                                "is",
                                "it",
                                "ja",
                                "jw",
                                "ka",
                                "kk",
                                "km",
                                "kn",
                                "ko",
                                "la",
                                "lb",
                                "ln",
                                "lo",
                                "lt",
                                "lv",
                                "mg",
                                "mi",
                                "mk",
                                "ml",
                                "mn",
                                "mr",
                                "ms",
                                "mt",
                                "my",
                                "ne",
                                "nl",
                                "nn",
                                "no",
                                "oc",
                                "pa",
                                "pl",
                                "ps",
                                "pt",
                                "ro",
                                "ru",
                                "sa",
                                "sd",
                                "si",
                                "sk",
                                "sl",
                                "sn",
                                "so",
                                "sq",
                                "sr",
                                "su",
                                "sv",
                                "sw",
                                "ta",
                                "te",
                                "tg",
                                "th",
                                "tk",
                                "tl",
                                "tr",
                                "tt",
                                "uk",
                                "ur",
                                "uz",
                                "vi",
                                "yi",
                                "yo",
                                "zh"
                              ])
                              .describe(
                                "Specify the language in which it will be pronounced when sound comparison occurs. Default to transcription language."
                              )
                              .describe("Spoken language in this utterance")
                          })
                        )
                        .describe("Transcribed speech utterances present in the audio")
                    })
                  )
                  .nullable()
                  .describe("List of translated transcriptions, one for each `target_languages`")
              })
              .optional()
              .describe(
                "If `translation` has been enabled, translation of the audio speech transcription"
              ),
            summarization: zod
              .object({
                success: zod
                  .boolean()
                  .describe("The audio intelligence model succeeded to get a valid output"),
                is_empty: zod
                  .boolean()
                  .describe("The audio intelligence model returned an empty value"),
                exec_time: zod
                  .number()
                  .describe("Time audio intelligence model took to complete the task"),
                error: zod
                  .object({
                    status_code: zod.number().describe("Status code of the addon error"),
                    exception: zod.string().describe("Reason of the addon error"),
                    message: zod.string().describe("Detailed message of the addon error")
                  })
                  .nullable()
                  .describe(
                    "`null` if `success` is `true`. Contains the error details of the failed model"
                  ),
                results: zod
                  .string()
                  .nullable()
                  .describe("If `summarization` has been enabled, summary of the transcription")
              })
              .optional()
              .describe(
                "If `summarization` has been enabled, summarization of the audio speech transcription"
              ),
            moderation: zod
              .object({
                success: zod
                  .boolean()
                  .describe("The audio intelligence model succeeded to get a valid output"),
                is_empty: zod
                  .boolean()
                  .describe("The audio intelligence model returned an empty value"),
                exec_time: zod
                  .number()
                  .describe("Time audio intelligence model took to complete the task"),
                error: zod
                  .object({
                    status_code: zod.number().describe("Status code of the addon error"),
                    exception: zod.string().describe("Reason of the addon error"),
                    message: zod.string().describe("Detailed message of the addon error")
                  })
                  .nullable()
                  .describe(
                    "`null` if `success` is `true`. Contains the error details of the failed model"
                  ),
                results: zod
                  .string()
                  .nullable()
                  .describe("If `moderation` has been enabled, moderated transcription")
              })
              .optional()
              .describe(
                "If `moderation` has been enabled, moderation of the audio speech transcription"
              ),
            named_entity_recognition: zod
              .object({
                success: zod
                  .boolean()
                  .describe("The audio intelligence model succeeded to get a valid output"),
                is_empty: zod
                  .boolean()
                  .describe("The audio intelligence model returned an empty value"),
                exec_time: zod
                  .number()
                  .describe("Time audio intelligence model took to complete the task"),
                error: zod
                  .object({
                    status_code: zod.number().describe("Status code of the addon error"),
                    exception: zod.string().describe("Reason of the addon error"),
                    message: zod.string().describe("Detailed message of the addon error")
                  })
                  .nullable()
                  .describe(
                    "`null` if `success` is `true`. Contains the error details of the failed model"
                  ),
                entity: zod
                  .string()
                  .describe(
                    "If `named_entity_recognition` has been enabled, the detected entities."
                  )
              })
              .optional()
              .describe("If `named_entity_recognition` has been enabled, the detected entities"),
            name_consistency: zod
              .object({
                success: zod
                  .boolean()
                  .describe("The audio intelligence model succeeded to get a valid output"),
                is_empty: zod
                  .boolean()
                  .describe("The audio intelligence model returned an empty value"),
                exec_time: zod
                  .number()
                  .describe("Time audio intelligence model took to complete the task"),
                error: zod
                  .object({
                    status_code: zod.number().describe("Status code of the addon error"),
                    exception: zod.string().describe("Reason of the addon error"),
                    message: zod.string().describe("Detailed message of the addon error")
                  })
                  .nullable()
                  .describe(
                    "`null` if `success` is `true`. Contains the error details of the failed model"
                  ),
                results: zod
                  .string()
                  .describe(
                    "If `name_consistency` has been enabled, Gladia will improve the consistency of the names across the transcription"
                  )
              })
              .optional()
              .describe(
                "If `name_consistency` has been enabled, Gladia will improve consistency of the names accross the transcription"
              ),
            speaker_reidentification: zod
              .object({
                success: zod
                  .boolean()
                  .describe("The audio intelligence model succeeded to get a valid output"),
                is_empty: zod
                  .boolean()
                  .describe("The audio intelligence model returned an empty value"),
                exec_time: zod
                  .number()
                  .describe("Time audio intelligence model took to complete the task"),
                error: zod
                  .object({
                    status_code: zod.number().describe("Status code of the addon error"),
                    exception: zod.string().describe("Reason of the addon error"),
                    message: zod.string().describe("Detailed message of the addon error")
                  })
                  .nullable()
                  .describe(
                    "`null` if `success` is `true`. Contains the error details of the failed model"
                  ),
                results: zod
                  .string()
                  .describe(
                    "If `speaker_reidentification` has been enabled, results of the AI speaker reidentification."
                  )
              })
              .optional()
              .describe(
                "If `speaker_reidentification` has been enabled, results of the AI speaker reidentification."
              ),
            structured_data_extraction: zod
              .object({
                success: zod
                  .boolean()
                  .describe("The audio intelligence model succeeded to get a valid output"),
                is_empty: zod
                  .boolean()
                  .describe("The audio intelligence model returned an empty value"),
                exec_time: zod
                  .number()
                  .describe("Time audio intelligence model took to complete the task"),
                error: zod
                  .object({
                    status_code: zod.number().describe("Status code of the addon error"),
                    exception: zod.string().describe("Reason of the addon error"),
                    message: zod.string().describe("Detailed message of the addon error")
                  })
                  .nullable()
                  .describe(
                    "`null` if `success` is `true`. Contains the error details of the failed model"
                  ),
                results: zod
                  .string()
                  .describe(
                    "If `structured_data_extraction` has been enabled, results of the AI structured data extraction for the defined classes."
                  )
              })
              .optional()
              .describe(
                "If `structured_data_extraction` has been enabled, structured data extraction results"
              ),
            sentiment_analysis: zod
              .object({
                success: zod
                  .boolean()
                  .describe("The audio intelligence model succeeded to get a valid output"),
                is_empty: zod
                  .boolean()
                  .describe("The audio intelligence model returned an empty value"),
                exec_time: zod
                  .number()
                  .describe("Time audio intelligence model took to complete the task"),
                error: zod
                  .object({
                    status_code: zod.number().describe("Status code of the addon error"),
                    exception: zod.string().describe("Reason of the addon error"),
                    message: zod.string().describe("Detailed message of the addon error")
                  })
                  .nullable()
                  .describe(
                    "`null` if `success` is `true`. Contains the error details of the failed model"
                  ),
                results: zod
                  .string()
                  .describe(
                    "If `sentiment_analysis` has been enabled, Gladia will analyze the sentiments and emotions of the audio"
                  )
              })
              .optional()
              .describe(
                "If `sentiment_analysis` has been enabled, sentiment analysis of the audio speech transcription"
              ),
            audio_to_llm: zod
              .object({
                success: zod
                  .boolean()
                  .describe("The audio intelligence model succeeded to get a valid output"),
                is_empty: zod
                  .boolean()
                  .describe("The audio intelligence model returned an empty value"),
                exec_time: zod
                  .number()
                  .describe("Time audio intelligence model took to complete the task"),
                error: zod
                  .object({
                    status_code: zod.number().describe("Status code of the addon error"),
                    exception: zod.string().describe("Reason of the addon error"),
                    message: zod.string().describe("Detailed message of the addon error")
                  })
                  .nullable()
                  .describe(
                    "`null` if `success` is `true`. Contains the error details of the failed model"
                  ),
                results: zod
                  .array(
                    zod.object({
                      success: zod
                        .boolean()
                        .describe("The audio intelligence model succeeded to get a valid output"),
                      is_empty: zod
                        .boolean()
                        .describe("The audio intelligence model returned an empty value"),
                      exec_time: zod
                        .number()
                        .describe("Time audio intelligence model took to complete the task"),
                      error: zod
                        .object({
                          status_code: zod.number().describe("Status code of the addon error"),
                          exception: zod.string().describe("Reason of the addon error"),
                          message: zod.string().describe("Detailed message of the addon error")
                        })
                        .nullable()
                        .describe(
                          "`null` if `success` is `true`. Contains the error details of the failed model"
                        ),
                      results: zod
                        .object({
                          prompt: zod.string().nullable().describe("The prompt used"),
                          response: zod
                            .string()
                            .nullable()
                            .describe("The result of the AI analysis")
                        })
                        .nullable()
                        .describe("The result from a specific prompt")
                    })
                  )
                  .nullable()
                  .describe("If `audio_to_llm` has been enabled, results of the AI custom analysis")
              })
              .optional()
              .describe(
                "If `audio_to_llm` has been enabled, audio to llm results of the audio speech transcription"
              ),
            sentences: zod
              .object({
                success: zod
                  .boolean()
                  .describe("The audio intelligence model succeeded to get a valid output"),
                is_empty: zod
                  .boolean()
                  .describe("The audio intelligence model returned an empty value"),
                exec_time: zod
                  .number()
                  .describe("Time audio intelligence model took to complete the task"),
                error: zod
                  .object({
                    status_code: zod.number().describe("Status code of the addon error"),
                    exception: zod.string().describe("Reason of the addon error"),
                    message: zod.string().describe("Detailed message of the addon error")
                  })
                  .nullable()
                  .describe(
                    "`null` if `success` is `true`. Contains the error details of the failed model"
                  ),
                results: zod
                  .array(zod.string())
                  .nullable()
                  .describe("If `sentences` has been enabled, transcription as sentences.")
              })
              .optional()
              .describe(
                "If `sentences` has been enabled, sentences of the audio speech transcription. Deprecated: content will move to the `transcription` object."
              ),
            display_mode: zod
              .object({
                success: zod
                  .boolean()
                  .describe("The audio intelligence model succeeded to get a valid output"),
                is_empty: zod
                  .boolean()
                  .describe("The audio intelligence model returned an empty value"),
                exec_time: zod
                  .number()
                  .describe("Time audio intelligence model took to complete the task"),
                error: zod
                  .object({
                    status_code: zod.number().describe("Status code of the addon error"),
                    exception: zod.string().describe("Reason of the addon error"),
                    message: zod.string().describe("Detailed message of the addon error")
                  })
                  .nullable()
                  .describe(
                    "`null` if `success` is `true`. Contains the error details of the failed model"
                  ),
                results: zod
                  .array(zod.string())
                  .nullable()
                  .describe(
                    "If `display_mode` has been enabled, proposes an alternative display output."
                  )
              })
              .optional()
              .describe(
                "If `display_mode` has been enabled, the output will be reordered, creating new utterances when speakers overlapped"
              ),
            chapterization: zod
              .object({
                success: zod
                  .boolean()
                  .describe("The audio intelligence model succeeded to get a valid output"),
                is_empty: zod
                  .boolean()
                  .describe("The audio intelligence model returned an empty value"),
                exec_time: zod
                  .number()
                  .describe("Time audio intelligence model took to complete the task"),
                error: zod
                  .object({
                    status_code: zod.number().describe("Status code of the addon error"),
                    exception: zod.string().describe("Reason of the addon error"),
                    message: zod.string().describe("Detailed message of the addon error")
                  })
                  .nullable()
                  .describe(
                    "`null` if `success` is `true`. Contains the error details of the failed model"
                  ),
                results: zod
                  .record(zod.string(), zod.any())
                  .describe(
                    "If `chapterization` has been enabled, will generate chapters name for different parts of the given audio."
                  )
              })
              .optional()
              .describe(
                "If `chapterization` has been enabled, will generate chapters name for different parts of the given audio."
              ),
            diarization: zod
              .object({
                success: zod
                  .boolean()
                  .describe("The audio intelligence model succeeded to get a valid output"),
                is_empty: zod
                  .boolean()
                  .describe("The audio intelligence model returned an empty value"),
                exec_time: zod
                  .number()
                  .describe("Time audio intelligence model took to complete the task"),
                error: zod
                  .object({
                    status_code: zod.number().describe("Status code of the addon error"),
                    exception: zod.string().describe("Reason of the addon error"),
                    message: zod.string().describe("Detailed message of the addon error")
                  })
                  .nullable()
                  .describe(
                    "`null` if `success` is `true`. Contains the error details of the failed model"
                  ),
                results: zod
                  .array(
                    zod.object({
                      start: zod.number().describe("Start timestamp in seconds of this utterance"),
                      end: zod.number().describe("End timestamp in seconds of this utterance"),
                      confidence: zod
                        .number()
                        .describe("Confidence on the transcribed utterance (1 = 100% confident)"),
                      channel: zod
                        .number()
                        .min(
                          preRecordedControllerGetPreRecordedJobsV2ResponseItemsItemResultDiarizationResultsItemChannelMin
                        )
                        .describe(
                          "Audio channel of where this utterance has been transcribed from"
                        ),
                      speaker: zod
                        .number()
                        .min(
                          preRecordedControllerGetPreRecordedJobsV2ResponseItemsItemResultDiarizationResultsItemSpeakerMin
                        )
                        .optional()
                        .describe("If `diarization` enabled, speaker identification number"),
                      words: zod
                        .array(
                          zod.object({
                            word: zod.string().describe("Spoken word"),
                            start: zod
                              .number()
                              .describe("Start timestamps in seconds of the spoken word"),
                            end: zod
                              .number()
                              .describe("End timestamps in seconds of the spoken word"),
                            confidence: zod
                              .number()
                              .describe("Confidence on the transcribed word (1 = 100% confident)")
                          })
                        )
                        .describe("List of words of the utterance, split by timestamp"),
                      text: zod.string().describe("Transcription for this utterance"),
                      language: zod
                        .enum([
                          "af",
                          "am",
                          "ar",
                          "as",
                          "az",
                          "ba",
                          "be",
                          "bg",
                          "bn",
                          "bo",
                          "br",
                          "bs",
                          "ca",
                          "cs",
                          "cy",
                          "da",
                          "de",
                          "el",
                          "en",
                          "es",
                          "et",
                          "eu",
                          "fa",
                          "fi",
                          "fo",
                          "fr",
                          "gl",
                          "gu",
                          "ha",
                          "haw",
                          "he",
                          "hi",
                          "hr",
                          "ht",
                          "hu",
                          "hy",
                          "id",
                          "is",
                          "it",
                          "ja",
                          "jw",
                          "ka",
                          "kk",
                          "km",
                          "kn",
                          "ko",
                          "la",
                          "lb",
                          "ln",
                          "lo",
                          "lt",
                          "lv",
                          "mg",
                          "mi",
                          "mk",
                          "ml",
                          "mn",
                          "mr",
                          "ms",
                          "mt",
                          "my",
                          "ne",
                          "nl",
                          "nn",
                          "no",
                          "oc",
                          "pa",
                          "pl",
                          "ps",
                          "pt",
                          "ro",
                          "ru",
                          "sa",
                          "sd",
                          "si",
                          "sk",
                          "sl",
                          "sn",
                          "so",
                          "sq",
                          "sr",
                          "su",
                          "sv",
                          "sw",
                          "ta",
                          "te",
                          "tg",
                          "th",
                          "tk",
                          "tl",
                          "tr",
                          "tt",
                          "uk",
                          "ur",
                          "uz",
                          "vi",
                          "yi",
                          "yo",
                          "zh"
                        ])
                        .describe(
                          "Specify the language in which it will be pronounced when sound comparison occurs. Default to transcription language."
                        )
                        .describe("Spoken language in this utterance")
                    })
                  )
                  .describe(
                    "[Deprecated] If `diarization` has been enabled, the diarization result will appear here"
                  )
              })
              .optional()
              .describe(
                "If `diarization` has been requested and an error has occurred, the result will appear here"
              )
          })
          .nullish()
          .describe('Pre-recorded transcription\'s result when status is \"done\"')
      })
    )
    .describe("List of pre-recorded transcriptions")
})

/**
 * @summary Get the pre recorded job's metadata
 */
export const preRecordedControllerGetPreRecordedJobV2Params = zod.object({
  id: zod.string().describe("Id of the pre recorded job")
})

export const preRecordedControllerGetPreRecordedJobV2ResponseErrorCodeMin = 400

export const preRecordedControllerGetPreRecordedJobV2ResponseErrorCodeMax = 599
export const preRecordedControllerGetPreRecordedJobV2ResponseKindDefault = "pre-recorded"
export const preRecordedControllerGetPreRecordedJobV2ResponseRequestParamsCustomVocabularyDefault = false
export const preRecordedControllerGetPreRecordedJobV2ResponseRequestParamsCustomVocabularyConfigVocabularyItemIntensityMin = 0

export const preRecordedControllerGetPreRecordedJobV2ResponseRequestParamsCustomVocabularyConfigVocabularyItemIntensityMax = 1
export const preRecordedControllerGetPreRecordedJobV2ResponseRequestParamsCustomVocabularyConfigDefaultIntensityMin = 0

export const preRecordedControllerGetPreRecordedJobV2ResponseRequestParamsCustomVocabularyConfigDefaultIntensityMax = 1
export const preRecordedControllerGetPreRecordedJobV2ResponseRequestParamsDetectLanguageDefault = true
export const preRecordedControllerGetPreRecordedJobV2ResponseRequestParamsEnableCodeSwitchingDefault = false
export const preRecordedControllerGetPreRecordedJobV2ResponseRequestParamsCodeSwitchingConfigLanguagesDefault =
  []
export const preRecordedControllerGetPreRecordedJobV2ResponseRequestParamsCallbackDefault = false
export const preRecordedControllerGetPreRecordedJobV2ResponseRequestParamsCallbackConfigMethodDefault =
  "POST"
export const preRecordedControllerGetPreRecordedJobV2ResponseRequestParamsSubtitlesDefault = false
export const preRecordedControllerGetPreRecordedJobV2ResponseRequestParamsSubtitlesConfigFormatsDefault: string[] =
  ["srt"]
export const preRecordedControllerGetPreRecordedJobV2ResponseRequestParamsSubtitlesConfigMinimumDurationMin = 0
export const preRecordedControllerGetPreRecordedJobV2ResponseRequestParamsSubtitlesConfigMaximumDurationMax = 30
export const preRecordedControllerGetPreRecordedJobV2ResponseRequestParamsSubtitlesConfigMaximumRowsPerCaptionMax = 5
export const preRecordedControllerGetPreRecordedJobV2ResponseRequestParamsSubtitlesConfigStyleDefault =
  "default"
export const preRecordedControllerGetPreRecordedJobV2ResponseRequestParamsDiarizationDefault = false
export const preRecordedControllerGetPreRecordedJobV2ResponseRequestParamsDiarizationConfigMinSpeakersMin = 0
export const preRecordedControllerGetPreRecordedJobV2ResponseRequestParamsDiarizationConfigMaxSpeakersMin = 0
export const preRecordedControllerGetPreRecordedJobV2ResponseRequestParamsTranslationDefault = false
export const preRecordedControllerGetPreRecordedJobV2ResponseRequestParamsTranslationConfigModelDefault =
  "base"
export const preRecordedControllerGetPreRecordedJobV2ResponseRequestParamsTranslationConfigMatchOriginalUtterancesDefault = true
export const preRecordedControllerGetPreRecordedJobV2ResponseRequestParamsTranslationConfigLipsyncDefault = true
export const preRecordedControllerGetPreRecordedJobV2ResponseRequestParamsTranslationConfigContextAdaptationDefault = true
export const preRecordedControllerGetPreRecordedJobV2ResponseRequestParamsTranslationConfigInformalDefault = false
export const preRecordedControllerGetPreRecordedJobV2ResponseRequestParamsSummarizationDefault = false
export const preRecordedControllerGetPreRecordedJobV2ResponseRequestParamsSummarizationConfigTypeDefault =
  "general"
export const preRecordedControllerGetPreRecordedJobV2ResponseRequestParamsModerationDefault = false
export const preRecordedControllerGetPreRecordedJobV2ResponseRequestParamsNamedEntityRecognitionDefault = false
export const preRecordedControllerGetPreRecordedJobV2ResponseRequestParamsChapterizationDefault = false
export const preRecordedControllerGetPreRecordedJobV2ResponseRequestParamsNameConsistencyDefault = false
export const preRecordedControllerGetPreRecordedJobV2ResponseRequestParamsCustomSpellingDefault = false
export const preRecordedControllerGetPreRecordedJobV2ResponseRequestParamsStructuredDataExtractionDefault = false
export const preRecordedControllerGetPreRecordedJobV2ResponseRequestParamsSentimentAnalysisDefault = false
export const preRecordedControllerGetPreRecordedJobV2ResponseRequestParamsAudioToLlmDefault = false
export const preRecordedControllerGetPreRecordedJobV2ResponseRequestParamsSentencesDefault = false
export const preRecordedControllerGetPreRecordedJobV2ResponseRequestParamsDisplayModeDefault = false
export const preRecordedControllerGetPreRecordedJobV2ResponseRequestParamsPunctuationEnhancedDefault = false
export const preRecordedControllerGetPreRecordedJobV2ResponseRequestParamsLanguageConfigLanguagesDefault =
  []
export const preRecordedControllerGetPreRecordedJobV2ResponseRequestParamsLanguageConfigCodeSwitchingDefault = false
export const preRecordedControllerGetPreRecordedJobV2ResponseResultTranscriptionUtterancesItemChannelMin = 0
export const preRecordedControllerGetPreRecordedJobV2ResponseResultTranscriptionUtterancesItemSpeakerMin = 0
export const preRecordedControllerGetPreRecordedJobV2ResponseResultTranslationResultsItemUtterancesItemChannelMin = 0
export const preRecordedControllerGetPreRecordedJobV2ResponseResultTranslationResultsItemUtterancesItemSpeakerMin = 0
export const preRecordedControllerGetPreRecordedJobV2ResponseResultDiarizationResultsItemChannelMin = 0
export const preRecordedControllerGetPreRecordedJobV2ResponseResultDiarizationResultsItemSpeakerMin = 0

export const preRecordedControllerGetPreRecordedJobV2Response = zod.object({
  id: zod.string().uuid().describe("Id of the job"),
  request_id: zod.string().describe("Debug id"),
  version: zod.number().describe("API version"),
  status: zod
    .enum(["queued", "processing", "done", "error"])
    .describe(
      '\"queued\": the job has been queued. \"processing\": the job is being processed. \"done\": the job has been processed and the result is available. \"error\": an error occurred during the job\'s processing.'
    ),
  created_at: zod.string().datetime({}).describe("Creation date"),
  completed_at: zod
    .string()
    .datetime({})
    .nullish()
    .describe('Completion date when status is \"done\" or \"error\"'),
  custom_metadata: zod
    .record(zod.string(), zod.any())
    .optional()
    .describe("Custom metadata given in the initial request"),
  error_code: zod
    .number()
    .min(preRecordedControllerGetPreRecordedJobV2ResponseErrorCodeMin)
    .max(preRecordedControllerGetPreRecordedJobV2ResponseErrorCodeMax)
    .nullish()
    .describe('HTTP status code of the error if status is \"error\"'),
  post_session_metadata: zod
    .object({})
    .describe("For debugging purposes, send data that could help to identify issues"),
  kind: zod.enum(["pre-recorded"]),
  file: zod
    .object({
      id: zod.string().describe("The file id"),
      filename: zod.string().nullable().describe("The name of the uploaded file"),
      source: zod
        .string()
        .nullable()
        .describe("The link used to download the file if audio_url was used"),
      audio_duration: zod.number().nullable().describe("Duration of the audio file"),
      number_of_channels: zod
        .number()
        .min(1)
        .nullable()
        .describe("Number of channels in the audio file")
    })
    .nullish()
    .describe('The file data you uploaded. Can be null if status is \"error\"'),
  request_params: zod
    .object({
      context_prompt: zod
        .string()
        .optional()
        .describe(
          "**[Deprecated]** Context to feed the transcription model with for possible better accuracy"
        ),
      custom_vocabulary: zod
        .boolean()
        .optional()
        .describe(
          "**[Beta]** Can be either boolean to enable custom_vocabulary for this audio or an array with specific vocabulary list to feed the transcription model with"
        ),
      custom_vocabulary_config: zod
        .object({
          vocabulary: zod
            .array(
              zod
                .object({
                  value: zod.string().describe("The text used to replace in the transcription."),
                  intensity: zod
                    .number()
                    .min(
                      preRecordedControllerGetPreRecordedJobV2ResponseRequestParamsCustomVocabularyConfigVocabularyItemIntensityMin
                    )
                    .max(
                      preRecordedControllerGetPreRecordedJobV2ResponseRequestParamsCustomVocabularyConfigVocabularyItemIntensityMax
                    )
                    .optional()
                    .describe("The global intensity of the feature."),
                  pronunciations: zod
                    .array(zod.string())
                    .optional()
                    .describe("The pronunciations used in the transcription."),
                  language: zod
                    .enum([
                      "af",
                      "am",
                      "ar",
                      "as",
                      "az",
                      "ba",
                      "be",
                      "bg",
                      "bn",
                      "bo",
                      "br",
                      "bs",
                      "ca",
                      "cs",
                      "cy",
                      "da",
                      "de",
                      "el",
                      "en",
                      "es",
                      "et",
                      "eu",
                      "fa",
                      "fi",
                      "fo",
                      "fr",
                      "gl",
                      "gu",
                      "ha",
                      "haw",
                      "he",
                      "hi",
                      "hr",
                      "ht",
                      "hu",
                      "hy",
                      "id",
                      "is",
                      "it",
                      "ja",
                      "jw",
                      "ka",
                      "kk",
                      "km",
                      "kn",
                      "ko",
                      "la",
                      "lb",
                      "ln",
                      "lo",
                      "lt",
                      "lv",
                      "mg",
                      "mi",
                      "mk",
                      "ml",
                      "mn",
                      "mr",
                      "ms",
                      "mt",
                      "my",
                      "ne",
                      "nl",
                      "nn",
                      "no",
                      "oc",
                      "pa",
                      "pl",
                      "ps",
                      "pt",
                      "ro",
                      "ru",
                      "sa",
                      "sd",
                      "si",
                      "sk",
                      "sl",
                      "sn",
                      "so",
                      "sq",
                      "sr",
                      "su",
                      "sv",
                      "sw",
                      "ta",
                      "te",
                      "tg",
                      "th",
                      "tk",
                      "tl",
                      "tr",
                      "tt",
                      "uk",
                      "ur",
                      "uz",
                      "vi",
                      "yi",
                      "yo",
                      "zh"
                    ])
                    .describe(
                      "Specify the language in which it will be pronounced when sound comparison occurs. Default to transcription language."
                    )
                    .optional()
                    .describe(
                      "Specify the language in which it will be pronounced when sound comparison occurs. Default to transcription language."
                    )
                })
                .or(zod.string())
            )
            .describe(
              "Specific vocabulary list to feed the transcription model with. Each item can be a string or an object with the following properties: value, intensity, pronunciations, language."
            ),
          default_intensity: zod
            .number()
            .min(
              preRecordedControllerGetPreRecordedJobV2ResponseRequestParamsCustomVocabularyConfigDefaultIntensityMin
            )
            .max(
              preRecordedControllerGetPreRecordedJobV2ResponseRequestParamsCustomVocabularyConfigDefaultIntensityMax
            )
            .optional()
            .describe("Default intensity for the custom vocabulary")
        })
        .optional()
        .describe("**[Beta]** Custom vocabulary configuration, if `custom_vocabulary` is enabled"),
      detect_language: zod
        .boolean()
        .default(preRecordedControllerGetPreRecordedJobV2ResponseRequestParamsDetectLanguageDefault)
        .describe(
          "**[Deprecated]** Use `language_config` instead. Detect the language from the given audio"
        ),
      enable_code_switching: zod
        .boolean()
        .optional()
        .describe(
          "**[Deprecated]** Use `language_config` instead.Detect multiple languages in the given audio"
        ),
      code_switching_config: zod
        .object({
          languages: zod
            .array(
              zod
                .enum([
                  "af",
                  "am",
                  "ar",
                  "as",
                  "az",
                  "ba",
                  "be",
                  "bg",
                  "bn",
                  "bo",
                  "br",
                  "bs",
                  "ca",
                  "cs",
                  "cy",
                  "da",
                  "de",
                  "el",
                  "en",
                  "es",
                  "et",
                  "eu",
                  "fa",
                  "fi",
                  "fo",
                  "fr",
                  "gl",
                  "gu",
                  "ha",
                  "haw",
                  "he",
                  "hi",
                  "hr",
                  "ht",
                  "hu",
                  "hy",
                  "id",
                  "is",
                  "it",
                  "ja",
                  "jw",
                  "ka",
                  "kk",
                  "km",
                  "kn",
                  "ko",
                  "la",
                  "lb",
                  "ln",
                  "lo",
                  "lt",
                  "lv",
                  "mg",
                  "mi",
                  "mk",
                  "ml",
                  "mn",
                  "mr",
                  "ms",
                  "mt",
                  "my",
                  "ne",
                  "nl",
                  "nn",
                  "no",
                  "oc",
                  "pa",
                  "pl",
                  "ps",
                  "pt",
                  "ro",
                  "ru",
                  "sa",
                  "sd",
                  "si",
                  "sk",
                  "sl",
                  "sn",
                  "so",
                  "sq",
                  "sr",
                  "su",
                  "sv",
                  "sw",
                  "ta",
                  "te",
                  "tg",
                  "th",
                  "tk",
                  "tl",
                  "tr",
                  "tt",
                  "uk",
                  "ur",
                  "uz",
                  "vi",
                  "yi",
                  "yo",
                  "zh"
                ])
                .describe(
                  "Specify the language in which it will be pronounced when sound comparison occurs. Default to transcription language."
                )
            )
            .default(
              preRecordedControllerGetPreRecordedJobV2ResponseRequestParamsCodeSwitchingConfigLanguagesDefault
            )
            .describe("Specify the languages you want to use when detecting multiple languages")
        })
        .optional()
        .describe(
          "**[Deprecated]** Use `language_config` instead. Specify the configuration for code switching"
        ),
      language: zod
        .enum([
          "af",
          "am",
          "ar",
          "as",
          "az",
          "ba",
          "be",
          "bg",
          "bn",
          "bo",
          "br",
          "bs",
          "ca",
          "cs",
          "cy",
          "da",
          "de",
          "el",
          "en",
          "es",
          "et",
          "eu",
          "fa",
          "fi",
          "fo",
          "fr",
          "gl",
          "gu",
          "ha",
          "haw",
          "he",
          "hi",
          "hr",
          "ht",
          "hu",
          "hy",
          "id",
          "is",
          "it",
          "ja",
          "jw",
          "ka",
          "kk",
          "km",
          "kn",
          "ko",
          "la",
          "lb",
          "ln",
          "lo",
          "lt",
          "lv",
          "mg",
          "mi",
          "mk",
          "ml",
          "mn",
          "mr",
          "ms",
          "mt",
          "my",
          "ne",
          "nl",
          "nn",
          "no",
          "oc",
          "pa",
          "pl",
          "ps",
          "pt",
          "ro",
          "ru",
          "sa",
          "sd",
          "si",
          "sk",
          "sl",
          "sn",
          "so",
          "sq",
          "sr",
          "su",
          "sv",
          "sw",
          "ta",
          "te",
          "tg",
          "th",
          "tk",
          "tl",
          "tr",
          "tt",
          "uk",
          "ur",
          "uz",
          "vi",
          "yi",
          "yo",
          "zh"
        ])
        .describe(
          "Specify the language in which it will be pronounced when sound comparison occurs. Default to transcription language."
        )
        .optional()
        .describe(
          "**[Deprecated]** Use `language_config` instead. Set the spoken language for the given audio (ISO 639 standard)"
        ),
      callback_url: zod
        .string()
        .url()
        .optional()
        .describe(
          "**[Deprecated]** Use `callback`/`callback_config` instead. Callback URL we will do a `POST` request to with the result of the transcription"
        ),
      callback: zod
        .boolean()
        .optional()
        .describe(
          "Enable callback for this transcription. If true, the `callback_config` property will be used to customize the callback behaviour"
        ),
      callback_config: zod
        .object({
          url: zod
            .string()
            .url()
            .describe("The URL to be called with the result of the transcription"),
          method: zod
            .enum(["POST", "PUT"])
            .describe(
              "The HTTP method to be used. Allowed values are `POST` or `PUT` (default: `POST`)"
            )
            .default(
              preRecordedControllerGetPreRecordedJobV2ResponseRequestParamsCallbackConfigMethodDefault
            )
            .describe(
              "The HTTP method to be used. Allowed values are `POST` or `PUT` (default: `POST`)"
            )
        })
        .optional()
        .describe("Customize the callback behaviour (url and http method)"),
      subtitles: zod
        .boolean()
        .optional()
        .describe("Enable subtitles generation for this transcription"),
      subtitles_config: zod
        .object({
          formats: zod
            .array(
              zod
                .enum(["srt", "vtt"])
                .describe("Subtitles formats you want your transcription to be formatted to")
            )
            .min(1)
            .default(
              preRecordedControllerGetPreRecordedJobV2ResponseRequestParamsSubtitlesConfigFormatsDefault
            )
            .describe("Subtitles formats you want your transcription to be formatted to"),
          minimum_duration: zod
            .number()
            .min(
              preRecordedControllerGetPreRecordedJobV2ResponseRequestParamsSubtitlesConfigMinimumDurationMin
            )
            .optional()
            .describe("Minimum duration of a subtitle in seconds"),
          maximum_duration: zod
            .number()
            .min(1)
            .max(
              preRecordedControllerGetPreRecordedJobV2ResponseRequestParamsSubtitlesConfigMaximumDurationMax
            )
            .optional()
            .describe("Maximum duration of a subtitle in seconds"),
          maximum_characters_per_row: zod
            .number()
            .min(1)
            .optional()
            .describe("Maximum number of characters per row in a subtitle"),
          maximum_rows_per_caption: zod
            .number()
            .min(1)
            .max(
              preRecordedControllerGetPreRecordedJobV2ResponseRequestParamsSubtitlesConfigMaximumRowsPerCaptionMax
            )
            .optional()
            .describe("Maximum number of rows per caption"),
          style: zod
            .enum(["default", "compliance"])
            .describe(
              "Style of the subtitles. Compliance mode refers to : https://loc.gov/preservation/digital/formats//fdd/fdd000569.shtml#:~:text=SRT%20files%20are%20basic%20text,alongside%2C%20example%3A%20%22MyVideo123 "
            )
            .default(
              preRecordedControllerGetPreRecordedJobV2ResponseRequestParamsSubtitlesConfigStyleDefault
            )
            .describe(
              "Style of the subtitles. Compliance mode refers to : https://loc.gov/preservation/digital/formats//fdd/fdd000569.shtml#:~:text=SRT%20files%20are%20basic%20text,alongside%2C%20example%3A%20%22MyVideo123 "
            )
        })
        .optional()
        .describe("Configuration for subtitles generation if `subtitles` is enabled"),
      diarization: zod
        .boolean()
        .optional()
        .describe("Enable speaker recognition (diarization) for this audio"),
      diarization_config: zod
        .object({
          number_of_speakers: zod
            .number()
            .min(1)
            .optional()
            .describe("Exact number of speakers in the audio"),
          min_speakers: zod
            .number()
            .min(
              preRecordedControllerGetPreRecordedJobV2ResponseRequestParamsDiarizationConfigMinSpeakersMin
            )
            .optional()
            .describe("Minimum number of speakers in the audio"),
          max_speakers: zod
            .number()
            .min(
              preRecordedControllerGetPreRecordedJobV2ResponseRequestParamsDiarizationConfigMaxSpeakersMin
            )
            .optional()
            .describe("Maximum number of speakers in the audio")
        })
        .optional()
        .describe("Speaker recognition configuration, if `diarization` is enabled"),
      translation: zod
        .boolean()
        .optional()
        .describe("**[Beta]** Enable translation for this audio"),
      translation_config: zod
        .object({
          target_languages: zod
            .array(
              zod
                .enum([
                  "af",
                  "am",
                  "ar",
                  "as",
                  "az",
                  "ba",
                  "be",
                  "bg",
                  "bn",
                  "bo",
                  "br",
                  "bs",
                  "ca",
                  "cs",
                  "cy",
                  "da",
                  "de",
                  "el",
                  "en",
                  "es",
                  "et",
                  "eu",
                  "fa",
                  "fi",
                  "fo",
                  "fr",
                  "gl",
                  "gu",
                  "ha",
                  "haw",
                  "he",
                  "hi",
                  "hr",
                  "ht",
                  "hu",
                  "hy",
                  "id",
                  "is",
                  "it",
                  "ja",
                  "jw",
                  "ka",
                  "kk",
                  "km",
                  "kn",
                  "ko",
                  "la",
                  "lb",
                  "ln",
                  "lo",
                  "lt",
                  "lv",
                  "mg",
                  "mi",
                  "mk",
                  "ml",
                  "mn",
                  "mr",
                  "ms",
                  "mt",
                  "my",
                  "ne",
                  "nl",
                  "nn",
                  "no",
                  "oc",
                  "pa",
                  "pl",
                  "ps",
                  "pt",
                  "ro",
                  "ru",
                  "sa",
                  "sd",
                  "si",
                  "sk",
                  "sl",
                  "sn",
                  "so",
                  "sq",
                  "sr",
                  "su",
                  "sv",
                  "sw",
                  "ta",
                  "te",
                  "tg",
                  "th",
                  "tk",
                  "tl",
                  "tr",
                  "tt",
                  "uk",
                  "ur",
                  "uz",
                  "vi",
                  "wo",
                  "yi",
                  "yo",
                  "zh"
                ])
                .describe(
                  "Target language in `iso639-1` format you want the transcription translated to"
                )
            )
            .min(1)
            .describe(
              "Target language in `iso639-1` format you want the transcription translated to"
            ),
          model: zod
            .enum(["base", "enhanced"])
            .describe("Model you want the translation model to use to translate")
            .default(
              preRecordedControllerGetPreRecordedJobV2ResponseRequestParamsTranslationConfigModelDefault
            )
            .describe("Model you want the translation model to use to translate"),
          match_original_utterances: zod
            .boolean()
            .default(
              preRecordedControllerGetPreRecordedJobV2ResponseRequestParamsTranslationConfigMatchOriginalUtterancesDefault
            )
            .describe("Align translated utterances with the original ones"),
          lipsync: zod
            .boolean()
            .default(
              preRecordedControllerGetPreRecordedJobV2ResponseRequestParamsTranslationConfigLipsyncDefault
            )
            .describe("Whether to apply lipsync to the translated transcription. "),
          context_adaptation: zod
            .boolean()
            .default(
              preRecordedControllerGetPreRecordedJobV2ResponseRequestParamsTranslationConfigContextAdaptationDefault
            )
            .describe(
              "Enables or disables context-aware translation features that allow the model to adapt translations based on provided context."
            ),
          context: zod
            .string()
            .optional()
            .describe("Context information to improve translation accuracy"),
          informal: zod
            .boolean()
            .optional()
            .describe(
              "Forces the translation to use informal language forms when available in the target language."
            )
        })
        .optional()
        .describe("**[Beta]** Translation configuration, if `translation` is enabled"),
      summarization: zod
        .boolean()
        .optional()
        .describe("**[Beta]** Enable summarization for this audio"),
      summarization_config: zod
        .object({
          type: zod
            .enum(["general", "bullet_points", "concise"])
            .describe("The type of summarization to apply")
            .default(
              preRecordedControllerGetPreRecordedJobV2ResponseRequestParamsSummarizationConfigTypeDefault
            )
            .describe("The type of summarization to apply")
        })
        .optional()
        .describe("**[Beta]** Summarization configuration, if `summarization` is enabled"),
      moderation: zod.boolean().optional().describe("**[Alpha]** Enable moderation for this audio"),
      named_entity_recognition: zod
        .boolean()
        .optional()
        .describe("**[Alpha]** Enable named entity recognition for this audio"),
      chapterization: zod
        .boolean()
        .optional()
        .describe("**[Alpha]** Enable chapterization for this audio"),
      name_consistency: zod
        .boolean()
        .optional()
        .describe("**[Alpha]** Enable names consistency for this audio"),
      custom_spelling: zod
        .boolean()
        .optional()
        .describe("**[Alpha]** Enable custom spelling for this audio"),
      custom_spelling_config: zod
        .object({
          spelling_dictionary: zod
            .record(zod.string(), zod.array(zod.string()))
            .describe("The list of spelling applied on the audio transcription")
        })
        .optional()
        .describe("**[Alpha]** Custom spelling configuration, if `custom_spelling` is enabled"),
      structured_data_extraction: zod
        .boolean()
        .optional()
        .describe("**[Alpha]** Enable structured data extraction for this audio"),
      structured_data_extraction_config: zod
        .object({
          classes: zod
            .array(zod.array(zod.unknown()))
            .min(1)
            .describe("The list of classes to extract from the audio transcription")
        })
        .optional()
        .describe(
          "**[Alpha]** Structured data extraction configuration, if `structured_data_extraction` is enabled"
        ),
      sentiment_analysis: zod
        .boolean()
        .optional()
        .describe("Enable sentiment analysis for this audio"),
      audio_to_llm: zod
        .boolean()
        .optional()
        .describe("**[Alpha]** Enable audio to llm processing for this audio"),
      audio_to_llm_config: zod
        .object({
          prompts: zod
            .array(zod.array(zod.unknown()))
            .min(1)
            .describe("The list of prompts applied on the audio transcription")
        })
        .optional()
        .describe("**[Alpha]** Audio to llm configuration, if `audio_to_llm` is enabled"),
      sentences: zod.boolean().optional().describe("Enable sentences for this audio"),
      display_mode: zod
        .boolean()
        .optional()
        .describe(
          "**[Alpha]** Allows to change the output display_mode for this audio. The output will be reordered, creating new utterances when speakers overlapped"
        ),
      punctuation_enhanced: zod
        .boolean()
        .optional()
        .describe("**[Alpha]** Use enhanced punctuation for this audio"),
      language_config: zod
        .object({
          languages: zod
            .array(
              zod
                .enum([
                  "af",
                  "am",
                  "ar",
                  "as",
                  "az",
                  "ba",
                  "be",
                  "bg",
                  "bn",
                  "bo",
                  "br",
                  "bs",
                  "ca",
                  "cs",
                  "cy",
                  "da",
                  "de",
                  "el",
                  "en",
                  "es",
                  "et",
                  "eu",
                  "fa",
                  "fi",
                  "fo",
                  "fr",
                  "gl",
                  "gu",
                  "ha",
                  "haw",
                  "he",
                  "hi",
                  "hr",
                  "ht",
                  "hu",
                  "hy",
                  "id",
                  "is",
                  "it",
                  "ja",
                  "jw",
                  "ka",
                  "kk",
                  "km",
                  "kn",
                  "ko",
                  "la",
                  "lb",
                  "ln",
                  "lo",
                  "lt",
                  "lv",
                  "mg",
                  "mi",
                  "mk",
                  "ml",
                  "mn",
                  "mr",
                  "ms",
                  "mt",
                  "my",
                  "ne",
                  "nl",
                  "nn",
                  "no",
                  "oc",
                  "pa",
                  "pl",
                  "ps",
                  "pt",
                  "ro",
                  "ru",
                  "sa",
                  "sd",
                  "si",
                  "sk",
                  "sl",
                  "sn",
                  "so",
                  "sq",
                  "sr",
                  "su",
                  "sv",
                  "sw",
                  "ta",
                  "te",
                  "tg",
                  "th",
                  "tk",
                  "tl",
                  "tr",
                  "tt",
                  "uk",
                  "ur",
                  "uz",
                  "vi",
                  "yi",
                  "yo",
                  "zh"
                ])
                .describe(
                  "Specify the language in which it will be pronounced when sound comparison occurs. Default to transcription language."
                )
            )
            .default(
              preRecordedControllerGetPreRecordedJobV2ResponseRequestParamsLanguageConfigLanguagesDefault
            )
            .describe(
              "If one language is set, it will be used for the transcription. Otherwise, language will be auto-detected by the model."
            ),
          code_switching: zod
            .boolean()
            .optional()
            .describe(
              "If true, language will be auto-detected on each utterance. Otherwise, language will be auto-detected on first utterance and then used for the rest of the transcription. If one language is set, this option will be ignored."
            )
        })
        .optional()
        .describe("Specify the language configuration"),
      audio_url: zod.string().url().nullable()
    })
    .nullish()
    .describe(
      'Parameters used for this pre-recorded transcription. Can be null if status is \"error\"'
    ),
  result: zod
    .object({
      metadata: zod
        .object({
          audio_duration: zod.number().describe("Duration of the transcribed audio file"),
          number_of_distinct_channels: zod
            .number()
            .min(1)
            .describe("Number of distinct channels in the transcribed audio file"),
          billing_time: zod
            .number()
            .describe("Billed duration in seconds (audio_duration * number_of_distinct_channels)"),
          transcription_time: zod.number().describe("Duration of the transcription in seconds")
        })
        .describe("Metadata for the given transcription & audio file"),
      transcription: zod
        .object({
          full_transcript: zod
            .string()
            .describe("All transcription on text format without any other information"),
          languages: zod
            .array(
              zod
                .enum([
                  "af",
                  "am",
                  "ar",
                  "as",
                  "az",
                  "ba",
                  "be",
                  "bg",
                  "bn",
                  "bo",
                  "br",
                  "bs",
                  "ca",
                  "cs",
                  "cy",
                  "da",
                  "de",
                  "el",
                  "en",
                  "es",
                  "et",
                  "eu",
                  "fa",
                  "fi",
                  "fo",
                  "fr",
                  "gl",
                  "gu",
                  "ha",
                  "haw",
                  "he",
                  "hi",
                  "hr",
                  "ht",
                  "hu",
                  "hy",
                  "id",
                  "is",
                  "it",
                  "ja",
                  "jw",
                  "ka",
                  "kk",
                  "km",
                  "kn",
                  "ko",
                  "la",
                  "lb",
                  "ln",
                  "lo",
                  "lt",
                  "lv",
                  "mg",
                  "mi",
                  "mk",
                  "ml",
                  "mn",
                  "mr",
                  "ms",
                  "mt",
                  "my",
                  "ne",
                  "nl",
                  "nn",
                  "no",
                  "oc",
                  "pa",
                  "pl",
                  "ps",
                  "pt",
                  "ro",
                  "ru",
                  "sa",
                  "sd",
                  "si",
                  "sk",
                  "sl",
                  "sn",
                  "so",
                  "sq",
                  "sr",
                  "su",
                  "sv",
                  "sw",
                  "ta",
                  "te",
                  "tg",
                  "th",
                  "tk",
                  "tl",
                  "tr",
                  "tt",
                  "uk",
                  "ur",
                  "uz",
                  "vi",
                  "yi",
                  "yo",
                  "zh"
                ])
                .describe(
                  "Specify the language in which it will be pronounced when sound comparison occurs. Default to transcription language."
                )
            )
            .describe(
              "All the detected languages in the audio sorted from the most detected to the less detected"
            ),
          sentences: zod
            .array(
              zod.object({
                success: zod
                  .boolean()
                  .describe("The audio intelligence model succeeded to get a valid output"),
                is_empty: zod
                  .boolean()
                  .describe("The audio intelligence model returned an empty value"),
                exec_time: zod
                  .number()
                  .describe("Time audio intelligence model took to complete the task"),
                error: zod
                  .object({
                    status_code: zod.number().describe("Status code of the addon error"),
                    exception: zod.string().describe("Reason of the addon error"),
                    message: zod.string().describe("Detailed message of the addon error")
                  })
                  .nullable()
                  .describe(
                    "`null` if `success` is `true`. Contains the error details of the failed model"
                  ),
                results: zod
                  .array(zod.string())
                  .nullable()
                  .describe("If `sentences` has been enabled, transcription as sentences.")
              })
            )
            .optional()
            .describe("If `sentences` has been enabled, sentences results"),
          subtitles: zod
            .array(
              zod.object({
                format: zod
                  .enum(["srt", "vtt"])
                  .describe("Subtitles formats you want your transcription to be formatted to")
                  .describe("Format of the current subtitle"),
                subtitles: zod.string().describe("Transcription on the asked subtitle format")
              })
            )
            .optional()
            .describe("If `subtitles` has been enabled, subtitles results"),
          utterances: zod
            .array(
              zod.object({
                start: zod.number().describe("Start timestamp in seconds of this utterance"),
                end: zod.number().describe("End timestamp in seconds of this utterance"),
                confidence: zod
                  .number()
                  .describe("Confidence on the transcribed utterance (1 = 100% confident)"),
                channel: zod
                  .number()
                  .min(
                    preRecordedControllerGetPreRecordedJobV2ResponseResultTranscriptionUtterancesItemChannelMin
                  )
                  .describe("Audio channel of where this utterance has been transcribed from"),
                speaker: zod
                  .number()
                  .min(
                    preRecordedControllerGetPreRecordedJobV2ResponseResultTranscriptionUtterancesItemSpeakerMin
                  )
                  .optional()
                  .describe("If `diarization` enabled, speaker identification number"),
                words: zod
                  .array(
                    zod.object({
                      word: zod.string().describe("Spoken word"),
                      start: zod
                        .number()
                        .describe("Start timestamps in seconds of the spoken word"),
                      end: zod.number().describe("End timestamps in seconds of the spoken word"),
                      confidence: zod
                        .number()
                        .describe("Confidence on the transcribed word (1 = 100% confident)")
                    })
                  )
                  .describe("List of words of the utterance, split by timestamp"),
                text: zod.string().describe("Transcription for this utterance"),
                language: zod
                  .enum([
                    "af",
                    "am",
                    "ar",
                    "as",
                    "az",
                    "ba",
                    "be",
                    "bg",
                    "bn",
                    "bo",
                    "br",
                    "bs",
                    "ca",
                    "cs",
                    "cy",
                    "da",
                    "de",
                    "el",
                    "en",
                    "es",
                    "et",
                    "eu",
                    "fa",
                    "fi",
                    "fo",
                    "fr",
                    "gl",
                    "gu",
                    "ha",
                    "haw",
                    "he",
                    "hi",
                    "hr",
                    "ht",
                    "hu",
                    "hy",
                    "id",
                    "is",
                    "it",
                    "ja",
                    "jw",
                    "ka",
                    "kk",
                    "km",
                    "kn",
                    "ko",
                    "la",
                    "lb",
                    "ln",
                    "lo",
                    "lt",
                    "lv",
                    "mg",
                    "mi",
                    "mk",
                    "ml",
                    "mn",
                    "mr",
                    "ms",
                    "mt",
                    "my",
                    "ne",
                    "nl",
                    "nn",
                    "no",
                    "oc",
                    "pa",
                    "pl",
                    "ps",
                    "pt",
                    "ro",
                    "ru",
                    "sa",
                    "sd",
                    "si",
                    "sk",
                    "sl",
                    "sn",
                    "so",
                    "sq",
                    "sr",
                    "su",
                    "sv",
                    "sw",
                    "ta",
                    "te",
                    "tg",
                    "th",
                    "tk",
                    "tl",
                    "tr",
                    "tt",
                    "uk",
                    "ur",
                    "uz",
                    "vi",
                    "yi",
                    "yo",
                    "zh"
                  ])
                  .describe(
                    "Specify the language in which it will be pronounced when sound comparison occurs. Default to transcription language."
                  )
                  .describe("Spoken language in this utterance")
              })
            )
            .describe("Transcribed speech utterances present in the audio")
        })
        .optional()
        .describe("Transcription of the audio speech"),
      translation: zod
        .object({
          success: zod
            .boolean()
            .describe("The audio intelligence model succeeded to get a valid output"),
          is_empty: zod.boolean().describe("The audio intelligence model returned an empty value"),
          exec_time: zod
            .number()
            .describe("Time audio intelligence model took to complete the task"),
          error: zod
            .object({
              status_code: zod.number().describe("Status code of the addon error"),
              exception: zod.string().describe("Reason of the addon error"),
              message: zod.string().describe("Detailed message of the addon error")
            })
            .nullable()
            .describe(
              "`null` if `success` is `true`. Contains the error details of the failed model"
            ),
          results: zod
            .array(
              zod.object({
                error: zod
                  .object({
                    status_code: zod.number().describe("Status code of the addon error"),
                    exception: zod.string().describe("Reason of the addon error"),
                    message: zod.string().describe("Detailed message of the addon error")
                  })
                  .nullable()
                  .describe("Contains the error details of the failed addon"),
                full_transcript: zod
                  .string()
                  .describe("All transcription on text format without any other information"),
                languages: zod
                  .array(
                    zod
                      .enum([
                        "af",
                        "am",
                        "ar",
                        "as",
                        "az",
                        "ba",
                        "be",
                        "bg",
                        "bn",
                        "bo",
                        "br",
                        "bs",
                        "ca",
                        "cs",
                        "cy",
                        "da",
                        "de",
                        "el",
                        "en",
                        "es",
                        "et",
                        "eu",
                        "fa",
                        "fi",
                        "fo",
                        "fr",
                        "gl",
                        "gu",
                        "ha",
                        "haw",
                        "he",
                        "hi",
                        "hr",
                        "ht",
                        "hu",
                        "hy",
                        "id",
                        "is",
                        "it",
                        "ja",
                        "jw",
                        "ka",
                        "kk",
                        "km",
                        "kn",
                        "ko",
                        "la",
                        "lb",
                        "ln",
                        "lo",
                        "lt",
                        "lv",
                        "mg",
                        "mi",
                        "mk",
                        "ml",
                        "mn",
                        "mr",
                        "ms",
                        "mt",
                        "my",
                        "ne",
                        "nl",
                        "nn",
                        "no",
                        "oc",
                        "pa",
                        "pl",
                        "ps",
                        "pt",
                        "ro",
                        "ru",
                        "sa",
                        "sd",
                        "si",
                        "sk",
                        "sl",
                        "sn",
                        "so",
                        "sq",
                        "sr",
                        "su",
                        "sv",
                        "sw",
                        "ta",
                        "te",
                        "tg",
                        "th",
                        "tk",
                        "tl",
                        "tr",
                        "tt",
                        "uk",
                        "ur",
                        "uz",
                        "vi",
                        "wo",
                        "yi",
                        "yo",
                        "zh"
                      ])
                      .describe(
                        "Target language in `iso639-1` format you want the transcription translated to"
                      )
                  )
                  .describe(
                    "All the detected languages in the audio sorted from the most detected to the less detected"
                  ),
                sentences: zod
                  .array(
                    zod.object({
                      success: zod
                        .boolean()
                        .describe("The audio intelligence model succeeded to get a valid output"),
                      is_empty: zod
                        .boolean()
                        .describe("The audio intelligence model returned an empty value"),
                      exec_time: zod
                        .number()
                        .describe("Time audio intelligence model took to complete the task"),
                      error: zod
                        .object({
                          status_code: zod.number().describe("Status code of the addon error"),
                          exception: zod.string().describe("Reason of the addon error"),
                          message: zod.string().describe("Detailed message of the addon error")
                        })
                        .nullable()
                        .describe(
                          "`null` if `success` is `true`. Contains the error details of the failed model"
                        ),
                      results: zod
                        .array(zod.string())
                        .nullable()
                        .describe("If `sentences` has been enabled, transcription as sentences.")
                    })
                  )
                  .optional()
                  .describe(
                    "If `sentences` has been enabled, sentences results for this translation"
                  ),
                subtitles: zod
                  .array(
                    zod.object({
                      format: zod
                        .enum(["srt", "vtt"])
                        .describe(
                          "Subtitles formats you want your transcription to be formatted to"
                        )
                        .describe("Format of the current subtitle"),
                      subtitles: zod.string().describe("Transcription on the asked subtitle format")
                    })
                  )
                  .optional()
                  .describe(
                    "If `subtitles` has been enabled, subtitles results for this translation"
                  ),
                utterances: zod
                  .array(
                    zod.object({
                      start: zod.number().describe("Start timestamp in seconds of this utterance"),
                      end: zod.number().describe("End timestamp in seconds of this utterance"),
                      confidence: zod
                        .number()
                        .describe("Confidence on the transcribed utterance (1 = 100% confident)"),
                      channel: zod
                        .number()
                        .min(
                          preRecordedControllerGetPreRecordedJobV2ResponseResultTranslationResultsItemUtterancesItemChannelMin
                        )
                        .describe(
                          "Audio channel of where this utterance has been transcribed from"
                        ),
                      speaker: zod
                        .number()
                        .min(
                          preRecordedControllerGetPreRecordedJobV2ResponseResultTranslationResultsItemUtterancesItemSpeakerMin
                        )
                        .optional()
                        .describe("If `diarization` enabled, speaker identification number"),
                      words: zod
                        .array(
                          zod.object({
                            word: zod.string().describe("Spoken word"),
                            start: zod
                              .number()
                              .describe("Start timestamps in seconds of the spoken word"),
                            end: zod
                              .number()
                              .describe("End timestamps in seconds of the spoken word"),
                            confidence: zod
                              .number()
                              .describe("Confidence on the transcribed word (1 = 100% confident)")
                          })
                        )
                        .describe("List of words of the utterance, split by timestamp"),
                      text: zod.string().describe("Transcription for this utterance"),
                      language: zod
                        .enum([
                          "af",
                          "am",
                          "ar",
                          "as",
                          "az",
                          "ba",
                          "be",
                          "bg",
                          "bn",
                          "bo",
                          "br",
                          "bs",
                          "ca",
                          "cs",
                          "cy",
                          "da",
                          "de",
                          "el",
                          "en",
                          "es",
                          "et",
                          "eu",
                          "fa",
                          "fi",
                          "fo",
                          "fr",
                          "gl",
                          "gu",
                          "ha",
                          "haw",
                          "he",
                          "hi",
                          "hr",
                          "ht",
                          "hu",
                          "hy",
                          "id",
                          "is",
                          "it",
                          "ja",
                          "jw",
                          "ka",
                          "kk",
                          "km",
                          "kn",
                          "ko",
                          "la",
                          "lb",
                          "ln",
                          "lo",
                          "lt",
                          "lv",
                          "mg",
                          "mi",
                          "mk",
                          "ml",
                          "mn",
                          "mr",
                          "ms",
                          "mt",
                          "my",
                          "ne",
                          "nl",
                          "nn",
                          "no",
                          "oc",
                          "pa",
                          "pl",
                          "ps",
                          "pt",
                          "ro",
                          "ru",
                          "sa",
                          "sd",
                          "si",
                          "sk",
                          "sl",
                          "sn",
                          "so",
                          "sq",
                          "sr",
                          "su",
                          "sv",
                          "sw",
                          "ta",
                          "te",
                          "tg",
                          "th",
                          "tk",
                          "tl",
                          "tr",
                          "tt",
                          "uk",
                          "ur",
                          "uz",
                          "vi",
                          "yi",
                          "yo",
                          "zh"
                        ])
                        .describe(
                          "Specify the language in which it will be pronounced when sound comparison occurs. Default to transcription language."
                        )
                        .describe("Spoken language in this utterance")
                    })
                  )
                  .describe("Transcribed speech utterances present in the audio")
              })
            )
            .nullable()
            .describe("List of translated transcriptions, one for each `target_languages`")
        })
        .optional()
        .describe(
          "If `translation` has been enabled, translation of the audio speech transcription"
        ),
      summarization: zod
        .object({
          success: zod
            .boolean()
            .describe("The audio intelligence model succeeded to get a valid output"),
          is_empty: zod.boolean().describe("The audio intelligence model returned an empty value"),
          exec_time: zod
            .number()
            .describe("Time audio intelligence model took to complete the task"),
          error: zod
            .object({
              status_code: zod.number().describe("Status code of the addon error"),
              exception: zod.string().describe("Reason of the addon error"),
              message: zod.string().describe("Detailed message of the addon error")
            })
            .nullable()
            .describe(
              "`null` if `success` is `true`. Contains the error details of the failed model"
            ),
          results: zod
            .string()
            .nullable()
            .describe("If `summarization` has been enabled, summary of the transcription")
        })
        .optional()
        .describe(
          "If `summarization` has been enabled, summarization of the audio speech transcription"
        ),
      moderation: zod
        .object({
          success: zod
            .boolean()
            .describe("The audio intelligence model succeeded to get a valid output"),
          is_empty: zod.boolean().describe("The audio intelligence model returned an empty value"),
          exec_time: zod
            .number()
            .describe("Time audio intelligence model took to complete the task"),
          error: zod
            .object({
              status_code: zod.number().describe("Status code of the addon error"),
              exception: zod.string().describe("Reason of the addon error"),
              message: zod.string().describe("Detailed message of the addon error")
            })
            .nullable()
            .describe(
              "`null` if `success` is `true`. Contains the error details of the failed model"
            ),
          results: zod
            .string()
            .nullable()
            .describe("If `moderation` has been enabled, moderated transcription")
        })
        .optional()
        .describe("If `moderation` has been enabled, moderation of the audio speech transcription"),
      named_entity_recognition: zod
        .object({
          success: zod
            .boolean()
            .describe("The audio intelligence model succeeded to get a valid output"),
          is_empty: zod.boolean().describe("The audio intelligence model returned an empty value"),
          exec_time: zod
            .number()
            .describe("Time audio intelligence model took to complete the task"),
          error: zod
            .object({
              status_code: zod.number().describe("Status code of the addon error"),
              exception: zod.string().describe("Reason of the addon error"),
              message: zod.string().describe("Detailed message of the addon error")
            })
            .nullable()
            .describe(
              "`null` if `success` is `true`. Contains the error details of the failed model"
            ),
          entity: zod
            .string()
            .describe("If `named_entity_recognition` has been enabled, the detected entities.")
        })
        .optional()
        .describe("If `named_entity_recognition` has been enabled, the detected entities"),
      name_consistency: zod
        .object({
          success: zod
            .boolean()
            .describe("The audio intelligence model succeeded to get a valid output"),
          is_empty: zod.boolean().describe("The audio intelligence model returned an empty value"),
          exec_time: zod
            .number()
            .describe("Time audio intelligence model took to complete the task"),
          error: zod
            .object({
              status_code: zod.number().describe("Status code of the addon error"),
              exception: zod.string().describe("Reason of the addon error"),
              message: zod.string().describe("Detailed message of the addon error")
            })
            .nullable()
            .describe(
              "`null` if `success` is `true`. Contains the error details of the failed model"
            ),
          results: zod
            .string()
            .describe(
              "If `name_consistency` has been enabled, Gladia will improve the consistency of the names across the transcription"
            )
        })
        .optional()
        .describe(
          "If `name_consistency` has been enabled, Gladia will improve consistency of the names accross the transcription"
        ),
      speaker_reidentification: zod
        .object({
          success: zod
            .boolean()
            .describe("The audio intelligence model succeeded to get a valid output"),
          is_empty: zod.boolean().describe("The audio intelligence model returned an empty value"),
          exec_time: zod
            .number()
            .describe("Time audio intelligence model took to complete the task"),
          error: zod
            .object({
              status_code: zod.number().describe("Status code of the addon error"),
              exception: zod.string().describe("Reason of the addon error"),
              message: zod.string().describe("Detailed message of the addon error")
            })
            .nullable()
            .describe(
              "`null` if `success` is `true`. Contains the error details of the failed model"
            ),
          results: zod
            .string()
            .describe(
              "If `speaker_reidentification` has been enabled, results of the AI speaker reidentification."
            )
        })
        .optional()
        .describe(
          "If `speaker_reidentification` has been enabled, results of the AI speaker reidentification."
        ),
      structured_data_extraction: zod
        .object({
          success: zod
            .boolean()
            .describe("The audio intelligence model succeeded to get a valid output"),
          is_empty: zod.boolean().describe("The audio intelligence model returned an empty value"),
          exec_time: zod
            .number()
            .describe("Time audio intelligence model took to complete the task"),
          error: zod
            .object({
              status_code: zod.number().describe("Status code of the addon error"),
              exception: zod.string().describe("Reason of the addon error"),
              message: zod.string().describe("Detailed message of the addon error")
            })
            .nullable()
            .describe(
              "`null` if `success` is `true`. Contains the error details of the failed model"
            ),
          results: zod
            .string()
            .describe(
              "If `structured_data_extraction` has been enabled, results of the AI structured data extraction for the defined classes."
            )
        })
        .optional()
        .describe(
          "If `structured_data_extraction` has been enabled, structured data extraction results"
        ),
      sentiment_analysis: zod
        .object({
          success: zod
            .boolean()
            .describe("The audio intelligence model succeeded to get a valid output"),
          is_empty: zod.boolean().describe("The audio intelligence model returned an empty value"),
          exec_time: zod
            .number()
            .describe("Time audio intelligence model took to complete the task"),
          error: zod
            .object({
              status_code: zod.number().describe("Status code of the addon error"),
              exception: zod.string().describe("Reason of the addon error"),
              message: zod.string().describe("Detailed message of the addon error")
            })
            .nullable()
            .describe(
              "`null` if `success` is `true`. Contains the error details of the failed model"
            ),
          results: zod
            .string()
            .describe(
              "If `sentiment_analysis` has been enabled, Gladia will analyze the sentiments and emotions of the audio"
            )
        })
        .optional()
        .describe(
          "If `sentiment_analysis` has been enabled, sentiment analysis of the audio speech transcription"
        ),
      audio_to_llm: zod
        .object({
          success: zod
            .boolean()
            .describe("The audio intelligence model succeeded to get a valid output"),
          is_empty: zod.boolean().describe("The audio intelligence model returned an empty value"),
          exec_time: zod
            .number()
            .describe("Time audio intelligence model took to complete the task"),
          error: zod
            .object({
              status_code: zod.number().describe("Status code of the addon error"),
              exception: zod.string().describe("Reason of the addon error"),
              message: zod.string().describe("Detailed message of the addon error")
            })
            .nullable()
            .describe(
              "`null` if `success` is `true`. Contains the error details of the failed model"
            ),
          results: zod
            .array(
              zod.object({
                success: zod
                  .boolean()
                  .describe("The audio intelligence model succeeded to get a valid output"),
                is_empty: zod
                  .boolean()
                  .describe("The audio intelligence model returned an empty value"),
                exec_time: zod
                  .number()
                  .describe("Time audio intelligence model took to complete the task"),
                error: zod
                  .object({
                    status_code: zod.number().describe("Status code of the addon error"),
                    exception: zod.string().describe("Reason of the addon error"),
                    message: zod.string().describe("Detailed message of the addon error")
                  })
                  .nullable()
                  .describe(
                    "`null` if `success` is `true`. Contains the error details of the failed model"
                  ),
                results: zod
                  .object({
                    prompt: zod.string().nullable().describe("The prompt used"),
                    response: zod.string().nullable().describe("The result of the AI analysis")
                  })
                  .nullable()
                  .describe("The result from a specific prompt")
              })
            )
            .nullable()
            .describe("If `audio_to_llm` has been enabled, results of the AI custom analysis")
        })
        .optional()
        .describe(
          "If `audio_to_llm` has been enabled, audio to llm results of the audio speech transcription"
        ),
      sentences: zod
        .object({
          success: zod
            .boolean()
            .describe("The audio intelligence model succeeded to get a valid output"),
          is_empty: zod.boolean().describe("The audio intelligence model returned an empty value"),
          exec_time: zod
            .number()
            .describe("Time audio intelligence model took to complete the task"),
          error: zod
            .object({
              status_code: zod.number().describe("Status code of the addon error"),
              exception: zod.string().describe("Reason of the addon error"),
              message: zod.string().describe("Detailed message of the addon error")
            })
            .nullable()
            .describe(
              "`null` if `success` is `true`. Contains the error details of the failed model"
            ),
          results: zod
            .array(zod.string())
            .nullable()
            .describe("If `sentences` has been enabled, transcription as sentences.")
        })
        .optional()
        .describe(
          "If `sentences` has been enabled, sentences of the audio speech transcription. Deprecated: content will move to the `transcription` object."
        ),
      display_mode: zod
        .object({
          success: zod
            .boolean()
            .describe("The audio intelligence model succeeded to get a valid output"),
          is_empty: zod.boolean().describe("The audio intelligence model returned an empty value"),
          exec_time: zod
            .number()
            .describe("Time audio intelligence model took to complete the task"),
          error: zod
            .object({
              status_code: zod.number().describe("Status code of the addon error"),
              exception: zod.string().describe("Reason of the addon error"),
              message: zod.string().describe("Detailed message of the addon error")
            })
            .nullable()
            .describe(
              "`null` if `success` is `true`. Contains the error details of the failed model"
            ),
          results: zod
            .array(zod.string())
            .nullable()
            .describe("If `display_mode` has been enabled, proposes an alternative display output.")
        })
        .optional()
        .describe(
          "If `display_mode` has been enabled, the output will be reordered, creating new utterances when speakers overlapped"
        ),
      chapterization: zod
        .object({
          success: zod
            .boolean()
            .describe("The audio intelligence model succeeded to get a valid output"),
          is_empty: zod.boolean().describe("The audio intelligence model returned an empty value"),
          exec_time: zod
            .number()
            .describe("Time audio intelligence model took to complete the task"),
          error: zod
            .object({
              status_code: zod.number().describe("Status code of the addon error"),
              exception: zod.string().describe("Reason of the addon error"),
              message: zod.string().describe("Detailed message of the addon error")
            })
            .nullable()
            .describe(
              "`null` if `success` is `true`. Contains the error details of the failed model"
            ),
          results: zod
            .record(zod.string(), zod.any())
            .describe(
              "If `chapterization` has been enabled, will generate chapters name for different parts of the given audio."
            )
        })
        .optional()
        .describe(
          "If `chapterization` has been enabled, will generate chapters name for different parts of the given audio."
        ),
      diarization: zod
        .object({
          success: zod
            .boolean()
            .describe("The audio intelligence model succeeded to get a valid output"),
          is_empty: zod.boolean().describe("The audio intelligence model returned an empty value"),
          exec_time: zod
            .number()
            .describe("Time audio intelligence model took to complete the task"),
          error: zod
            .object({
              status_code: zod.number().describe("Status code of the addon error"),
              exception: zod.string().describe("Reason of the addon error"),
              message: zod.string().describe("Detailed message of the addon error")
            })
            .nullable()
            .describe(
              "`null` if `success` is `true`. Contains the error details of the failed model"
            ),
          results: zod
            .array(
              zod.object({
                start: zod.number().describe("Start timestamp in seconds of this utterance"),
                end: zod.number().describe("End timestamp in seconds of this utterance"),
                confidence: zod
                  .number()
                  .describe("Confidence on the transcribed utterance (1 = 100% confident)"),
                channel: zod
                  .number()
                  .min(
                    preRecordedControllerGetPreRecordedJobV2ResponseResultDiarizationResultsItemChannelMin
                  )
                  .describe("Audio channel of where this utterance has been transcribed from"),
                speaker: zod
                  .number()
                  .min(
                    preRecordedControllerGetPreRecordedJobV2ResponseResultDiarizationResultsItemSpeakerMin
                  )
                  .optional()
                  .describe("If `diarization` enabled, speaker identification number"),
                words: zod
                  .array(
                    zod.object({
                      word: zod.string().describe("Spoken word"),
                      start: zod
                        .number()
                        .describe("Start timestamps in seconds of the spoken word"),
                      end: zod.number().describe("End timestamps in seconds of the spoken word"),
                      confidence: zod
                        .number()
                        .describe("Confidence on the transcribed word (1 = 100% confident)")
                    })
                  )
                  .describe("List of words of the utterance, split by timestamp"),
                text: zod.string().describe("Transcription for this utterance"),
                language: zod
                  .enum([
                    "af",
                    "am",
                    "ar",
                    "as",
                    "az",
                    "ba",
                    "be",
                    "bg",
                    "bn",
                    "bo",
                    "br",
                    "bs",
                    "ca",
                    "cs",
                    "cy",
                    "da",
                    "de",
                    "el",
                    "en",
                    "es",
                    "et",
                    "eu",
                    "fa",
                    "fi",
                    "fo",
                    "fr",
                    "gl",
                    "gu",
                    "ha",
                    "haw",
                    "he",
                    "hi",
                    "hr",
                    "ht",
                    "hu",
                    "hy",
                    "id",
                    "is",
                    "it",
                    "ja",
                    "jw",
                    "ka",
                    "kk",
                    "km",
                    "kn",
                    "ko",
                    "la",
                    "lb",
                    "ln",
                    "lo",
                    "lt",
                    "lv",
                    "mg",
                    "mi",
                    "mk",
                    "ml",
                    "mn",
                    "mr",
                    "ms",
                    "mt",
                    "my",
                    "ne",
                    "nl",
                    "nn",
                    "no",
                    "oc",
                    "pa",
                    "pl",
                    "ps",
                    "pt",
                    "ro",
                    "ru",
                    "sa",
                    "sd",
                    "si",
                    "sk",
                    "sl",
                    "sn",
                    "so",
                    "sq",
                    "sr",
                    "su",
                    "sv",
                    "sw",
                    "ta",
                    "te",
                    "tg",
                    "th",
                    "tk",
                    "tl",
                    "tr",
                    "tt",
                    "uk",
                    "ur",
                    "uz",
                    "vi",
                    "yi",
                    "yo",
                    "zh"
                  ])
                  .describe(
                    "Specify the language in which it will be pronounced when sound comparison occurs. Default to transcription language."
                  )
                  .describe("Spoken language in this utterance")
              })
            )
            .describe(
              "[Deprecated] If `diarization` has been enabled, the diarization result will appear here"
            )
        })
        .optional()
        .describe(
          "If `diarization` has been requested and an error has occurred, the result will appear here"
        )
    })
    .nullish()
    .describe('Pre-recorded transcription\'s result when status is \"done\"')
})

/**
 * @summary Delete the pre recorded job
 */
export const preRecordedControllerDeletePreRecordedJobV2Params = zod.object({
  id: zod.string().describe("Id of the pre recorded job")
})

/**
 * @summary Download the audio file used for this pre recorded job
 */
export const preRecordedControllerGetAudioV2Params = zod.object({
  id: zod.string().describe("Id of the pre recorded job")
})

/**
 * @summary Initiate a new transcription job
 */
export const transcriptionControllerInitPreRecordedJobV2BodyCustomVocabularyDefault = false
export const transcriptionControllerInitPreRecordedJobV2BodyCustomVocabularyConfigVocabularyItemIntensityMin = 0

export const transcriptionControllerInitPreRecordedJobV2BodyCustomVocabularyConfigVocabularyItemIntensityMax = 1
export const transcriptionControllerInitPreRecordedJobV2BodyCustomVocabularyConfigDefaultIntensityMin = 0

export const transcriptionControllerInitPreRecordedJobV2BodyCustomVocabularyConfigDefaultIntensityMax = 1
export const transcriptionControllerInitPreRecordedJobV2BodyDetectLanguageDefault = true
export const transcriptionControllerInitPreRecordedJobV2BodyEnableCodeSwitchingDefault = false
export const transcriptionControllerInitPreRecordedJobV2BodyCodeSwitchingConfigLanguagesDefault = []
export const transcriptionControllerInitPreRecordedJobV2BodyCallbackDefault = false
export const transcriptionControllerInitPreRecordedJobV2BodyCallbackConfigMethodDefault = "POST"
export const transcriptionControllerInitPreRecordedJobV2BodySubtitlesDefault = false
export const transcriptionControllerInitPreRecordedJobV2BodySubtitlesConfigFormatsDefault: string[] = ["srt"]
export const transcriptionControllerInitPreRecordedJobV2BodySubtitlesConfigMinimumDurationMin = 0
export const transcriptionControllerInitPreRecordedJobV2BodySubtitlesConfigMaximumDurationMax = 30
export const transcriptionControllerInitPreRecordedJobV2BodySubtitlesConfigMaximumRowsPerCaptionMax = 5
export const transcriptionControllerInitPreRecordedJobV2BodySubtitlesConfigStyleDefault = "default"
export const transcriptionControllerInitPreRecordedJobV2BodyDiarizationDefault = false
export const transcriptionControllerInitPreRecordedJobV2BodyDiarizationConfigMinSpeakersMin = 0
export const transcriptionControllerInitPreRecordedJobV2BodyDiarizationConfigMaxSpeakersMin = 0
export const transcriptionControllerInitPreRecordedJobV2BodyTranslationDefault = false
export const transcriptionControllerInitPreRecordedJobV2BodyTranslationConfigModelDefault = "base"
export const transcriptionControllerInitPreRecordedJobV2BodyTranslationConfigMatchOriginalUtterancesDefault = true
export const transcriptionControllerInitPreRecordedJobV2BodyTranslationConfigLipsyncDefault = true
export const transcriptionControllerInitPreRecordedJobV2BodyTranslationConfigContextAdaptationDefault = true
export const transcriptionControllerInitPreRecordedJobV2BodyTranslationConfigInformalDefault = false
export const transcriptionControllerInitPreRecordedJobV2BodySummarizationDefault = false
export const transcriptionControllerInitPreRecordedJobV2BodySummarizationConfigTypeDefault =
  "general"
export const transcriptionControllerInitPreRecordedJobV2BodyModerationDefault = false
export const transcriptionControllerInitPreRecordedJobV2BodyNamedEntityRecognitionDefault = false
export const transcriptionControllerInitPreRecordedJobV2BodyChapterizationDefault = false
export const transcriptionControllerInitPreRecordedJobV2BodyNameConsistencyDefault = false
export const transcriptionControllerInitPreRecordedJobV2BodyCustomSpellingDefault = false
export const transcriptionControllerInitPreRecordedJobV2BodyStructuredDataExtractionDefault = false
export const transcriptionControllerInitPreRecordedJobV2BodySentimentAnalysisDefault = false
export const transcriptionControllerInitPreRecordedJobV2BodyAudioToLlmDefault = false
export const transcriptionControllerInitPreRecordedJobV2BodySentencesDefault = false
export const transcriptionControllerInitPreRecordedJobV2BodyDisplayModeDefault = false
export const transcriptionControllerInitPreRecordedJobV2BodyPunctuationEnhancedDefault = false
export const transcriptionControllerInitPreRecordedJobV2BodyLanguageConfigLanguagesDefault = []
export const transcriptionControllerInitPreRecordedJobV2BodyLanguageConfigCodeSwitchingDefault = false

export const transcriptionControllerInitPreRecordedJobV2Body = zod.object({
  context_prompt: zod
    .string()
    .optional()
    .describe(
      "**[Deprecated]** Context to feed the transcription model with for possible better accuracy"
    ),
  custom_vocabulary: zod
    .boolean()
    .optional()
    .describe(
      "**[Beta]** Can be either boolean to enable custom_vocabulary for this audio or an array with specific vocabulary list to feed the transcription model with"
    ),
  custom_vocabulary_config: zod
    .object({
      vocabulary: zod
        .array(
          zod
            .object({
              value: zod.string().describe("The text used to replace in the transcription."),
              intensity: zod
                .number()
                .min(
                  transcriptionControllerInitPreRecordedJobV2BodyCustomVocabularyConfigVocabularyItemIntensityMin
                )
                .max(
                  transcriptionControllerInitPreRecordedJobV2BodyCustomVocabularyConfigVocabularyItemIntensityMax
                )
                .optional()
                .describe("The global intensity of the feature."),
              pronunciations: zod
                .array(zod.string())
                .optional()
                .describe("The pronunciations used in the transcription."),
              language: zod
                .enum([
                  "af",
                  "am",
                  "ar",
                  "as",
                  "az",
                  "ba",
                  "be",
                  "bg",
                  "bn",
                  "bo",
                  "br",
                  "bs",
                  "ca",
                  "cs",
                  "cy",
                  "da",
                  "de",
                  "el",
                  "en",
                  "es",
                  "et",
                  "eu",
                  "fa",
                  "fi",
                  "fo",
                  "fr",
                  "gl",
                  "gu",
                  "ha",
                  "haw",
                  "he",
                  "hi",
                  "hr",
                  "ht",
                  "hu",
                  "hy",
                  "id",
                  "is",
                  "it",
                  "ja",
                  "jw",
                  "ka",
                  "kk",
                  "km",
                  "kn",
                  "ko",
                  "la",
                  "lb",
                  "ln",
                  "lo",
                  "lt",
                  "lv",
                  "mg",
                  "mi",
                  "mk",
                  "ml",
                  "mn",
                  "mr",
                  "ms",
                  "mt",
                  "my",
                  "ne",
                  "nl",
                  "nn",
                  "no",
                  "oc",
                  "pa",
                  "pl",
                  "ps",
                  "pt",
                  "ro",
                  "ru",
                  "sa",
                  "sd",
                  "si",
                  "sk",
                  "sl",
                  "sn",
                  "so",
                  "sq",
                  "sr",
                  "su",
                  "sv",
                  "sw",
                  "ta",
                  "te",
                  "tg",
                  "th",
                  "tk",
                  "tl",
                  "tr",
                  "tt",
                  "uk",
                  "ur",
                  "uz",
                  "vi",
                  "yi",
                  "yo",
                  "zh"
                ])
                .describe(
                  "Specify the language in which it will be pronounced when sound comparison occurs. Default to transcription language."
                )
                .optional()
                .describe(
                  "Specify the language in which it will be pronounced when sound comparison occurs. Default to transcription language."
                )
            })
            .or(zod.string())
        )
        .describe(
          "Specific vocabulary list to feed the transcription model with. Each item can be a string or an object with the following properties: value, intensity, pronunciations, language."
        ),
      default_intensity: zod
        .number()
        .min(
          transcriptionControllerInitPreRecordedJobV2BodyCustomVocabularyConfigDefaultIntensityMin
        )
        .max(
          transcriptionControllerInitPreRecordedJobV2BodyCustomVocabularyConfigDefaultIntensityMax
        )
        .optional()
        .describe("Default intensity for the custom vocabulary")
    })
    .optional()
    .describe("**[Beta]** Custom vocabulary configuration, if `custom_vocabulary` is enabled"),
  detect_language: zod
    .boolean()
    .default(transcriptionControllerInitPreRecordedJobV2BodyDetectLanguageDefault)
    .describe(
      "**[Deprecated]** Use `language_config` instead. Detect the language from the given audio"
    ),
  enable_code_switching: zod
    .boolean()
    .optional()
    .describe(
      "**[Deprecated]** Use `language_config` instead.Detect multiple languages in the given audio"
    ),
  code_switching_config: zod
    .object({
      languages: zod
        .array(
          zod
            .enum([
              "af",
              "am",
              "ar",
              "as",
              "az",
              "ba",
              "be",
              "bg",
              "bn",
              "bo",
              "br",
              "bs",
              "ca",
              "cs",
              "cy",
              "da",
              "de",
              "el",
              "en",
              "es",
              "et",
              "eu",
              "fa",
              "fi",
              "fo",
              "fr",
              "gl",
              "gu",
              "ha",
              "haw",
              "he",
              "hi",
              "hr",
              "ht",
              "hu",
              "hy",
              "id",
              "is",
              "it",
              "ja",
              "jw",
              "ka",
              "kk",
              "km",
              "kn",
              "ko",
              "la",
              "lb",
              "ln",
              "lo",
              "lt",
              "lv",
              "mg",
              "mi",
              "mk",
              "ml",
              "mn",
              "mr",
              "ms",
              "mt",
              "my",
              "ne",
              "nl",
              "nn",
              "no",
              "oc",
              "pa",
              "pl",
              "ps",
              "pt",
              "ro",
              "ru",
              "sa",
              "sd",
              "si",
              "sk",
              "sl",
              "sn",
              "so",
              "sq",
              "sr",
              "su",
              "sv",
              "sw",
              "ta",
              "te",
              "tg",
              "th",
              "tk",
              "tl",
              "tr",
              "tt",
              "uk",
              "ur",
              "uz",
              "vi",
              "yi",
              "yo",
              "zh"
            ])
            .describe(
              "Specify the language in which it will be pronounced when sound comparison occurs. Default to transcription language."
            )
        )
        .default(transcriptionControllerInitPreRecordedJobV2BodyCodeSwitchingConfigLanguagesDefault)
        .describe("Specify the languages you want to use when detecting multiple languages")
    })
    .optional()
    .describe(
      "**[Deprecated]** Use `language_config` instead. Specify the configuration for code switching"
    ),
  language: zod
    .enum([
      "af",
      "am",
      "ar",
      "as",
      "az",
      "ba",
      "be",
      "bg",
      "bn",
      "bo",
      "br",
      "bs",
      "ca",
      "cs",
      "cy",
      "da",
      "de",
      "el",
      "en",
      "es",
      "et",
      "eu",
      "fa",
      "fi",
      "fo",
      "fr",
      "gl",
      "gu",
      "ha",
      "haw",
      "he",
      "hi",
      "hr",
      "ht",
      "hu",
      "hy",
      "id",
      "is",
      "it",
      "ja",
      "jw",
      "ka",
      "kk",
      "km",
      "kn",
      "ko",
      "la",
      "lb",
      "ln",
      "lo",
      "lt",
      "lv",
      "mg",
      "mi",
      "mk",
      "ml",
      "mn",
      "mr",
      "ms",
      "mt",
      "my",
      "ne",
      "nl",
      "nn",
      "no",
      "oc",
      "pa",
      "pl",
      "ps",
      "pt",
      "ro",
      "ru",
      "sa",
      "sd",
      "si",
      "sk",
      "sl",
      "sn",
      "so",
      "sq",
      "sr",
      "su",
      "sv",
      "sw",
      "ta",
      "te",
      "tg",
      "th",
      "tk",
      "tl",
      "tr",
      "tt",
      "uk",
      "ur",
      "uz",
      "vi",
      "yi",
      "yo",
      "zh"
    ])
    .describe(
      "Specify the language in which it will be pronounced when sound comparison occurs. Default to transcription language."
    )
    .optional()
    .describe(
      "**[Deprecated]** Use `language_config` instead. Set the spoken language for the given audio (ISO 639 standard)"
    ),
  callback_url: zod
    .string()
    .url()
    .optional()
    .describe(
      "**[Deprecated]** Use `callback`/`callback_config` instead. Callback URL we will do a `POST` request to with the result of the transcription"
    ),
  callback: zod
    .boolean()
    .optional()
    .describe(
      "Enable callback for this transcription. If true, the `callback_config` property will be used to customize the callback behaviour"
    ),
  callback_config: zod
    .object({
      url: zod.string().url().describe("The URL to be called with the result of the transcription"),
      method: zod
        .enum(["POST", "PUT"])
        .describe(
          "The HTTP method to be used. Allowed values are `POST` or `PUT` (default: `POST`)"
        )
        .default(transcriptionControllerInitPreRecordedJobV2BodyCallbackConfigMethodDefault)
        .describe(
          "The HTTP method to be used. Allowed values are `POST` or `PUT` (default: `POST`)"
        )
    })
    .optional()
    .describe("Customize the callback behaviour (url and http method)"),
  subtitles: zod
    .boolean()
    .optional()
    .describe("Enable subtitles generation for this transcription"),
  subtitles_config: zod
    .object({
      formats: zod
        .array(
          zod
            .enum(["srt", "vtt"])
            .describe("Subtitles formats you want your transcription to be formatted to")
        )
        .min(1)
        .default(transcriptionControllerInitPreRecordedJobV2BodySubtitlesConfigFormatsDefault)
        .describe("Subtitles formats you want your transcription to be formatted to"),
      minimum_duration: zod
        .number()
        .min(transcriptionControllerInitPreRecordedJobV2BodySubtitlesConfigMinimumDurationMin)
        .optional()
        .describe("Minimum duration of a subtitle in seconds"),
      maximum_duration: zod
        .number()
        .min(1)
        .max(transcriptionControllerInitPreRecordedJobV2BodySubtitlesConfigMaximumDurationMax)
        .optional()
        .describe("Maximum duration of a subtitle in seconds"),
      maximum_characters_per_row: zod
        .number()
        .min(1)
        .optional()
        .describe("Maximum number of characters per row in a subtitle"),
      maximum_rows_per_caption: zod
        .number()
        .min(1)
        .max(transcriptionControllerInitPreRecordedJobV2BodySubtitlesConfigMaximumRowsPerCaptionMax)
        .optional()
        .describe("Maximum number of rows per caption"),
      style: zod
        .enum(["default", "compliance"])
        .describe(
          "Style of the subtitles. Compliance mode refers to : https://loc.gov/preservation/digital/formats//fdd/fdd000569.shtml#:~:text=SRT%20files%20are%20basic%20text,alongside%2C%20example%3A%20%22MyVideo123 "
        )
        .default(transcriptionControllerInitPreRecordedJobV2BodySubtitlesConfigStyleDefault)
        .describe(
          "Style of the subtitles. Compliance mode refers to : https://loc.gov/preservation/digital/formats//fdd/fdd000569.shtml#:~:text=SRT%20files%20are%20basic%20text,alongside%2C%20example%3A%20%22MyVideo123 "
        )
    })
    .optional()
    .describe("Configuration for subtitles generation if `subtitles` is enabled"),
  diarization: zod
    .boolean()
    .optional()
    .describe("Enable speaker recognition (diarization) for this audio"),
  diarization_config: zod
    .object({
      number_of_speakers: zod
        .number()
        .min(1)
        .optional()
        .describe("Exact number of speakers in the audio"),
      min_speakers: zod
        .number()
        .min(transcriptionControllerInitPreRecordedJobV2BodyDiarizationConfigMinSpeakersMin)
        .optional()
        .describe("Minimum number of speakers in the audio"),
      max_speakers: zod
        .number()
        .min(transcriptionControllerInitPreRecordedJobV2BodyDiarizationConfigMaxSpeakersMin)
        .optional()
        .describe("Maximum number of speakers in the audio")
    })
    .optional()
    .describe("Speaker recognition configuration, if `diarization` is enabled"),
  translation: zod.boolean().optional().describe("**[Beta]** Enable translation for this audio"),
  translation_config: zod
    .object({
      target_languages: zod
        .array(
          zod
            .enum([
              "af",
              "am",
              "ar",
              "as",
              "az",
              "ba",
              "be",
              "bg",
              "bn",
              "bo",
              "br",
              "bs",
              "ca",
              "cs",
              "cy",
              "da",
              "de",
              "el",
              "en",
              "es",
              "et",
              "eu",
              "fa",
              "fi",
              "fo",
              "fr",
              "gl",
              "gu",
              "ha",
              "haw",
              "he",
              "hi",
              "hr",
              "ht",
              "hu",
              "hy",
              "id",
              "is",
              "it",
              "ja",
              "jw",
              "ka",
              "kk",
              "km",
              "kn",
              "ko",
              "la",
              "lb",
              "ln",
              "lo",
              "lt",
              "lv",
              "mg",
              "mi",
              "mk",
              "ml",
              "mn",
              "mr",
              "ms",
              "mt",
              "my",
              "ne",
              "nl",
              "nn",
              "no",
              "oc",
              "pa",
              "pl",
              "ps",
              "pt",
              "ro",
              "ru",
              "sa",
              "sd",
              "si",
              "sk",
              "sl",
              "sn",
              "so",
              "sq",
              "sr",
              "su",
              "sv",
              "sw",
              "ta",
              "te",
              "tg",
              "th",
              "tk",
              "tl",
              "tr",
              "tt",
              "uk",
              "ur",
              "uz",
              "vi",
              "wo",
              "yi",
              "yo",
              "zh"
            ])
            .describe(
              "Target language in `iso639-1` format you want the transcription translated to"
            )
        )
        .min(1)
        .describe("Target language in `iso639-1` format you want the transcription translated to"),
      model: zod
        .enum(["base", "enhanced"])
        .describe("Model you want the translation model to use to translate")
        .default(transcriptionControllerInitPreRecordedJobV2BodyTranslationConfigModelDefault)
        .describe("Model you want the translation model to use to translate"),
      match_original_utterances: zod
        .boolean()
        .default(
          transcriptionControllerInitPreRecordedJobV2BodyTranslationConfigMatchOriginalUtterancesDefault
        )
        .describe("Align translated utterances with the original ones"),
      lipsync: zod
        .boolean()
        .default(transcriptionControllerInitPreRecordedJobV2BodyTranslationConfigLipsyncDefault)
        .describe("Whether to apply lipsync to the translated transcription. "),
      context_adaptation: zod
        .boolean()
        .default(
          transcriptionControllerInitPreRecordedJobV2BodyTranslationConfigContextAdaptationDefault
        )
        .describe(
          "Enables or disables context-aware translation features that allow the model to adapt translations based on provided context."
        ),
      context: zod
        .string()
        .optional()
        .describe("Context information to improve translation accuracy"),
      informal: zod
        .boolean()
        .optional()
        .describe(
          "Forces the translation to use informal language forms when available in the target language."
        )
    })
    .optional()
    .describe("**[Beta]** Translation configuration, if `translation` is enabled"),
  summarization: zod
    .boolean()
    .optional()
    .describe("**[Beta]** Enable summarization for this audio"),
  summarization_config: zod
    .object({
      type: zod
        .enum(["general", "bullet_points", "concise"])
        .describe("The type of summarization to apply")
        .default(transcriptionControllerInitPreRecordedJobV2BodySummarizationConfigTypeDefault)
        .describe("The type of summarization to apply")
    })
    .optional()
    .describe("**[Beta]** Summarization configuration, if `summarization` is enabled"),
  moderation: zod.boolean().optional().describe("**[Alpha]** Enable moderation for this audio"),
  named_entity_recognition: zod
    .boolean()
    .optional()
    .describe("**[Alpha]** Enable named entity recognition for this audio"),
  chapterization: zod
    .boolean()
    .optional()
    .describe("**[Alpha]** Enable chapterization for this audio"),
  name_consistency: zod
    .boolean()
    .optional()
    .describe("**[Alpha]** Enable names consistency for this audio"),
  custom_spelling: zod
    .boolean()
    .optional()
    .describe("**[Alpha]** Enable custom spelling for this audio"),
  custom_spelling_config: zod
    .object({
      spelling_dictionary: zod
        .record(zod.string(), zod.array(zod.string()))
        .describe("The list of spelling applied on the audio transcription")
    })
    .optional()
    .describe("**[Alpha]** Custom spelling configuration, if `custom_spelling` is enabled"),
  structured_data_extraction: zod
    .boolean()
    .optional()
    .describe("**[Alpha]** Enable structured data extraction for this audio"),
  structured_data_extraction_config: zod
    .object({
      classes: zod
        .array(zod.array(zod.unknown()))
        .min(1)
        .describe("The list of classes to extract from the audio transcription")
    })
    .optional()
    .describe(
      "**[Alpha]** Structured data extraction configuration, if `structured_data_extraction` is enabled"
    ),
  sentiment_analysis: zod.boolean().optional().describe("Enable sentiment analysis for this audio"),
  audio_to_llm: zod
    .boolean()
    .optional()
    .describe("**[Alpha]** Enable audio to llm processing for this audio"),
  audio_to_llm_config: zod
    .object({
      prompts: zod
        .array(zod.array(zod.unknown()))
        .min(1)
        .describe("The list of prompts applied on the audio transcription")
    })
    .optional()
    .describe("**[Alpha]** Audio to llm configuration, if `audio_to_llm` is enabled"),
  custom_metadata: zod
    .record(zod.string(), zod.any())
    .optional()
    .describe("Custom metadata you can attach to this transcription"),
  sentences: zod.boolean().optional().describe("Enable sentences for this audio"),
  display_mode: zod
    .boolean()
    .optional()
    .describe(
      "**[Alpha]** Allows to change the output display_mode for this audio. The output will be reordered, creating new utterances when speakers overlapped"
    ),
  punctuation_enhanced: zod
    .boolean()
    .optional()
    .describe("**[Alpha]** Use enhanced punctuation for this audio"),
  language_config: zod
    .object({
      languages: zod
        .array(
          zod
            .enum([
              "af",
              "am",
              "ar",
              "as",
              "az",
              "ba",
              "be",
              "bg",
              "bn",
              "bo",
              "br",
              "bs",
              "ca",
              "cs",
              "cy",
              "da",
              "de",
              "el",
              "en",
              "es",
              "et",
              "eu",
              "fa",
              "fi",
              "fo",
              "fr",
              "gl",
              "gu",
              "ha",
              "haw",
              "he",
              "hi",
              "hr",
              "ht",
              "hu",
              "hy",
              "id",
              "is",
              "it",
              "ja",
              "jw",
              "ka",
              "kk",
              "km",
              "kn",
              "ko",
              "la",
              "lb",
              "ln",
              "lo",
              "lt",
              "lv",
              "mg",
              "mi",
              "mk",
              "ml",
              "mn",
              "mr",
              "ms",
              "mt",
              "my",
              "ne",
              "nl",
              "nn",
              "no",
              "oc",
              "pa",
              "pl",
              "ps",
              "pt",
              "ro",
              "ru",
              "sa",
              "sd",
              "si",
              "sk",
              "sl",
              "sn",
              "so",
              "sq",
              "sr",
              "su",
              "sv",
              "sw",
              "ta",
              "te",
              "tg",
              "th",
              "tk",
              "tl",
              "tr",
              "tt",
              "uk",
              "ur",
              "uz",
              "vi",
              "yi",
              "yo",
              "zh"
            ])
            .describe(
              "Specify the language in which it will be pronounced when sound comparison occurs. Default to transcription language."
            )
        )
        .default(transcriptionControllerInitPreRecordedJobV2BodyLanguageConfigLanguagesDefault)
        .describe(
          "If one language is set, it will be used for the transcription. Otherwise, language will be auto-detected by the model."
        ),
      code_switching: zod
        .boolean()
        .optional()
        .describe(
          "If true, language will be auto-detected on each utterance. Otherwise, language will be auto-detected on first utterance and then used for the rest of the transcription. If one language is set, this option will be ignored."
        )
    })
    .optional()
    .describe("Specify the language configuration"),
  audio_url: zod
    .string()
    .url()
    .describe("URL to a Gladia file or to an external audio or video file")
})

/**
 * @summary Get transcription jobs based on query parameters
 */
export const transcriptionControllerListV2QueryOffsetDefault = 0
export const transcriptionControllerListV2QueryOffsetMin = 0
export const transcriptionControllerListV2QueryLimitDefault = 20

export const transcriptionControllerListV2QueryParams = zod.object({
  offset: zod
    .number()
    .min(transcriptionControllerListV2QueryOffsetMin)
    .optional()
    .describe("The starting point for pagination. A value of 0 starts from the first item."),
  limit: zod
    .number()
    .min(1)
    .default(transcriptionControllerListV2QueryLimitDefault)
    .describe(
      "The maximum number of items to return. Useful for pagination and controlling data payload size."
    ),
  date: zod
    .string()
    .datetime({})
    .optional()
    .describe("Filter items relevant to a specific date in ISO format (YYYY-MM-DD)."),
  before_date: zod
    .string()
    .datetime({})
    .optional()
    .describe("Include items that occurred before the specified date in ISO format."),
  after_date: zod
    .string()
    .datetime({})
    .optional()
    .describe(
      "Filter for items after the specified date. Use with `before_date` for a range. Date in ISO format."
    ),
  status: zod
    .array(zod.enum(["queued", "processing", "done", "error"]))
    .optional()
    .describe(
      "Filter the list based on item status. Accepts multiple values from the predefined list."
    ),
  custom_metadata: zod.record(zod.string(), zod.any()).optional(),
  kind: zod
    .array(zod.enum(["pre-recorded", "live"]))
    .optional()
    .describe(
      "Filter the list based on the item type. Supports multiple values from the predefined list."
    )
})

export const transcriptionControllerListV2ResponseItemsItemErrorCodeMin = 400

export const transcriptionControllerListV2ResponseItemsItemErrorCodeMax = 599
export const transcriptionControllerListV2ResponseItemsItemKindDefault = "pre-recorded"
export const transcriptionControllerListV2ResponseItemsItemRequestParamsCustomVocabularyDefault = false
export const transcriptionControllerListV2ResponseItemsItemRequestParamsCustomVocabularyConfigVocabularyItemIntensityMin = 0

export const transcriptionControllerListV2ResponseItemsItemRequestParamsCustomVocabularyConfigVocabularyItemIntensityMax = 1
export const transcriptionControllerListV2ResponseItemsItemRequestParamsCustomVocabularyConfigDefaultIntensityMin = 0

export const transcriptionControllerListV2ResponseItemsItemRequestParamsCustomVocabularyConfigDefaultIntensityMax = 1
export const transcriptionControllerListV2ResponseItemsItemRequestParamsDetectLanguageDefault = true
export const transcriptionControllerListV2ResponseItemsItemRequestParamsEnableCodeSwitchingDefault = false
export const transcriptionControllerListV2ResponseItemsItemRequestParamsCodeSwitchingConfigLanguagesDefault =
  []
export const transcriptionControllerListV2ResponseItemsItemRequestParamsCallbackDefault = false
export const transcriptionControllerListV2ResponseItemsItemRequestParamsCallbackConfigMethodDefault =
  "POST"
export const transcriptionControllerListV2ResponseItemsItemRequestParamsSubtitlesDefault = false
export const transcriptionControllerListV2ResponseItemsItemRequestParamsSubtitlesConfigFormatsDefault: string[] =
  ["srt"]
export const transcriptionControllerListV2ResponseItemsItemRequestParamsSubtitlesConfigMinimumDurationMin = 0
export const transcriptionControllerListV2ResponseItemsItemRequestParamsSubtitlesConfigMaximumDurationMax = 30
export const transcriptionControllerListV2ResponseItemsItemRequestParamsSubtitlesConfigMaximumRowsPerCaptionMax = 5
export const transcriptionControllerListV2ResponseItemsItemRequestParamsSubtitlesConfigStyleDefault =
  "default"
export const transcriptionControllerListV2ResponseItemsItemRequestParamsDiarizationDefault = false
export const transcriptionControllerListV2ResponseItemsItemRequestParamsDiarizationConfigMinSpeakersMin = 0
export const transcriptionControllerListV2ResponseItemsItemRequestParamsDiarizationConfigMaxSpeakersMin = 0
export const transcriptionControllerListV2ResponseItemsItemRequestParamsTranslationDefault = false
export const transcriptionControllerListV2ResponseItemsItemRequestParamsTranslationConfigModelDefault =
  "base"
export const transcriptionControllerListV2ResponseItemsItemRequestParamsTranslationConfigMatchOriginalUtterancesDefault = true
export const transcriptionControllerListV2ResponseItemsItemRequestParamsTranslationConfigLipsyncDefault = true
export const transcriptionControllerListV2ResponseItemsItemRequestParamsTranslationConfigContextAdaptationDefault = true
export const transcriptionControllerListV2ResponseItemsItemRequestParamsTranslationConfigInformalDefault = false
export const transcriptionControllerListV2ResponseItemsItemRequestParamsSummarizationDefault = false
export const transcriptionControllerListV2ResponseItemsItemRequestParamsSummarizationConfigTypeDefault =
  "general"
export const transcriptionControllerListV2ResponseItemsItemRequestParamsModerationDefault = false
export const transcriptionControllerListV2ResponseItemsItemRequestParamsNamedEntityRecognitionDefault = false
export const transcriptionControllerListV2ResponseItemsItemRequestParamsChapterizationDefault = false
export const transcriptionControllerListV2ResponseItemsItemRequestParamsNameConsistencyDefault = false
export const transcriptionControllerListV2ResponseItemsItemRequestParamsCustomSpellingDefault = false
export const transcriptionControllerListV2ResponseItemsItemRequestParamsStructuredDataExtractionDefault = false
export const transcriptionControllerListV2ResponseItemsItemRequestParamsSentimentAnalysisDefault = false
export const transcriptionControllerListV2ResponseItemsItemRequestParamsAudioToLlmDefault = false
export const transcriptionControllerListV2ResponseItemsItemRequestParamsSentencesDefault = false
export const transcriptionControllerListV2ResponseItemsItemRequestParamsDisplayModeDefault = false
export const transcriptionControllerListV2ResponseItemsItemRequestParamsPunctuationEnhancedDefault = false
export const transcriptionControllerListV2ResponseItemsItemRequestParamsLanguageConfigLanguagesDefault =
  []
export const transcriptionControllerListV2ResponseItemsItemRequestParamsLanguageConfigCodeSwitchingDefault = false
export const transcriptionControllerListV2ResponseItemsItemResultTranscriptionUtterancesItemChannelMin = 0
export const transcriptionControllerListV2ResponseItemsItemResultTranscriptionUtterancesItemSpeakerMin = 0
export const transcriptionControllerListV2ResponseItemsItemResultTranslationResultsItemUtterancesItemChannelMin = 0
export const transcriptionControllerListV2ResponseItemsItemResultTranslationResultsItemUtterancesItemSpeakerMin = 0
export const transcriptionControllerListV2ResponseItemsItemResultDiarizationResultsItemChannelMin = 0
export const transcriptionControllerListV2ResponseItemsItemResultDiarizationResultsItemSpeakerMin = 0
export const transcriptionControllerListV2ResponseItemsItemErrorCodeMinOne = 400

export const transcriptionControllerListV2ResponseItemsItemErrorCodeMaxOne = 599
export const transcriptionControllerListV2ResponseItemsItemKindDefaultOne = "live"
export const transcriptionControllerListV2ResponseItemsItemRequestParamsEncodingDefault = "wav/pcm"
export const transcriptionControllerListV2ResponseItemsItemRequestParamsBitDepthDefault = 16
export const transcriptionControllerListV2ResponseItemsItemRequestParamsSampleRateDefault = 16000
export const transcriptionControllerListV2ResponseItemsItemRequestParamsChannelsDefault = 1
export const transcriptionControllerListV2ResponseItemsItemRequestParamsChannelsMax = 8
export const transcriptionControllerListV2ResponseItemsItemRequestParamsModelDefault = "solaria-1"
export const transcriptionControllerListV2ResponseItemsItemRequestParamsEndpointingDefault = 0.05
export const transcriptionControllerListV2ResponseItemsItemRequestParamsEndpointingMin = 0.01

export const transcriptionControllerListV2ResponseItemsItemRequestParamsEndpointingMax = 10
export const transcriptionControllerListV2ResponseItemsItemRequestParamsMaximumDurationWithoutEndpointingDefault = 5
export const transcriptionControllerListV2ResponseItemsItemRequestParamsMaximumDurationWithoutEndpointingMin = 5

export const transcriptionControllerListV2ResponseItemsItemRequestParamsMaximumDurationWithoutEndpointingMax = 60
export const transcriptionControllerListV2ResponseItemsItemRequestParamsLanguageConfigLanguagesDefaultOne =
  []
export const transcriptionControllerListV2ResponseItemsItemRequestParamsLanguageConfigCodeSwitchingDefaultOne = false
export const transcriptionControllerListV2ResponseItemsItemRequestParamsPreProcessingAudioEnhancerDefault = false
export const transcriptionControllerListV2ResponseItemsItemRequestParamsPreProcessingSpeechThresholdDefault = 0.6
export const transcriptionControllerListV2ResponseItemsItemRequestParamsPreProcessingSpeechThresholdMin = 0

export const transcriptionControllerListV2ResponseItemsItemRequestParamsPreProcessingSpeechThresholdMax = 1
export const transcriptionControllerListV2ResponseItemsItemRequestParamsRealtimeProcessingCustomVocabularyDefault = false
export const transcriptionControllerListV2ResponseItemsItemRequestParamsRealtimeProcessingCustomVocabularyConfigVocabularyItemIntensityMin = 0

export const transcriptionControllerListV2ResponseItemsItemRequestParamsRealtimeProcessingCustomVocabularyConfigVocabularyItemIntensityMax = 1
export const transcriptionControllerListV2ResponseItemsItemRequestParamsRealtimeProcessingCustomVocabularyConfigDefaultIntensityMin = 0

export const transcriptionControllerListV2ResponseItemsItemRequestParamsRealtimeProcessingCustomVocabularyConfigDefaultIntensityMax = 1
export const transcriptionControllerListV2ResponseItemsItemRequestParamsRealtimeProcessingCustomSpellingDefault = false
export const transcriptionControllerListV2ResponseItemsItemRequestParamsRealtimeProcessingTranslationDefault = false
export const transcriptionControllerListV2ResponseItemsItemRequestParamsRealtimeProcessingTranslationConfigModelDefault =
  "base"
export const transcriptionControllerListV2ResponseItemsItemRequestParamsRealtimeProcessingTranslationConfigMatchOriginalUtterancesDefault = true
export const transcriptionControllerListV2ResponseItemsItemRequestParamsRealtimeProcessingTranslationConfigLipsyncDefault = true
export const transcriptionControllerListV2ResponseItemsItemRequestParamsRealtimeProcessingTranslationConfigContextAdaptationDefault = true
export const transcriptionControllerListV2ResponseItemsItemRequestParamsRealtimeProcessingTranslationConfigInformalDefault = false
export const transcriptionControllerListV2ResponseItemsItemRequestParamsRealtimeProcessingNamedEntityRecognitionDefault = false
export const transcriptionControllerListV2ResponseItemsItemRequestParamsRealtimeProcessingSentimentAnalysisDefault = false
export const transcriptionControllerListV2ResponseItemsItemRequestParamsPostProcessingSummarizationDefault = false
export const transcriptionControllerListV2ResponseItemsItemRequestParamsPostProcessingSummarizationConfigTypeDefault =
  "general"
export const transcriptionControllerListV2ResponseItemsItemRequestParamsPostProcessingChapterizationDefault = false
export const transcriptionControllerListV2ResponseItemsItemRequestParamsMessagesConfigReceivePartialTranscriptsDefault = false
export const transcriptionControllerListV2ResponseItemsItemRequestParamsMessagesConfigReceiveFinalTranscriptsDefault = true
export const transcriptionControllerListV2ResponseItemsItemRequestParamsMessagesConfigReceiveSpeechEventsDefault = true
export const transcriptionControllerListV2ResponseItemsItemRequestParamsMessagesConfigReceivePreProcessingEventsDefault = true
export const transcriptionControllerListV2ResponseItemsItemRequestParamsMessagesConfigReceiveRealtimeProcessingEventsDefault = true
export const transcriptionControllerListV2ResponseItemsItemRequestParamsMessagesConfigReceivePostProcessingEventsDefault = true
export const transcriptionControllerListV2ResponseItemsItemRequestParamsMessagesConfigReceiveAcknowledgmentsDefault = true
export const transcriptionControllerListV2ResponseItemsItemRequestParamsMessagesConfigReceiveErrorsDefault = true
export const transcriptionControllerListV2ResponseItemsItemRequestParamsMessagesConfigReceiveLifecycleEventsDefault = false
export const transcriptionControllerListV2ResponseItemsItemRequestParamsCallbackDefaultOne = false
export const transcriptionControllerListV2ResponseItemsItemRequestParamsCallbackConfigReceivePartialTranscriptsDefault = false
export const transcriptionControllerListV2ResponseItemsItemRequestParamsCallbackConfigReceiveFinalTranscriptsDefault = true
export const transcriptionControllerListV2ResponseItemsItemRequestParamsCallbackConfigReceiveSpeechEventsDefault = false
export const transcriptionControllerListV2ResponseItemsItemRequestParamsCallbackConfigReceivePreProcessingEventsDefault = true
export const transcriptionControllerListV2ResponseItemsItemRequestParamsCallbackConfigReceiveRealtimeProcessingEventsDefault = true
export const transcriptionControllerListV2ResponseItemsItemRequestParamsCallbackConfigReceivePostProcessingEventsDefault = true
export const transcriptionControllerListV2ResponseItemsItemRequestParamsCallbackConfigReceiveAcknowledgmentsDefault = false
export const transcriptionControllerListV2ResponseItemsItemRequestParamsCallbackConfigReceiveErrorsDefault = false
export const transcriptionControllerListV2ResponseItemsItemRequestParamsCallbackConfigReceiveLifecycleEventsDefault = true
export const transcriptionControllerListV2ResponseItemsItemResultTranscriptionUtterancesItemChannelMinOne = 0
export const transcriptionControllerListV2ResponseItemsItemResultTranscriptionUtterancesItemSpeakerMinOne = 0
export const transcriptionControllerListV2ResponseItemsItemResultTranslationResultsItemUtterancesItemChannelMinOne = 0
export const transcriptionControllerListV2ResponseItemsItemResultTranslationResultsItemUtterancesItemSpeakerMinOne = 0

export const transcriptionControllerListV2Response = zod.object({
  first: zod.string().url().describe("URL to fetch the first page"),
  current: zod.string().url().describe("URL to fetch the current page"),
  next: zod.string().url().nullable().describe("URL to fetch the next page"),
  items: zod
    .array(
      zod
        .object({
          id: zod.string().uuid().describe("Id of the job"),
          request_id: zod.string().describe("Debug id"),
          version: zod.number().describe("API version"),
          status: zod
            .enum(["queued", "processing", "done", "error"])
            .describe(
              '\"queued\": the job has been queued. \"processing\": the job is being processed. \"done\": the job has been processed and the result is available. \"error\": an error occurred during the job\'s processing.'
            ),
          created_at: zod.string().datetime({}).describe("Creation date"),
          completed_at: zod
            .string()
            .datetime({})
            .nullish()
            .describe('Completion date when status is \"done\" or \"error\"'),
          custom_metadata: zod
            .record(zod.string(), zod.any())
            .optional()
            .describe("Custom metadata given in the initial request"),
          error_code: zod
            .number()
            .min(transcriptionControllerListV2ResponseItemsItemErrorCodeMin)
            .max(transcriptionControllerListV2ResponseItemsItemErrorCodeMax)
            .nullish()
            .describe('HTTP status code of the error if status is \"error\"'),
          post_session_metadata: zod
            .object({})
            .describe("For debugging purposes, send data that could help to identify issues"),
          kind: zod.enum(["pre-recorded"]),
          file: zod
            .object({
              id: zod.string().describe("The file id"),
              filename: zod.string().nullable().describe("The name of the uploaded file"),
              source: zod
                .string()
                .nullable()
                .describe("The link used to download the file if audio_url was used"),
              audio_duration: zod.number().nullable().describe("Duration of the audio file"),
              number_of_channels: zod
                .number()
                .min(1)
                .nullable()
                .describe("Number of channels in the audio file")
            })
            .nullish()
            .describe('The file data you uploaded. Can be null if status is \"error\"'),
          request_params: zod
            .object({
              context_prompt: zod
                .string()
                .optional()
                .describe(
                  "**[Deprecated]** Context to feed the transcription model with for possible better accuracy"
                ),
              custom_vocabulary: zod
                .boolean()
                .optional()
                .describe(
                  "**[Beta]** Can be either boolean to enable custom_vocabulary for this audio or an array with specific vocabulary list to feed the transcription model with"
                ),
              custom_vocabulary_config: zod
                .object({
                  vocabulary: zod
                    .array(
                      zod
                        .object({
                          value: zod
                            .string()
                            .describe("The text used to replace in the transcription."),
                          intensity: zod
                            .number()
                            .min(
                              transcriptionControllerListV2ResponseItemsItemRequestParamsCustomVocabularyConfigVocabularyItemIntensityMin
                            )
                            .max(
                              transcriptionControllerListV2ResponseItemsItemRequestParamsCustomVocabularyConfigVocabularyItemIntensityMax
                            )
                            .optional()
                            .describe("The global intensity of the feature."),
                          pronunciations: zod
                            .array(zod.string())
                            .optional()
                            .describe("The pronunciations used in the transcription."),
                          language: zod
                            .enum([
                              "af",
                              "am",
                              "ar",
                              "as",
                              "az",
                              "ba",
                              "be",
                              "bg",
                              "bn",
                              "bo",
                              "br",
                              "bs",
                              "ca",
                              "cs",
                              "cy",
                              "da",
                              "de",
                              "el",
                              "en",
                              "es",
                              "et",
                              "eu",
                              "fa",
                              "fi",
                              "fo",
                              "fr",
                              "gl",
                              "gu",
                              "ha",
                              "haw",
                              "he",
                              "hi",
                              "hr",
                              "ht",
                              "hu",
                              "hy",
                              "id",
                              "is",
                              "it",
                              "ja",
                              "jw",
                              "ka",
                              "kk",
                              "km",
                              "kn",
                              "ko",
                              "la",
                              "lb",
                              "ln",
                              "lo",
                              "lt",
                              "lv",
                              "mg",
                              "mi",
                              "mk",
                              "ml",
                              "mn",
                              "mr",
                              "ms",
                              "mt",
                              "my",
                              "ne",
                              "nl",
                              "nn",
                              "no",
                              "oc",
                              "pa",
                              "pl",
                              "ps",
                              "pt",
                              "ro",
                              "ru",
                              "sa",
                              "sd",
                              "si",
                              "sk",
                              "sl",
                              "sn",
                              "so",
                              "sq",
                              "sr",
                              "su",
                              "sv",
                              "sw",
                              "ta",
                              "te",
                              "tg",
                              "th",
                              "tk",
                              "tl",
                              "tr",
                              "tt",
                              "uk",
                              "ur",
                              "uz",
                              "vi",
                              "yi",
                              "yo",
                              "zh"
                            ])
                            .describe(
                              "Specify the language in which it will be pronounced when sound comparison occurs. Default to transcription language."
                            )
                            .optional()
                            .describe(
                              "Specify the language in which it will be pronounced when sound comparison occurs. Default to transcription language."
                            )
                        })
                        .or(zod.string())
                    )
                    .describe(
                      "Specific vocabulary list to feed the transcription model with. Each item can be a string or an object with the following properties: value, intensity, pronunciations, language."
                    ),
                  default_intensity: zod
                    .number()
                    .min(
                      transcriptionControllerListV2ResponseItemsItemRequestParamsCustomVocabularyConfigDefaultIntensityMin
                    )
                    .max(
                      transcriptionControllerListV2ResponseItemsItemRequestParamsCustomVocabularyConfigDefaultIntensityMax
                    )
                    .optional()
                    .describe("Default intensity for the custom vocabulary")
                })
                .optional()
                .describe(
                  "**[Beta]** Custom vocabulary configuration, if `custom_vocabulary` is enabled"
                ),
              detect_language: zod
                .boolean()
                .default(
                  transcriptionControllerListV2ResponseItemsItemRequestParamsDetectLanguageDefault
                )
                .describe(
                  "**[Deprecated]** Use `language_config` instead. Detect the language from the given audio"
                ),
              enable_code_switching: zod
                .boolean()
                .optional()
                .describe(
                  "**[Deprecated]** Use `language_config` instead.Detect multiple languages in the given audio"
                ),
              code_switching_config: zod
                .object({
                  languages: zod
                    .array(
                      zod
                        .enum([
                          "af",
                          "am",
                          "ar",
                          "as",
                          "az",
                          "ba",
                          "be",
                          "bg",
                          "bn",
                          "bo",
                          "br",
                          "bs",
                          "ca",
                          "cs",
                          "cy",
                          "da",
                          "de",
                          "el",
                          "en",
                          "es",
                          "et",
                          "eu",
                          "fa",
                          "fi",
                          "fo",
                          "fr",
                          "gl",
                          "gu",
                          "ha",
                          "haw",
                          "he",
                          "hi",
                          "hr",
                          "ht",
                          "hu",
                          "hy",
                          "id",
                          "is",
                          "it",
                          "ja",
                          "jw",
                          "ka",
                          "kk",
                          "km",
                          "kn",
                          "ko",
                          "la",
                          "lb",
                          "ln",
                          "lo",
                          "lt",
                          "lv",
                          "mg",
                          "mi",
                          "mk",
                          "ml",
                          "mn",
                          "mr",
                          "ms",
                          "mt",
                          "my",
                          "ne",
                          "nl",
                          "nn",
                          "no",
                          "oc",
                          "pa",
                          "pl",
                          "ps",
                          "pt",
                          "ro",
                          "ru",
                          "sa",
                          "sd",
                          "si",
                          "sk",
                          "sl",
                          "sn",
                          "so",
                          "sq",
                          "sr",
                          "su",
                          "sv",
                          "sw",
                          "ta",
                          "te",
                          "tg",
                          "th",
                          "tk",
                          "tl",
                          "tr",
                          "tt",
                          "uk",
                          "ur",
                          "uz",
                          "vi",
                          "yi",
                          "yo",
                          "zh"
                        ])
                        .describe(
                          "Specify the language in which it will be pronounced when sound comparison occurs. Default to transcription language."
                        )
                    )
                    .default(
                      transcriptionControllerListV2ResponseItemsItemRequestParamsCodeSwitchingConfigLanguagesDefault
                    )
                    .describe(
                      "Specify the languages you want to use when detecting multiple languages"
                    )
                })
                .optional()
                .describe(
                  "**[Deprecated]** Use `language_config` instead. Specify the configuration for code switching"
                ),
              language: zod
                .enum([
                  "af",
                  "am",
                  "ar",
                  "as",
                  "az",
                  "ba",
                  "be",
                  "bg",
                  "bn",
                  "bo",
                  "br",
                  "bs",
                  "ca",
                  "cs",
                  "cy",
                  "da",
                  "de",
                  "el",
                  "en",
                  "es",
                  "et",
                  "eu",
                  "fa",
                  "fi",
                  "fo",
                  "fr",
                  "gl",
                  "gu",
                  "ha",
                  "haw",
                  "he",
                  "hi",
                  "hr",
                  "ht",
                  "hu",
                  "hy",
                  "id",
                  "is",
                  "it",
                  "ja",
                  "jw",
                  "ka",
                  "kk",
                  "km",
                  "kn",
                  "ko",
                  "la",
                  "lb",
                  "ln",
                  "lo",
                  "lt",
                  "lv",
                  "mg",
                  "mi",
                  "mk",
                  "ml",
                  "mn",
                  "mr",
                  "ms",
                  "mt",
                  "my",
                  "ne",
                  "nl",
                  "nn",
                  "no",
                  "oc",
                  "pa",
                  "pl",
                  "ps",
                  "pt",
                  "ro",
                  "ru",
                  "sa",
                  "sd",
                  "si",
                  "sk",
                  "sl",
                  "sn",
                  "so",
                  "sq",
                  "sr",
                  "su",
                  "sv",
                  "sw",
                  "ta",
                  "te",
                  "tg",
                  "th",
                  "tk",
                  "tl",
                  "tr",
                  "tt",
                  "uk",
                  "ur",
                  "uz",
                  "vi",
                  "yi",
                  "yo",
                  "zh"
                ])
                .describe(
                  "Specify the language in which it will be pronounced when sound comparison occurs. Default to transcription language."
                )
                .optional()
                .describe(
                  "**[Deprecated]** Use `language_config` instead. Set the spoken language for the given audio (ISO 639 standard)"
                ),
              callback_url: zod
                .string()
                .url()
                .optional()
                .describe(
                  "**[Deprecated]** Use `callback`/`callback_config` instead. Callback URL we will do a `POST` request to with the result of the transcription"
                ),
              callback: zod
                .boolean()
                .optional()
                .describe(
                  "Enable callback for this transcription. If true, the `callback_config` property will be used to customize the callback behaviour"
                ),
              callback_config: zod
                .object({
                  url: zod
                    .string()
                    .url()
                    .describe("The URL to be called with the result of the transcription"),
                  method: zod
                    .enum(["POST", "PUT"])
                    .describe(
                      "The HTTP method to be used. Allowed values are `POST` or `PUT` (default: `POST`)"
                    )
                    .default(
                      transcriptionControllerListV2ResponseItemsItemRequestParamsCallbackConfigMethodDefault
                    )
                    .describe(
                      "The HTTP method to be used. Allowed values are `POST` or `PUT` (default: `POST`)"
                    )
                })
                .optional()
                .describe("Customize the callback behaviour (url and http method)"),
              subtitles: zod
                .boolean()
                .optional()
                .describe("Enable subtitles generation for this transcription"),
              subtitles_config: zod
                .object({
                  formats: zod
                    .array(
                      zod
                        .enum(["srt", "vtt"])
                        .describe(
                          "Subtitles formats you want your transcription to be formatted to"
                        )
                    )
                    .min(1)
                    .default(
                      transcriptionControllerListV2ResponseItemsItemRequestParamsSubtitlesConfigFormatsDefault
                    )
                    .describe("Subtitles formats you want your transcription to be formatted to"),
                  minimum_duration: zod
                    .number()
                    .min(
                      transcriptionControllerListV2ResponseItemsItemRequestParamsSubtitlesConfigMinimumDurationMin
                    )
                    .optional()
                    .describe("Minimum duration of a subtitle in seconds"),
                  maximum_duration: zod
                    .number()
                    .min(1)
                    .max(
                      transcriptionControllerListV2ResponseItemsItemRequestParamsSubtitlesConfigMaximumDurationMax
                    )
                    .optional()
                    .describe("Maximum duration of a subtitle in seconds"),
                  maximum_characters_per_row: zod
                    .number()
                    .min(1)
                    .optional()
                    .describe("Maximum number of characters per row in a subtitle"),
                  maximum_rows_per_caption: zod
                    .number()
                    .min(1)
                    .max(
                      transcriptionControllerListV2ResponseItemsItemRequestParamsSubtitlesConfigMaximumRowsPerCaptionMax
                    )
                    .optional()
                    .describe("Maximum number of rows per caption"),
                  style: zod
                    .enum(["default", "compliance"])
                    .describe(
                      "Style of the subtitles. Compliance mode refers to : https://loc.gov/preservation/digital/formats//fdd/fdd000569.shtml#:~:text=SRT%20files%20are%20basic%20text,alongside%2C%20example%3A%20%22MyVideo123 "
                    )
                    .default(
                      transcriptionControllerListV2ResponseItemsItemRequestParamsSubtitlesConfigStyleDefault
                    )
                    .describe(
                      "Style of the subtitles. Compliance mode refers to : https://loc.gov/preservation/digital/formats//fdd/fdd000569.shtml#:~:text=SRT%20files%20are%20basic%20text,alongside%2C%20example%3A%20%22MyVideo123 "
                    )
                })
                .optional()
                .describe("Configuration for subtitles generation if `subtitles` is enabled"),
              diarization: zod
                .boolean()
                .optional()
                .describe("Enable speaker recognition (diarization) for this audio"),
              diarization_config: zod
                .object({
                  number_of_speakers: zod
                    .number()
                    .min(1)
                    .optional()
                    .describe("Exact number of speakers in the audio"),
                  min_speakers: zod
                    .number()
                    .min(
                      transcriptionControllerListV2ResponseItemsItemRequestParamsDiarizationConfigMinSpeakersMin
                    )
                    .optional()
                    .describe("Minimum number of speakers in the audio"),
                  max_speakers: zod
                    .number()
                    .min(
                      transcriptionControllerListV2ResponseItemsItemRequestParamsDiarizationConfigMaxSpeakersMin
                    )
                    .optional()
                    .describe("Maximum number of speakers in the audio")
                })
                .optional()
                .describe("Speaker recognition configuration, if `diarization` is enabled"),
              translation: zod
                .boolean()
                .optional()
                .describe("**[Beta]** Enable translation for this audio"),
              translation_config: zod
                .object({
                  target_languages: zod
                    .array(
                      zod
                        .enum([
                          "af",
                          "am",
                          "ar",
                          "as",
                          "az",
                          "ba",
                          "be",
                          "bg",
                          "bn",
                          "bo",
                          "br",
                          "bs",
                          "ca",
                          "cs",
                          "cy",
                          "da",
                          "de",
                          "el",
                          "en",
                          "es",
                          "et",
                          "eu",
                          "fa",
                          "fi",
                          "fo",
                          "fr",
                          "gl",
                          "gu",
                          "ha",
                          "haw",
                          "he",
                          "hi",
                          "hr",
                          "ht",
                          "hu",
                          "hy",
                          "id",
                          "is",
                          "it",
                          "ja",
                          "jw",
                          "ka",
                          "kk",
                          "km",
                          "kn",
                          "ko",
                          "la",
                          "lb",
                          "ln",
                          "lo",
                          "lt",
                          "lv",
                          "mg",
                          "mi",
                          "mk",
                          "ml",
                          "mn",
                          "mr",
                          "ms",
                          "mt",
                          "my",
                          "ne",
                          "nl",
                          "nn",
                          "no",
                          "oc",
                          "pa",
                          "pl",
                          "ps",
                          "pt",
                          "ro",
                          "ru",
                          "sa",
                          "sd",
                          "si",
                          "sk",
                          "sl",
                          "sn",
                          "so",
                          "sq",
                          "sr",
                          "su",
                          "sv",
                          "sw",
                          "ta",
                          "te",
                          "tg",
                          "th",
                          "tk",
                          "tl",
                          "tr",
                          "tt",
                          "uk",
                          "ur",
                          "uz",
                          "vi",
                          "wo",
                          "yi",
                          "yo",
                          "zh"
                        ])
                        .describe(
                          "Target language in `iso639-1` format you want the transcription translated to"
                        )
                    )
                    .min(1)
                    .describe(
                      "Target language in `iso639-1` format you want the transcription translated to"
                    ),
                  model: zod
                    .enum(["base", "enhanced"])
                    .describe("Model you want the translation model to use to translate")
                    .default(
                      transcriptionControllerListV2ResponseItemsItemRequestParamsTranslationConfigModelDefault
                    )
                    .describe("Model you want the translation model to use to translate"),
                  match_original_utterances: zod
                    .boolean()
                    .default(
                      transcriptionControllerListV2ResponseItemsItemRequestParamsTranslationConfigMatchOriginalUtterancesDefault
                    )
                    .describe("Align translated utterances with the original ones"),
                  lipsync: zod
                    .boolean()
                    .default(
                      transcriptionControllerListV2ResponseItemsItemRequestParamsTranslationConfigLipsyncDefault
                    )
                    .describe("Whether to apply lipsync to the translated transcription. "),
                  context_adaptation: zod
                    .boolean()
                    .default(
                      transcriptionControllerListV2ResponseItemsItemRequestParamsTranslationConfigContextAdaptationDefault
                    )
                    .describe(
                      "Enables or disables context-aware translation features that allow the model to adapt translations based on provided context."
                    ),
                  context: zod
                    .string()
                    .optional()
                    .describe("Context information to improve translation accuracy"),
                  informal: zod
                    .boolean()
                    .optional()
                    .describe(
                      "Forces the translation to use informal language forms when available in the target language."
                    )
                })
                .optional()
                .describe("**[Beta]** Translation configuration, if `translation` is enabled"),
              summarization: zod
                .boolean()
                .optional()
                .describe("**[Beta]** Enable summarization for this audio"),
              summarization_config: zod
                .object({
                  type: zod
                    .enum(["general", "bullet_points", "concise"])
                    .describe("The type of summarization to apply")
                    .default(
                      transcriptionControllerListV2ResponseItemsItemRequestParamsSummarizationConfigTypeDefault
                    )
                    .describe("The type of summarization to apply")
                })
                .optional()
                .describe("**[Beta]** Summarization configuration, if `summarization` is enabled"),
              moderation: zod
                .boolean()
                .optional()
                .describe("**[Alpha]** Enable moderation for this audio"),
              named_entity_recognition: zod
                .boolean()
                .optional()
                .describe("**[Alpha]** Enable named entity recognition for this audio"),
              chapterization: zod
                .boolean()
                .optional()
                .describe("**[Alpha]** Enable chapterization for this audio"),
              name_consistency: zod
                .boolean()
                .optional()
                .describe("**[Alpha]** Enable names consistency for this audio"),
              custom_spelling: zod
                .boolean()
                .optional()
                .describe("**[Alpha]** Enable custom spelling for this audio"),
              custom_spelling_config: zod
                .object({
                  spelling_dictionary: zod
                    .record(zod.string(), zod.array(zod.string()))
                    .describe("The list of spelling applied on the audio transcription")
                })
                .optional()
                .describe(
                  "**[Alpha]** Custom spelling configuration, if `custom_spelling` is enabled"
                ),
              structured_data_extraction: zod
                .boolean()
                .optional()
                .describe("**[Alpha]** Enable structured data extraction for this audio"),
              structured_data_extraction_config: zod
                .object({
                  classes: zod
                    .array(zod.array(zod.unknown()))
                    .min(1)
                    .describe("The list of classes to extract from the audio transcription")
                })
                .optional()
                .describe(
                  "**[Alpha]** Structured data extraction configuration, if `structured_data_extraction` is enabled"
                ),
              sentiment_analysis: zod
                .boolean()
                .optional()
                .describe("Enable sentiment analysis for this audio"),
              audio_to_llm: zod
                .boolean()
                .optional()
                .describe("**[Alpha]** Enable audio to llm processing for this audio"),
              audio_to_llm_config: zod
                .object({
                  prompts: zod
                    .array(zod.array(zod.unknown()))
                    .min(1)
                    .describe("The list of prompts applied on the audio transcription")
                })
                .optional()
                .describe("**[Alpha]** Audio to llm configuration, if `audio_to_llm` is enabled"),
              sentences: zod.boolean().optional().describe("Enable sentences for this audio"),
              display_mode: zod
                .boolean()
                .optional()
                .describe(
                  "**[Alpha]** Allows to change the output display_mode for this audio. The output will be reordered, creating new utterances when speakers overlapped"
                ),
              punctuation_enhanced: zod
                .boolean()
                .optional()
                .describe("**[Alpha]** Use enhanced punctuation for this audio"),
              language_config: zod
                .object({
                  languages: zod
                    .array(
                      zod
                        .enum([
                          "af",
                          "am",
                          "ar",
                          "as",
                          "az",
                          "ba",
                          "be",
                          "bg",
                          "bn",
                          "bo",
                          "br",
                          "bs",
                          "ca",
                          "cs",
                          "cy",
                          "da",
                          "de",
                          "el",
                          "en",
                          "es",
                          "et",
                          "eu",
                          "fa",
                          "fi",
                          "fo",
                          "fr",
                          "gl",
                          "gu",
                          "ha",
                          "haw",
                          "he",
                          "hi",
                          "hr",
                          "ht",
                          "hu",
                          "hy",
                          "id",
                          "is",
                          "it",
                          "ja",
                          "jw",
                          "ka",
                          "kk",
                          "km",
                          "kn",
                          "ko",
                          "la",
                          "lb",
                          "ln",
                          "lo",
                          "lt",
                          "lv",
                          "mg",
                          "mi",
                          "mk",
                          "ml",
                          "mn",
                          "mr",
                          "ms",
                          "mt",
                          "my",
                          "ne",
                          "nl",
                          "nn",
                          "no",
                          "oc",
                          "pa",
                          "pl",
                          "ps",
                          "pt",
                          "ro",
                          "ru",
                          "sa",
                          "sd",
                          "si",
                          "sk",
                          "sl",
                          "sn",
                          "so",
                          "sq",
                          "sr",
                          "su",
                          "sv",
                          "sw",
                          "ta",
                          "te",
                          "tg",
                          "th",
                          "tk",
                          "tl",
                          "tr",
                          "tt",
                          "uk",
                          "ur",
                          "uz",
                          "vi",
                          "yi",
                          "yo",
                          "zh"
                        ])
                        .describe(
                          "Specify the language in which it will be pronounced when sound comparison occurs. Default to transcription language."
                        )
                    )
                    .default(
                      transcriptionControllerListV2ResponseItemsItemRequestParamsLanguageConfigLanguagesDefault
                    )
                    .describe(
                      "If one language is set, it will be used for the transcription. Otherwise, language will be auto-detected by the model."
                    ),
                  code_switching: zod
                    .boolean()
                    .optional()
                    .describe(
                      "If true, language will be auto-detected on each utterance. Otherwise, language will be auto-detected on first utterance and then used for the rest of the transcription. If one language is set, this option will be ignored."
                    )
                })
                .optional()
                .describe("Specify the language configuration"),
              audio_url: zod.string().url().nullable()
            })
            .nullish()
            .describe(
              'Parameters used for this pre-recorded transcription. Can be null if status is \"error\"'
            ),
          result: zod
            .object({
              metadata: zod
                .object({
                  audio_duration: zod.number().describe("Duration of the transcribed audio file"),
                  number_of_distinct_channels: zod
                    .number()
                    .min(1)
                    .describe("Number of distinct channels in the transcribed audio file"),
                  billing_time: zod
                    .number()
                    .describe(
                      "Billed duration in seconds (audio_duration * number_of_distinct_channels)"
                    ),
                  transcription_time: zod
                    .number()
                    .describe("Duration of the transcription in seconds")
                })
                .describe("Metadata for the given transcription & audio file"),
              transcription: zod
                .object({
                  full_transcript: zod
                    .string()
                    .describe("All transcription on text format without any other information"),
                  languages: zod
                    .array(
                      zod
                        .enum([
                          "af",
                          "am",
                          "ar",
                          "as",
                          "az",
                          "ba",
                          "be",
                          "bg",
                          "bn",
                          "bo",
                          "br",
                          "bs",
                          "ca",
                          "cs",
                          "cy",
                          "da",
                          "de",
                          "el",
                          "en",
                          "es",
                          "et",
                          "eu",
                          "fa",
                          "fi",
                          "fo",
                          "fr",
                          "gl",
                          "gu",
                          "ha",
                          "haw",
                          "he",
                          "hi",
                          "hr",
                          "ht",
                          "hu",
                          "hy",
                          "id",
                          "is",
                          "it",
                          "ja",
                          "jw",
                          "ka",
                          "kk",
                          "km",
                          "kn",
                          "ko",
                          "la",
                          "lb",
                          "ln",
                          "lo",
                          "lt",
                          "lv",
                          "mg",
                          "mi",
                          "mk",
                          "ml",
                          "mn",
                          "mr",
                          "ms",
                          "mt",
                          "my",
                          "ne",
                          "nl",
                          "nn",
                          "no",
                          "oc",
                          "pa",
                          "pl",
                          "ps",
                          "pt",
                          "ro",
                          "ru",
                          "sa",
                          "sd",
                          "si",
                          "sk",
                          "sl",
                          "sn",
                          "so",
                          "sq",
                          "sr",
                          "su",
                          "sv",
                          "sw",
                          "ta",
                          "te",
                          "tg",
                          "th",
                          "tk",
                          "tl",
                          "tr",
                          "tt",
                          "uk",
                          "ur",
                          "uz",
                          "vi",
                          "yi",
                          "yo",
                          "zh"
                        ])
                        .describe(
                          "Specify the language in which it will be pronounced when sound comparison occurs. Default to transcription language."
                        )
                    )
                    .describe(
                      "All the detected languages in the audio sorted from the most detected to the less detected"
                    ),
                  sentences: zod
                    .array(
                      zod.object({
                        success: zod
                          .boolean()
                          .describe("The audio intelligence model succeeded to get a valid output"),
                        is_empty: zod
                          .boolean()
                          .describe("The audio intelligence model returned an empty value"),
                        exec_time: zod
                          .number()
                          .describe("Time audio intelligence model took to complete the task"),
                        error: zod
                          .object({
                            status_code: zod.number().describe("Status code of the addon error"),
                            exception: zod.string().describe("Reason of the addon error"),
                            message: zod.string().describe("Detailed message of the addon error")
                          })
                          .nullable()
                          .describe(
                            "`null` if `success` is `true`. Contains the error details of the failed model"
                          ),
                        results: zod
                          .array(zod.string())
                          .nullable()
                          .describe("If `sentences` has been enabled, transcription as sentences.")
                      })
                    )
                    .optional()
                    .describe("If `sentences` has been enabled, sentences results"),
                  subtitles: zod
                    .array(
                      zod.object({
                        format: zod
                          .enum(["srt", "vtt"])
                          .describe(
                            "Subtitles formats you want your transcription to be formatted to"
                          )
                          .describe("Format of the current subtitle"),
                        subtitles: zod
                          .string()
                          .describe("Transcription on the asked subtitle format")
                      })
                    )
                    .optional()
                    .describe("If `subtitles` has been enabled, subtitles results"),
                  utterances: zod
                    .array(
                      zod.object({
                        start: zod
                          .number()
                          .describe("Start timestamp in seconds of this utterance"),
                        end: zod.number().describe("End timestamp in seconds of this utterance"),
                        confidence: zod
                          .number()
                          .describe("Confidence on the transcribed utterance (1 = 100% confident)"),
                        channel: zod
                          .number()
                          .min(
                            transcriptionControllerListV2ResponseItemsItemResultTranscriptionUtterancesItemChannelMin
                          )
                          .describe(
                            "Audio channel of where this utterance has been transcribed from"
                          ),
                        speaker: zod
                          .number()
                          .min(
                            transcriptionControllerListV2ResponseItemsItemResultTranscriptionUtterancesItemSpeakerMin
                          )
                          .optional()
                          .describe("If `diarization` enabled, speaker identification number"),
                        words: zod
                          .array(
                            zod.object({
                              word: zod.string().describe("Spoken word"),
                              start: zod
                                .number()
                                .describe("Start timestamps in seconds of the spoken word"),
                              end: zod
                                .number()
                                .describe("End timestamps in seconds of the spoken word"),
                              confidence: zod
                                .number()
                                .describe("Confidence on the transcribed word (1 = 100% confident)")
                            })
                          )
                          .describe("List of words of the utterance, split by timestamp"),
                        text: zod.string().describe("Transcription for this utterance"),
                        language: zod
                          .enum([
                            "af",
                            "am",
                            "ar",
                            "as",
                            "az",
                            "ba",
                            "be",
                            "bg",
                            "bn",
                            "bo",
                            "br",
                            "bs",
                            "ca",
                            "cs",
                            "cy",
                            "da",
                            "de",
                            "el",
                            "en",
                            "es",
                            "et",
                            "eu",
                            "fa",
                            "fi",
                            "fo",
                            "fr",
                            "gl",
                            "gu",
                            "ha",
                            "haw",
                            "he",
                            "hi",
                            "hr",
                            "ht",
                            "hu",
                            "hy",
                            "id",
                            "is",
                            "it",
                            "ja",
                            "jw",
                            "ka",
                            "kk",
                            "km",
                            "kn",
                            "ko",
                            "la",
                            "lb",
                            "ln",
                            "lo",
                            "lt",
                            "lv",
                            "mg",
                            "mi",
                            "mk",
                            "ml",
                            "mn",
                            "mr",
                            "ms",
                            "mt",
                            "my",
                            "ne",
                            "nl",
                            "nn",
                            "no",
                            "oc",
                            "pa",
                            "pl",
                            "ps",
                            "pt",
                            "ro",
                            "ru",
                            "sa",
                            "sd",
                            "si",
                            "sk",
                            "sl",
                            "sn",
                            "so",
                            "sq",
                            "sr",
                            "su",
                            "sv",
                            "sw",
                            "ta",
                            "te",
                            "tg",
                            "th",
                            "tk",
                            "tl",
                            "tr",
                            "tt",
                            "uk",
                            "ur",
                            "uz",
                            "vi",
                            "yi",
                            "yo",
                            "zh"
                          ])
                          .describe(
                            "Specify the language in which it will be pronounced when sound comparison occurs. Default to transcription language."
                          )
                          .describe("Spoken language in this utterance")
                      })
                    )
                    .describe("Transcribed speech utterances present in the audio")
                })
                .optional()
                .describe("Transcription of the audio speech"),
              translation: zod
                .object({
                  success: zod
                    .boolean()
                    .describe("The audio intelligence model succeeded to get a valid output"),
                  is_empty: zod
                    .boolean()
                    .describe("The audio intelligence model returned an empty value"),
                  exec_time: zod
                    .number()
                    .describe("Time audio intelligence model took to complete the task"),
                  error: zod
                    .object({
                      status_code: zod.number().describe("Status code of the addon error"),
                      exception: zod.string().describe("Reason of the addon error"),
                      message: zod.string().describe("Detailed message of the addon error")
                    })
                    .nullable()
                    .describe(
                      "`null` if `success` is `true`. Contains the error details of the failed model"
                    ),
                  results: zod
                    .array(
                      zod.object({
                        error: zod
                          .object({
                            status_code: zod.number().describe("Status code of the addon error"),
                            exception: zod.string().describe("Reason of the addon error"),
                            message: zod.string().describe("Detailed message of the addon error")
                          })
                          .nullable()
                          .describe("Contains the error details of the failed addon"),
                        full_transcript: zod
                          .string()
                          .describe(
                            "All transcription on text format without any other information"
                          ),
                        languages: zod
                          .array(
                            zod
                              .enum([
                                "af",
                                "am",
                                "ar",
                                "as",
                                "az",
                                "ba",
                                "be",
                                "bg",
                                "bn",
                                "bo",
                                "br",
                                "bs",
                                "ca",
                                "cs",
                                "cy",
                                "da",
                                "de",
                                "el",
                                "en",
                                "es",
                                "et",
                                "eu",
                                "fa",
                                "fi",
                                "fo",
                                "fr",
                                "gl",
                                "gu",
                                "ha",
                                "haw",
                                "he",
                                "hi",
                                "hr",
                                "ht",
                                "hu",
                                "hy",
                                "id",
                                "is",
                                "it",
                                "ja",
                                "jw",
                                "ka",
                                "kk",
                                "km",
                                "kn",
                                "ko",
                                "la",
                                "lb",
                                "ln",
                                "lo",
                                "lt",
                                "lv",
                                "mg",
                                "mi",
                                "mk",
                                "ml",
                                "mn",
                                "mr",
                                "ms",
                                "mt",
                                "my",
                                "ne",
                                "nl",
                                "nn",
                                "no",
                                "oc",
                                "pa",
                                "pl",
                                "ps",
                                "pt",
                                "ro",
                                "ru",
                                "sa",
                                "sd",
                                "si",
                                "sk",
                                "sl",
                                "sn",
                                "so",
                                "sq",
                                "sr",
                                "su",
                                "sv",
                                "sw",
                                "ta",
                                "te",
                                "tg",
                                "th",
                                "tk",
                                "tl",
                                "tr",
                                "tt",
                                "uk",
                                "ur",
                                "uz",
                                "vi",
                                "wo",
                                "yi",
                                "yo",
                                "zh"
                              ])
                              .describe(
                                "Target language in `iso639-1` format you want the transcription translated to"
                              )
                          )
                          .describe(
                            "All the detected languages in the audio sorted from the most detected to the less detected"
                          ),
                        sentences: zod
                          .array(
                            zod.object({
                              success: zod
                                .boolean()
                                .describe(
                                  "The audio intelligence model succeeded to get a valid output"
                                ),
                              is_empty: zod
                                .boolean()
                                .describe("The audio intelligence model returned an empty value"),
                              exec_time: zod
                                .number()
                                .describe(
                                  "Time audio intelligence model took to complete the task"
                                ),
                              error: zod
                                .object({
                                  status_code: zod
                                    .number()
                                    .describe("Status code of the addon error"),
                                  exception: zod.string().describe("Reason of the addon error"),
                                  message: zod
                                    .string()
                                    .describe("Detailed message of the addon error")
                                })
                                .nullable()
                                .describe(
                                  "`null` if `success` is `true`. Contains the error details of the failed model"
                                ),
                              results: zod
                                .array(zod.string())
                                .nullable()
                                .describe(
                                  "If `sentences` has been enabled, transcription as sentences."
                                )
                            })
                          )
                          .optional()
                          .describe(
                            "If `sentences` has been enabled, sentences results for this translation"
                          ),
                        subtitles: zod
                          .array(
                            zod.object({
                              format: zod
                                .enum(["srt", "vtt"])
                                .describe(
                                  "Subtitles formats you want your transcription to be formatted to"
                                )
                                .describe("Format of the current subtitle"),
                              subtitles: zod
                                .string()
                                .describe("Transcription on the asked subtitle format")
                            })
                          )
                          .optional()
                          .describe(
                            "If `subtitles` has been enabled, subtitles results for this translation"
                          ),
                        utterances: zod
                          .array(
                            zod.object({
                              start: zod
                                .number()
                                .describe("Start timestamp in seconds of this utterance"),
                              end: zod
                                .number()
                                .describe("End timestamp in seconds of this utterance"),
                              confidence: zod
                                .number()
                                .describe(
                                  "Confidence on the transcribed utterance (1 = 100% confident)"
                                ),
                              channel: zod
                                .number()
                                .min(
                                  transcriptionControllerListV2ResponseItemsItemResultTranslationResultsItemUtterancesItemChannelMin
                                )
                                .describe(
                                  "Audio channel of where this utterance has been transcribed from"
                                ),
                              speaker: zod
                                .number()
                                .min(
                                  transcriptionControllerListV2ResponseItemsItemResultTranslationResultsItemUtterancesItemSpeakerMin
                                )
                                .optional()
                                .describe(
                                  "If `diarization` enabled, speaker identification number"
                                ),
                              words: zod
                                .array(
                                  zod.object({
                                    word: zod.string().describe("Spoken word"),
                                    start: zod
                                      .number()
                                      .describe("Start timestamps in seconds of the spoken word"),
                                    end: zod
                                      .number()
                                      .describe("End timestamps in seconds of the spoken word"),
                                    confidence: zod
                                      .number()
                                      .describe(
                                        "Confidence on the transcribed word (1 = 100% confident)"
                                      )
                                  })
                                )
                                .describe("List of words of the utterance, split by timestamp"),
                              text: zod.string().describe("Transcription for this utterance"),
                              language: zod
                                .enum([
                                  "af",
                                  "am",
                                  "ar",
                                  "as",
                                  "az",
                                  "ba",
                                  "be",
                                  "bg",
                                  "bn",
                                  "bo",
                                  "br",
                                  "bs",
                                  "ca",
                                  "cs",
                                  "cy",
                                  "da",
                                  "de",
                                  "el",
                                  "en",
                                  "es",
                                  "et",
                                  "eu",
                                  "fa",
                                  "fi",
                                  "fo",
                                  "fr",
                                  "gl",
                                  "gu",
                                  "ha",
                                  "haw",
                                  "he",
                                  "hi",
                                  "hr",
                                  "ht",
                                  "hu",
                                  "hy",
                                  "id",
                                  "is",
                                  "it",
                                  "ja",
                                  "jw",
                                  "ka",
                                  "kk",
                                  "km",
                                  "kn",
                                  "ko",
                                  "la",
                                  "lb",
                                  "ln",
                                  "lo",
                                  "lt",
                                  "lv",
                                  "mg",
                                  "mi",
                                  "mk",
                                  "ml",
                                  "mn",
                                  "mr",
                                  "ms",
                                  "mt",
                                  "my",
                                  "ne",
                                  "nl",
                                  "nn",
                                  "no",
                                  "oc",
                                  "pa",
                                  "pl",
                                  "ps",
                                  "pt",
                                  "ro",
                                  "ru",
                                  "sa",
                                  "sd",
                                  "si",
                                  "sk",
                                  "sl",
                                  "sn",
                                  "so",
                                  "sq",
                                  "sr",
                                  "su",
                                  "sv",
                                  "sw",
                                  "ta",
                                  "te",
                                  "tg",
                                  "th",
                                  "tk",
                                  "tl",
                                  "tr",
                                  "tt",
                                  "uk",
                                  "ur",
                                  "uz",
                                  "vi",
                                  "yi",
                                  "yo",
                                  "zh"
                                ])
                                .describe(
                                  "Specify the language in which it will be pronounced when sound comparison occurs. Default to transcription language."
                                )
                                .describe("Spoken language in this utterance")
                            })
                          )
                          .describe("Transcribed speech utterances present in the audio")
                      })
                    )
                    .nullable()
                    .describe("List of translated transcriptions, one for each `target_languages`")
                })
                .optional()
                .describe(
                  "If `translation` has been enabled, translation of the audio speech transcription"
                ),
              summarization: zod
                .object({
                  success: zod
                    .boolean()
                    .describe("The audio intelligence model succeeded to get a valid output"),
                  is_empty: zod
                    .boolean()
                    .describe("The audio intelligence model returned an empty value"),
                  exec_time: zod
                    .number()
                    .describe("Time audio intelligence model took to complete the task"),
                  error: zod
                    .object({
                      status_code: zod.number().describe("Status code of the addon error"),
                      exception: zod.string().describe("Reason of the addon error"),
                      message: zod.string().describe("Detailed message of the addon error")
                    })
                    .nullable()
                    .describe(
                      "`null` if `success` is `true`. Contains the error details of the failed model"
                    ),
                  results: zod
                    .string()
                    .nullable()
                    .describe("If `summarization` has been enabled, summary of the transcription")
                })
                .optional()
                .describe(
                  "If `summarization` has been enabled, summarization of the audio speech transcription"
                ),
              moderation: zod
                .object({
                  success: zod
                    .boolean()
                    .describe("The audio intelligence model succeeded to get a valid output"),
                  is_empty: zod
                    .boolean()
                    .describe("The audio intelligence model returned an empty value"),
                  exec_time: zod
                    .number()
                    .describe("Time audio intelligence model took to complete the task"),
                  error: zod
                    .object({
                      status_code: zod.number().describe("Status code of the addon error"),
                      exception: zod.string().describe("Reason of the addon error"),
                      message: zod.string().describe("Detailed message of the addon error")
                    })
                    .nullable()
                    .describe(
                      "`null` if `success` is `true`. Contains the error details of the failed model"
                    ),
                  results: zod
                    .string()
                    .nullable()
                    .describe("If `moderation` has been enabled, moderated transcription")
                })
                .optional()
                .describe(
                  "If `moderation` has been enabled, moderation of the audio speech transcription"
                ),
              named_entity_recognition: zod
                .object({
                  success: zod
                    .boolean()
                    .describe("The audio intelligence model succeeded to get a valid output"),
                  is_empty: zod
                    .boolean()
                    .describe("The audio intelligence model returned an empty value"),
                  exec_time: zod
                    .number()
                    .describe("Time audio intelligence model took to complete the task"),
                  error: zod
                    .object({
                      status_code: zod.number().describe("Status code of the addon error"),
                      exception: zod.string().describe("Reason of the addon error"),
                      message: zod.string().describe("Detailed message of the addon error")
                    })
                    .nullable()
                    .describe(
                      "`null` if `success` is `true`. Contains the error details of the failed model"
                    ),
                  entity: zod
                    .string()
                    .describe(
                      "If `named_entity_recognition` has been enabled, the detected entities."
                    )
                })
                .optional()
                .describe("If `named_entity_recognition` has been enabled, the detected entities"),
              name_consistency: zod
                .object({
                  success: zod
                    .boolean()
                    .describe("The audio intelligence model succeeded to get a valid output"),
                  is_empty: zod
                    .boolean()
                    .describe("The audio intelligence model returned an empty value"),
                  exec_time: zod
                    .number()
                    .describe("Time audio intelligence model took to complete the task"),
                  error: zod
                    .object({
                      status_code: zod.number().describe("Status code of the addon error"),
                      exception: zod.string().describe("Reason of the addon error"),
                      message: zod.string().describe("Detailed message of the addon error")
                    })
                    .nullable()
                    .describe(
                      "`null` if `success` is `true`. Contains the error details of the failed model"
                    ),
                  results: zod
                    .string()
                    .describe(
                      "If `name_consistency` has been enabled, Gladia will improve the consistency of the names across the transcription"
                    )
                })
                .optional()
                .describe(
                  "If `name_consistency` has been enabled, Gladia will improve consistency of the names accross the transcription"
                ),
              speaker_reidentification: zod
                .object({
                  success: zod
                    .boolean()
                    .describe("The audio intelligence model succeeded to get a valid output"),
                  is_empty: zod
                    .boolean()
                    .describe("The audio intelligence model returned an empty value"),
                  exec_time: zod
                    .number()
                    .describe("Time audio intelligence model took to complete the task"),
                  error: zod
                    .object({
                      status_code: zod.number().describe("Status code of the addon error"),
                      exception: zod.string().describe("Reason of the addon error"),
                      message: zod.string().describe("Detailed message of the addon error")
                    })
                    .nullable()
                    .describe(
                      "`null` if `success` is `true`. Contains the error details of the failed model"
                    ),
                  results: zod
                    .string()
                    .describe(
                      "If `speaker_reidentification` has been enabled, results of the AI speaker reidentification."
                    )
                })
                .optional()
                .describe(
                  "If `speaker_reidentification` has been enabled, results of the AI speaker reidentification."
                ),
              structured_data_extraction: zod
                .object({
                  success: zod
                    .boolean()
                    .describe("The audio intelligence model succeeded to get a valid output"),
                  is_empty: zod
                    .boolean()
                    .describe("The audio intelligence model returned an empty value"),
                  exec_time: zod
                    .number()
                    .describe("Time audio intelligence model took to complete the task"),
                  error: zod
                    .object({
                      status_code: zod.number().describe("Status code of the addon error"),
                      exception: zod.string().describe("Reason of the addon error"),
                      message: zod.string().describe("Detailed message of the addon error")
                    })
                    .nullable()
                    .describe(
                      "`null` if `success` is `true`. Contains the error details of the failed model"
                    ),
                  results: zod
                    .string()
                    .describe(
                      "If `structured_data_extraction` has been enabled, results of the AI structured data extraction for the defined classes."
                    )
                })
                .optional()
                .describe(
                  "If `structured_data_extraction` has been enabled, structured data extraction results"
                ),
              sentiment_analysis: zod
                .object({
                  success: zod
                    .boolean()
                    .describe("The audio intelligence model succeeded to get a valid output"),
                  is_empty: zod
                    .boolean()
                    .describe("The audio intelligence model returned an empty value"),
                  exec_time: zod
                    .number()
                    .describe("Time audio intelligence model took to complete the task"),
                  error: zod
                    .object({
                      status_code: zod.number().describe("Status code of the addon error"),
                      exception: zod.string().describe("Reason of the addon error"),
                      message: zod.string().describe("Detailed message of the addon error")
                    })
                    .nullable()
                    .describe(
                      "`null` if `success` is `true`. Contains the error details of the failed model"
                    ),
                  results: zod
                    .string()
                    .describe(
                      "If `sentiment_analysis` has been enabled, Gladia will analyze the sentiments and emotions of the audio"
                    )
                })
                .optional()
                .describe(
                  "If `sentiment_analysis` has been enabled, sentiment analysis of the audio speech transcription"
                ),
              audio_to_llm: zod
                .object({
                  success: zod
                    .boolean()
                    .describe("The audio intelligence model succeeded to get a valid output"),
                  is_empty: zod
                    .boolean()
                    .describe("The audio intelligence model returned an empty value"),
                  exec_time: zod
                    .number()
                    .describe("Time audio intelligence model took to complete the task"),
                  error: zod
                    .object({
                      status_code: zod.number().describe("Status code of the addon error"),
                      exception: zod.string().describe("Reason of the addon error"),
                      message: zod.string().describe("Detailed message of the addon error")
                    })
                    .nullable()
                    .describe(
                      "`null` if `success` is `true`. Contains the error details of the failed model"
                    ),
                  results: zod
                    .array(
                      zod.object({
                        success: zod
                          .boolean()
                          .describe("The audio intelligence model succeeded to get a valid output"),
                        is_empty: zod
                          .boolean()
                          .describe("The audio intelligence model returned an empty value"),
                        exec_time: zod
                          .number()
                          .describe("Time audio intelligence model took to complete the task"),
                        error: zod
                          .object({
                            status_code: zod.number().describe("Status code of the addon error"),
                            exception: zod.string().describe("Reason of the addon error"),
                            message: zod.string().describe("Detailed message of the addon error")
                          })
                          .nullable()
                          .describe(
                            "`null` if `success` is `true`. Contains the error details of the failed model"
                          ),
                        results: zod
                          .object({
                            prompt: zod.string().nullable().describe("The prompt used"),
                            response: zod
                              .string()
                              .nullable()
                              .describe("The result of the AI analysis")
                          })
                          .nullable()
                          .describe("The result from a specific prompt")
                      })
                    )
                    .nullable()
                    .describe(
                      "If `audio_to_llm` has been enabled, results of the AI custom analysis"
                    )
                })
                .optional()
                .describe(
                  "If `audio_to_llm` has been enabled, audio to llm results of the audio speech transcription"
                ),
              sentences: zod
                .object({
                  success: zod
                    .boolean()
                    .describe("The audio intelligence model succeeded to get a valid output"),
                  is_empty: zod
                    .boolean()
                    .describe("The audio intelligence model returned an empty value"),
                  exec_time: zod
                    .number()
                    .describe("Time audio intelligence model took to complete the task"),
                  error: zod
                    .object({
                      status_code: zod.number().describe("Status code of the addon error"),
                      exception: zod.string().describe("Reason of the addon error"),
                      message: zod.string().describe("Detailed message of the addon error")
                    })
                    .nullable()
                    .describe(
                      "`null` if `success` is `true`. Contains the error details of the failed model"
                    ),
                  results: zod
                    .array(zod.string())
                    .nullable()
                    .describe("If `sentences` has been enabled, transcription as sentences.")
                })
                .optional()
                .describe(
                  "If `sentences` has been enabled, sentences of the audio speech transcription. Deprecated: content will move to the `transcription` object."
                ),
              display_mode: zod
                .object({
                  success: zod
                    .boolean()
                    .describe("The audio intelligence model succeeded to get a valid output"),
                  is_empty: zod
                    .boolean()
                    .describe("The audio intelligence model returned an empty value"),
                  exec_time: zod
                    .number()
                    .describe("Time audio intelligence model took to complete the task"),
                  error: zod
                    .object({
                      status_code: zod.number().describe("Status code of the addon error"),
                      exception: zod.string().describe("Reason of the addon error"),
                      message: zod.string().describe("Detailed message of the addon error")
                    })
                    .nullable()
                    .describe(
                      "`null` if `success` is `true`. Contains the error details of the failed model"
                    ),
                  results: zod
                    .array(zod.string())
                    .nullable()
                    .describe(
                      "If `display_mode` has been enabled, proposes an alternative display output."
                    )
                })
                .optional()
                .describe(
                  "If `display_mode` has been enabled, the output will be reordered, creating new utterances when speakers overlapped"
                ),
              chapterization: zod
                .object({
                  success: zod
                    .boolean()
                    .describe("The audio intelligence model succeeded to get a valid output"),
                  is_empty: zod
                    .boolean()
                    .describe("The audio intelligence model returned an empty value"),
                  exec_time: zod
                    .number()
                    .describe("Time audio intelligence model took to complete the task"),
                  error: zod
                    .object({
                      status_code: zod.number().describe("Status code of the addon error"),
                      exception: zod.string().describe("Reason of the addon error"),
                      message: zod.string().describe("Detailed message of the addon error")
                    })
                    .nullable()
                    .describe(
                      "`null` if `success` is `true`. Contains the error details of the failed model"
                    ),
                  results: zod
                    .record(zod.string(), zod.any())
                    .describe(
                      "If `chapterization` has been enabled, will generate chapters name for different parts of the given audio."
                    )
                })
                .optional()
                .describe(
                  "If `chapterization` has been enabled, will generate chapters name for different parts of the given audio."
                ),
              diarization: zod
                .object({
                  success: zod
                    .boolean()
                    .describe("The audio intelligence model succeeded to get a valid output"),
                  is_empty: zod
                    .boolean()
                    .describe("The audio intelligence model returned an empty value"),
                  exec_time: zod
                    .number()
                    .describe("Time audio intelligence model took to complete the task"),
                  error: zod
                    .object({
                      status_code: zod.number().describe("Status code of the addon error"),
                      exception: zod.string().describe("Reason of the addon error"),
                      message: zod.string().describe("Detailed message of the addon error")
                    })
                    .nullable()
                    .describe(
                      "`null` if `success` is `true`. Contains the error details of the failed model"
                    ),
                  results: zod
                    .array(
                      zod.object({
                        start: zod
                          .number()
                          .describe("Start timestamp in seconds of this utterance"),
                        end: zod.number().describe("End timestamp in seconds of this utterance"),
                        confidence: zod
                          .number()
                          .describe("Confidence on the transcribed utterance (1 = 100% confident)"),
                        channel: zod
                          .number()
                          .min(
                            transcriptionControllerListV2ResponseItemsItemResultDiarizationResultsItemChannelMin
                          )
                          .describe(
                            "Audio channel of where this utterance has been transcribed from"
                          ),
                        speaker: zod
                          .number()
                          .min(
                            transcriptionControllerListV2ResponseItemsItemResultDiarizationResultsItemSpeakerMin
                          )
                          .optional()
                          .describe("If `diarization` enabled, speaker identification number"),
                        words: zod
                          .array(
                            zod.object({
                              word: zod.string().describe("Spoken word"),
                              start: zod
                                .number()
                                .describe("Start timestamps in seconds of the spoken word"),
                              end: zod
                                .number()
                                .describe("End timestamps in seconds of the spoken word"),
                              confidence: zod
                                .number()
                                .describe("Confidence on the transcribed word (1 = 100% confident)")
                            })
                          )
                          .describe("List of words of the utterance, split by timestamp"),
                        text: zod.string().describe("Transcription for this utterance"),
                        language: zod
                          .enum([
                            "af",
                            "am",
                            "ar",
                            "as",
                            "az",
                            "ba",
                            "be",
                            "bg",
                            "bn",
                            "bo",
                            "br",
                            "bs",
                            "ca",
                            "cs",
                            "cy",
                            "da",
                            "de",
                            "el",
                            "en",
                            "es",
                            "et",
                            "eu",
                            "fa",
                            "fi",
                            "fo",
                            "fr",
                            "gl",
                            "gu",
                            "ha",
                            "haw",
                            "he",
                            "hi",
                            "hr",
                            "ht",
                            "hu",
                            "hy",
                            "id",
                            "is",
                            "it",
                            "ja",
                            "jw",
                            "ka",
                            "kk",
                            "km",
                            "kn",
                            "ko",
                            "la",
                            "lb",
                            "ln",
                            "lo",
                            "lt",
                            "lv",
                            "mg",
                            "mi",
                            "mk",
                            "ml",
                            "mn",
                            "mr",
                            "ms",
                            "mt",
                            "my",
                            "ne",
                            "nl",
                            "nn",
                            "no",
                            "oc",
                            "pa",
                            "pl",
                            "ps",
                            "pt",
                            "ro",
                            "ru",
                            "sa",
                            "sd",
                            "si",
                            "sk",
                            "sl",
                            "sn",
                            "so",
                            "sq",
                            "sr",
                            "su",
                            "sv",
                            "sw",
                            "ta",
                            "te",
                            "tg",
                            "th",
                            "tk",
                            "tl",
                            "tr",
                            "tt",
                            "uk",
                            "ur",
                            "uz",
                            "vi",
                            "yi",
                            "yo",
                            "zh"
                          ])
                          .describe(
                            "Specify the language in which it will be pronounced when sound comparison occurs. Default to transcription language."
                          )
                          .describe("Spoken language in this utterance")
                      })
                    )
                    .describe(
                      "[Deprecated] If `diarization` has been enabled, the diarization result will appear here"
                    )
                })
                .optional()
                .describe(
                  "If `diarization` has been requested and an error has occurred, the result will appear here"
                )
            })
            .nullish()
            .describe('Pre-recorded transcription\'s result when status is \"done\"')
        })
        .or(
          zod.object({
            id: zod.string().uuid().describe("Id of the job"),
            request_id: zod.string().describe("Debug id"),
            version: zod.number().describe("API version"),
            status: zod
              .enum(["queued", "processing", "done", "error"])
              .describe(
                '\"queued\": the job has been queued. \"processing\": the job is being processed. \"done\": the job has been processed and the result is available. \"error\": an error occurred during the job\'s processing.'
              ),
            created_at: zod.string().datetime({}).describe("Creation date"),
            completed_at: zod
              .string()
              .datetime({})
              .nullish()
              .describe('Completion date when status is \"done\" or \"error\"'),
            custom_metadata: zod
              .record(zod.string(), zod.any())
              .optional()
              .describe("Custom metadata given in the initial request"),
            error_code: zod
              .number()
              .min(transcriptionControllerListV2ResponseItemsItemErrorCodeMinOne)
              .max(transcriptionControllerListV2ResponseItemsItemErrorCodeMaxOne)
              .nullish()
              .describe('HTTP status code of the error if status is \"error\"'),
            post_session_metadata: zod
              .object({})
              .describe("For debugging purposes, send data that could help to identify issues"),
            kind: zod.enum(["live"]),
            file: zod
              .object({
                id: zod.string().describe("The file id"),
                filename: zod.string().nullable().describe("The name of the uploaded file"),
                source: zod
                  .string()
                  .nullable()
                  .describe("The link used to download the file if audio_url was used"),
                audio_duration: zod.number().nullable().describe("Duration of the audio file"),
                number_of_channels: zod
                  .number()
                  .min(1)
                  .nullable()
                  .describe("Number of channels in the audio file")
              })
              .nullish()
              .describe('The file data you uploaded. Can be null if status is \"error\"'),
            request_params: zod
              .object({
                encoding: zod
                  .enum(["wav/pcm", "wav/alaw", "wav/ulaw"])
                  .describe(
                    "The encoding format of the audio stream. Supported formats: \n- PCM: 8, 16, 24, and 32 bits \n- A-law: 8 bits \n- Œº-law: 8 bits \n\nNote: No need to add WAV headers to raw audio as the API supports both formats."
                  )
                  .default(
                    transcriptionControllerListV2ResponseItemsItemRequestParamsEncodingDefault
                  )
                  .describe(
                    "The encoding format of the audio stream. Supported formats: \n- PCM: 8, 16, 24, and 32 bits \n- A-law: 8 bits \n- Œº-law: 8 bits \n\nNote: No need to add WAV headers to raw audio as the API supports both formats."
                  ),
                bit_depth: zod
                  .literal(8)
                  .or(zod.literal(16))
                  .or(zod.literal(24))
                  .or(zod.literal(32))
                  .describe("The bit depth of the audio stream")
                  .default(
                    transcriptionControllerListV2ResponseItemsItemRequestParamsBitDepthDefault
                  )
                  .describe("The bit depth of the audio stream"),
                sample_rate: zod
                  .literal(8000)
                  .or(zod.literal(16000))
                  .or(zod.literal(32000))
                  .or(zod.literal(44100))
                  .or(zod.literal(48000))
                  .describe("The sample rate of the audio stream")
                  .default(
                    transcriptionControllerListV2ResponseItemsItemRequestParamsSampleRateDefault
                  )
                  .describe("The sample rate of the audio stream"),
                channels: zod
                  .number()
                  .min(1)
                  .max(transcriptionControllerListV2ResponseItemsItemRequestParamsChannelsMax)
                  .default(
                    transcriptionControllerListV2ResponseItemsItemRequestParamsChannelsDefault
                  )
                  .describe("The number of channels of the audio stream"),
                model: zod
                  .enum(["solaria-1"])
                  .describe(
                    'The model used to process the audio. \"solaria-1\" is used by default.'
                  )
                  .default(transcriptionControllerListV2ResponseItemsItemRequestParamsModelDefault)
                  .describe(
                    'The model used to process the audio. \"solaria-1\" is used by default.'
                  ),
                endpointing: zod
                  .number()
                  .min(transcriptionControllerListV2ResponseItemsItemRequestParamsEndpointingMin)
                  .max(transcriptionControllerListV2ResponseItemsItemRequestParamsEndpointingMax)
                  .default(
                    transcriptionControllerListV2ResponseItemsItemRequestParamsEndpointingDefault
                  )
                  .describe(
                    "The endpointing duration in seconds. Endpointing is the duration of silence which will cause an utterance to be considered as finished"
                  ),
                maximum_duration_without_endpointing: zod
                  .number()
                  .min(
                    transcriptionControllerListV2ResponseItemsItemRequestParamsMaximumDurationWithoutEndpointingMin
                  )
                  .max(
                    transcriptionControllerListV2ResponseItemsItemRequestParamsMaximumDurationWithoutEndpointingMax
                  )
                  .default(
                    transcriptionControllerListV2ResponseItemsItemRequestParamsMaximumDurationWithoutEndpointingDefault
                  )
                  .describe(
                    "The maximum duration in seconds without endpointing. If endpointing is not detected after this duration, current utterance will be considered as finished"
                  ),
                language_config: zod
                  .object({
                    languages: zod
                      .array(
                        zod
                          .enum([
                            "af",
                            "am",
                            "ar",
                            "as",
                            "az",
                            "ba",
                            "be",
                            "bg",
                            "bn",
                            "bo",
                            "br",
                            "bs",
                            "ca",
                            "cs",
                            "cy",
                            "da",
                            "de",
                            "el",
                            "en",
                            "es",
                            "et",
                            "eu",
                            "fa",
                            "fi",
                            "fo",
                            "fr",
                            "gl",
                            "gu",
                            "ha",
                            "haw",
                            "he",
                            "hi",
                            "hr",
                            "ht",
                            "hu",
                            "hy",
                            "id",
                            "is",
                            "it",
                            "ja",
                            "jw",
                            "ka",
                            "kk",
                            "km",
                            "kn",
                            "ko",
                            "la",
                            "lb",
                            "ln",
                            "lo",
                            "lt",
                            "lv",
                            "mg",
                            "mi",
                            "mk",
                            "ml",
                            "mn",
                            "mr",
                            "ms",
                            "mt",
                            "my",
                            "ne",
                            "nl",
                            "nn",
                            "no",
                            "oc",
                            "pa",
                            "pl",
                            "ps",
                            "pt",
                            "ro",
                            "ru",
                            "sa",
                            "sd",
                            "si",
                            "sk",
                            "sl",
                            "sn",
                            "so",
                            "sq",
                            "sr",
                            "su",
                            "sv",
                            "sw",
                            "ta",
                            "te",
                            "tg",
                            "th",
                            "tk",
                            "tl",
                            "tr",
                            "tt",
                            "uk",
                            "ur",
                            "uz",
                            "vi",
                            "yi",
                            "yo",
                            "zh"
                          ])
                          .describe(
                            "Specify the language in which it will be pronounced when sound comparison occurs. Default to transcription language."
                          )
                      )
                      .default(
                        transcriptionControllerListV2ResponseItemsItemRequestParamsLanguageConfigLanguagesDefaultOne
                      )
                      .describe(
                        "If one language is set, it will be used for the transcription. Otherwise, language will be auto-detected by the model."
                      ),
                    code_switching: zod
                      .boolean()
                      .optional()
                      .describe(
                        "If true, language will be auto-detected on each utterance. Otherwise, language will be auto-detected on first utterance and then used for the rest of the transcription. If one language is set, this option will be ignored."
                      )
                  })
                  .optional()
                  .describe("Specify the language configuration"),
                pre_processing: zod
                  .object({
                    audio_enhancer: zod
                      .boolean()
                      .optional()
                      .describe(
                        "If true, apply pre-processing to the audio stream to enhance the quality."
                      ),
                    speech_threshold: zod
                      .number()
                      .min(
                        transcriptionControllerListV2ResponseItemsItemRequestParamsPreProcessingSpeechThresholdMin
                      )
                      .max(
                        transcriptionControllerListV2ResponseItemsItemRequestParamsPreProcessingSpeechThresholdMax
                      )
                      .default(
                        transcriptionControllerListV2ResponseItemsItemRequestParamsPreProcessingSpeechThresholdDefault
                      )
                      .describe(
                        "Sensitivity configuration for Speech Threshold. A value close to 1 will apply stricter thresholds, making it less likely to detect background sounds as speech."
                      )
                  })
                  .optional()
                  .describe("Specify the pre-processing configuration"),
                realtime_processing: zod
                  .object({
                    custom_vocabulary: zod
                      .boolean()
                      .optional()
                      .describe("If true, enable custom vocabulary for the transcription."),
                    custom_vocabulary_config: zod
                      .object({
                        vocabulary: zod
                          .array(
                            zod
                              .object({
                                value: zod
                                  .string()
                                  .describe("The text used to replace in the transcription."),
                                intensity: zod
                                  .number()
                                  .min(
                                    transcriptionControllerListV2ResponseItemsItemRequestParamsRealtimeProcessingCustomVocabularyConfigVocabularyItemIntensityMin
                                  )
                                  .max(
                                    transcriptionControllerListV2ResponseItemsItemRequestParamsRealtimeProcessingCustomVocabularyConfigVocabularyItemIntensityMax
                                  )
                                  .optional()
                                  .describe("The global intensity of the feature."),
                                pronunciations: zod
                                  .array(zod.string())
                                  .optional()
                                  .describe("The pronunciations used in the transcription."),
                                language: zod
                                  .enum([
                                    "af",
                                    "am",
                                    "ar",
                                    "as",
                                    "az",
                                    "ba",
                                    "be",
                                    "bg",
                                    "bn",
                                    "bo",
                                    "br",
                                    "bs",
                                    "ca",
                                    "cs",
                                    "cy",
                                    "da",
                                    "de",
                                    "el",
                                    "en",
                                    "es",
                                    "et",
                                    "eu",
                                    "fa",
                                    "fi",
                                    "fo",
                                    "fr",
                                    "gl",
                                    "gu",
                                    "ha",
                                    "haw",
                                    "he",
                                    "hi",
                                    "hr",
                                    "ht",
                                    "hu",
                                    "hy",
                                    "id",
                                    "is",
                                    "it",
                                    "ja",
                                    "jw",
                                    "ka",
                                    "kk",
                                    "km",
                                    "kn",
                                    "ko",
                                    "la",
                                    "lb",
                                    "ln",
                                    "lo",
                                    "lt",
                                    "lv",
                                    "mg",
                                    "mi",
                                    "mk",
                                    "ml",
                                    "mn",
                                    "mr",
                                    "ms",
                                    "mt",
                                    "my",
                                    "ne",
                                    "nl",
                                    "nn",
                                    "no",
                                    "oc",
                                    "pa",
                                    "pl",
                                    "ps",
                                    "pt",
                                    "ro",
                                    "ru",
                                    "sa",
                                    "sd",
                                    "si",
                                    "sk",
                                    "sl",
                                    "sn",
                                    "so",
                                    "sq",
                                    "sr",
                                    "su",
                                    "sv",
                                    "sw",
                                    "ta",
                                    "te",
                                    "tg",
                                    "th",
                                    "tk",
                                    "tl",
                                    "tr",
                                    "tt",
                                    "uk",
                                    "ur",
                                    "uz",
                                    "vi",
                                    "yi",
                                    "yo",
                                    "zh"
                                  ])
                                  .describe(
                                    "Specify the language in which it will be pronounced when sound comparison occurs. Default to transcription language."
                                  )
                                  .optional()
                                  .describe(
                                    "Specify the language in which it will be pronounced when sound comparison occurs. Default to transcription language."
                                  )
                              })
                              .or(zod.string())
                          )
                          .describe(
                            "Specific vocabulary list to feed the transcription model with. Each item can be a string or an object with the following properties: value, intensity, pronunciations, language."
                          ),
                        default_intensity: zod
                          .number()
                          .min(
                            transcriptionControllerListV2ResponseItemsItemRequestParamsRealtimeProcessingCustomVocabularyConfigDefaultIntensityMin
                          )
                          .max(
                            transcriptionControllerListV2ResponseItemsItemRequestParamsRealtimeProcessingCustomVocabularyConfigDefaultIntensityMax
                          )
                          .optional()
                          .describe("Default intensity for the custom vocabulary")
                      })
                      .optional()
                      .describe(
                        "Custom vocabulary configuration, if `custom_vocabulary` is enabled"
                      ),
                    custom_spelling: zod
                      .boolean()
                      .optional()
                      .describe("If true, enable custom spelling for the transcription."),
                    custom_spelling_config: zod
                      .object({
                        spelling_dictionary: zod
                          .record(zod.string(), zod.array(zod.string()))
                          .describe("The list of spelling applied on the audio transcription")
                      })
                      .optional()
                      .describe("Custom spelling configuration, if `custom_spelling` is enabled"),
                    translation: zod
                      .boolean()
                      .optional()
                      .describe("If true, enable translation for the transcription"),
                    translation_config: zod
                      .object({
                        target_languages: zod
                          .array(
                            zod
                              .enum([
                                "af",
                                "am",
                                "ar",
                                "as",
                                "az",
                                "ba",
                                "be",
                                "bg",
                                "bn",
                                "bo",
                                "br",
                                "bs",
                                "ca",
                                "cs",
                                "cy",
                                "da",
                                "de",
                                "el",
                                "en",
                                "es",
                                "et",
                                "eu",
                                "fa",
                                "fi",
                                "fo",
                                "fr",
                                "gl",
                                "gu",
                                "ha",
                                "haw",
                                "he",
                                "hi",
                                "hr",
                                "ht",
                                "hu",
                                "hy",
                                "id",
                                "is",
                                "it",
                                "ja",
                                "jw",
                                "ka",
                                "kk",
                                "km",
                                "kn",
                                "ko",
                                "la",
                                "lb",
                                "ln",
                                "lo",
                                "lt",
                                "lv",
                                "mg",
                                "mi",
                                "mk",
                                "ml",
                                "mn",
                                "mr",
                                "ms",
                                "mt",
                                "my",
                                "ne",
                                "nl",
                                "nn",
                                "no",
                                "oc",
                                "pa",
                                "pl",
                                "ps",
                                "pt",
                                "ro",
                                "ru",
                                "sa",
                                "sd",
                                "si",
                                "sk",
                                "sl",
                                "sn",
                                "so",
                                "sq",
                                "sr",
                                "su",
                                "sv",
                                "sw",
                                "ta",
                                "te",
                                "tg",
                                "th",
                                "tk",
                                "tl",
                                "tr",
                                "tt",
                                "uk",
                                "ur",
                                "uz",
                                "vi",
                                "wo",
                                "yi",
                                "yo",
                                "zh"
                              ])
                              .describe(
                                "Target language in `iso639-1` format you want the transcription translated to"
                              )
                          )
                          .min(1)
                          .describe(
                            "Target language in `iso639-1` format you want the transcription translated to"
                          ),
                        model: zod
                          .enum(["base", "enhanced"])
                          .describe("Model you want the translation model to use to translate")
                          .default(
                            transcriptionControllerListV2ResponseItemsItemRequestParamsRealtimeProcessingTranslationConfigModelDefault
                          )
                          .describe("Model you want the translation model to use to translate"),
                        match_original_utterances: zod
                          .boolean()
                          .default(
                            transcriptionControllerListV2ResponseItemsItemRequestParamsRealtimeProcessingTranslationConfigMatchOriginalUtterancesDefault
                          )
                          .describe("Align translated utterances with the original ones"),
                        lipsync: zod
                          .boolean()
                          .default(
                            transcriptionControllerListV2ResponseItemsItemRequestParamsRealtimeProcessingTranslationConfigLipsyncDefault
                          )
                          .describe("Whether to apply lipsync to the translated transcription. "),
                        context_adaptation: zod
                          .boolean()
                          .default(
                            transcriptionControllerListV2ResponseItemsItemRequestParamsRealtimeProcessingTranslationConfigContextAdaptationDefault
                          )
                          .describe(
                            "Enables or disables context-aware translation features that allow the model to adapt translations based on provided context."
                          ),
                        context: zod
                          .string()
                          .optional()
                          .describe("Context information to improve translation accuracy"),
                        informal: zod
                          .boolean()
                          .optional()
                          .describe(
                            "Forces the translation to use informal language forms when available in the target language."
                          )
                      })
                      .optional()
                      .describe("Translation configuration, if `translation` is enabled"),
                    named_entity_recognition: zod
                      .boolean()
                      .optional()
                      .describe("If true, enable named entity recognition for the transcription."),
                    sentiment_analysis: zod
                      .boolean()
                      .optional()
                      .describe("If true, enable sentiment analysis for the transcription.")
                  })
                  .optional()
                  .describe("Specify the realtime processing configuration"),
                post_processing: zod
                  .object({
                    summarization: zod
                      .boolean()
                      .optional()
                      .describe("If true, generates summarization for the whole transcription."),
                    summarization_config: zod
                      .object({
                        type: zod
                          .enum(["general", "bullet_points", "concise"])
                          .describe("The type of summarization to apply")
                          .default(
                            transcriptionControllerListV2ResponseItemsItemRequestParamsPostProcessingSummarizationConfigTypeDefault
                          )
                          .describe("The type of summarization to apply")
                      })
                      .optional()
                      .describe("Summarization configuration, if `summarization` is enabled"),
                    chapterization: zod
                      .boolean()
                      .optional()
                      .describe("If true, generates chapters for the whole transcription.")
                  })
                  .optional()
                  .describe("Specify the post-processing configuration"),
                messages_config: zod
                  .object({
                    receive_partial_transcripts: zod
                      .boolean()
                      .optional()
                      .describe("If true, partial transcript will be sent to websocket."),
                    receive_final_transcripts: zod
                      .boolean()
                      .default(
                        transcriptionControllerListV2ResponseItemsItemRequestParamsMessagesConfigReceiveFinalTranscriptsDefault
                      )
                      .describe("If true, final transcript will be sent to websocket."),
                    receive_speech_events: zod
                      .boolean()
                      .default(
                        transcriptionControllerListV2ResponseItemsItemRequestParamsMessagesConfigReceiveSpeechEventsDefault
                      )
                      .describe("If true, begin and end speech events will be sent to websocket."),
                    receive_pre_processing_events: zod
                      .boolean()
                      .default(
                        transcriptionControllerListV2ResponseItemsItemRequestParamsMessagesConfigReceivePreProcessingEventsDefault
                      )
                      .describe("If true, pre-processing events will be sent to websocket."),
                    receive_realtime_processing_events: zod
                      .boolean()
                      .default(
                        transcriptionControllerListV2ResponseItemsItemRequestParamsMessagesConfigReceiveRealtimeProcessingEventsDefault
                      )
                      .describe("If true, realtime processing events will be sent to websocket."),
                    receive_post_processing_events: zod
                      .boolean()
                      .default(
                        transcriptionControllerListV2ResponseItemsItemRequestParamsMessagesConfigReceivePostProcessingEventsDefault
                      )
                      .describe("If true, post-processing events will be sent to websocket."),
                    receive_acknowledgments: zod
                      .boolean()
                      .default(
                        transcriptionControllerListV2ResponseItemsItemRequestParamsMessagesConfigReceiveAcknowledgmentsDefault
                      )
                      .describe("If true, acknowledgments will be sent to websocket."),
                    receive_errors: zod
                      .boolean()
                      .default(
                        transcriptionControllerListV2ResponseItemsItemRequestParamsMessagesConfigReceiveErrorsDefault
                      )
                      .describe("If true, errors will be sent to websocket."),
                    receive_lifecycle_events: zod
                      .boolean()
                      .optional()
                      .describe("If true, lifecycle events will be sent to websocket.")
                  })
                  .optional()
                  .describe("Specify the websocket messages configuration"),
                callback: zod
                  .boolean()
                  .optional()
                  .describe("If true, messages will be sent to configured url."),
                callback_config: zod
                  .object({
                    url: zod
                      .string()
                      .url()
                      .optional()
                      .describe(
                        "URL on which we will do a `POST` request with configured messages"
                      ),
                    receive_partial_transcripts: zod
                      .boolean()
                      .optional()
                      .describe(
                        "If true, partial transcript will be sent to the defined callback."
                      ),
                    receive_final_transcripts: zod
                      .boolean()
                      .default(
                        transcriptionControllerListV2ResponseItemsItemRequestParamsCallbackConfigReceiveFinalTranscriptsDefault
                      )
                      .describe("If true, final transcript will be sent to the defined callback."),
                    receive_speech_events: zod
                      .boolean()
                      .optional()
                      .describe(
                        "If true, begin and end speech events will be sent to the defined callback."
                      ),
                    receive_pre_processing_events: zod
                      .boolean()
                      .default(
                        transcriptionControllerListV2ResponseItemsItemRequestParamsCallbackConfigReceivePreProcessingEventsDefault
                      )
                      .describe(
                        "If true, pre-processing events will be sent to the defined callback."
                      ),
                    receive_realtime_processing_events: zod
                      .boolean()
                      .default(
                        transcriptionControllerListV2ResponseItemsItemRequestParamsCallbackConfigReceiveRealtimeProcessingEventsDefault
                      )
                      .describe(
                        "If true, realtime processing events will be sent to the defined callback."
                      ),
                    receive_post_processing_events: zod
                      .boolean()
                      .default(
                        transcriptionControllerListV2ResponseItemsItemRequestParamsCallbackConfigReceivePostProcessingEventsDefault
                      )
                      .describe(
                        "If true, post-processing events will be sent to the defined callback."
                      ),
                    receive_acknowledgments: zod
                      .boolean()
                      .optional()
                      .describe("If true, acknowledgments will be sent to the defined callback."),
                    receive_errors: zod
                      .boolean()
                      .optional()
                      .describe("If true, errors will be sent to the defined callback."),
                    receive_lifecycle_events: zod
                      .boolean()
                      .default(
                        transcriptionControllerListV2ResponseItemsItemRequestParamsCallbackConfigReceiveLifecycleEventsDefault
                      )
                      .describe("If true, lifecycle events will be sent to the defined callback.")
                  })
                  .optional()
                  .describe("Specify the callback configuration")
              })
              .nullish()
              .describe(
                'Parameters used for this live transcription. Can be null if status is \"error\"'
              ),
            result: zod
              .object({
                metadata: zod
                  .object({
                    audio_duration: zod.number().describe("Duration of the transcribed audio file"),
                    number_of_distinct_channels: zod
                      .number()
                      .min(1)
                      .describe("Number of distinct channels in the transcribed audio file"),
                    billing_time: zod
                      .number()
                      .describe(
                        "Billed duration in seconds (audio_duration * number_of_distinct_channels)"
                      ),
                    transcription_time: zod
                      .number()
                      .describe("Duration of the transcription in seconds")
                  })
                  .describe("Metadata for the given transcription & audio file"),
                transcription: zod
                  .object({
                    full_transcript: zod
                      .string()
                      .describe("All transcription on text format without any other information"),
                    languages: zod
                      .array(
                        zod
                          .enum([
                            "af",
                            "am",
                            "ar",
                            "as",
                            "az",
                            "ba",
                            "be",
                            "bg",
                            "bn",
                            "bo",
                            "br",
                            "bs",
                            "ca",
                            "cs",
                            "cy",
                            "da",
                            "de",
                            "el",
                            "en",
                            "es",
                            "et",
                            "eu",
                            "fa",
                            "fi",
                            "fo",
                            "fr",
                            "gl",
                            "gu",
                            "ha",
                            "haw",
                            "he",
                            "hi",
                            "hr",
                            "ht",
                            "hu",
                            "hy",
                            "id",
                            "is",
                            "it",
                            "ja",
                            "jw",
                            "ka",
                            "kk",
                            "km",
                            "kn",
                            "ko",
                            "la",
                            "lb",
                            "ln",
                            "lo",
                            "lt",
                            "lv",
                            "mg",
                            "mi",
                            "mk",
                            "ml",
                            "mn",
                            "mr",
                            "ms",
                            "mt",
                            "my",
                            "ne",
                            "nl",
                            "nn",
                            "no",
                            "oc",
                            "pa",
                            "pl",
                            "ps",
                            "pt",
                            "ro",
                            "ru",
                            "sa",
                            "sd",
                            "si",
                            "sk",
                            "sl",
                            "sn",
                            "so",
                            "sq",
                            "sr",
                            "su",
                            "sv",
                            "sw",
                            "ta",
                            "te",
                            "tg",
                            "th",
                            "tk",
                            "tl",
                            "tr",
                            "tt",
                            "uk",
                            "ur",
                            "uz",
                            "vi",
                            "yi",
                            "yo",
                            "zh"
                          ])
                          .describe(
                            "Specify the language in which it will be pronounced when sound comparison occurs. Default to transcription language."
                          )
                      )
                      .describe(
                        "All the detected languages in the audio sorted from the most detected to the less detected"
                      ),
                    sentences: zod
                      .array(
                        zod.object({
                          success: zod
                            .boolean()
                            .describe(
                              "The audio intelligence model succeeded to get a valid output"
                            ),
                          is_empty: zod
                            .boolean()
                            .describe("The audio intelligence model returned an empty value"),
                          exec_time: zod
                            .number()
                            .describe("Time audio intelligence model took to complete the task"),
                          error: zod
                            .object({
                              status_code: zod.number().describe("Status code of the addon error"),
                              exception: zod.string().describe("Reason of the addon error"),
                              message: zod.string().describe("Detailed message of the addon error")
                            })
                            .nullable()
                            .describe(
                              "`null` if `success` is `true`. Contains the error details of the failed model"
                            ),
                          results: zod
                            .array(zod.string())
                            .nullable()
                            .describe(
                              "If `sentences` has been enabled, transcription as sentences."
                            )
                        })
                      )
                      .optional()
                      .describe("If `sentences` has been enabled, sentences results"),
                    subtitles: zod
                      .array(
                        zod.object({
                          format: zod
                            .enum(["srt", "vtt"])
                            .describe(
                              "Subtitles formats you want your transcription to be formatted to"
                            )
                            .describe("Format of the current subtitle"),
                          subtitles: zod
                            .string()
                            .describe("Transcription on the asked subtitle format")
                        })
                      )
                      .optional()
                      .describe("If `subtitles` has been enabled, subtitles results"),
                    utterances: zod
                      .array(
                        zod.object({
                          start: zod
                            .number()
                            .describe("Start timestamp in seconds of this utterance"),
                          end: zod.number().describe("End timestamp in seconds of this utterance"),
                          confidence: zod
                            .number()
                            .describe(
                              "Confidence on the transcribed utterance (1 = 100% confident)"
                            ),
                          channel: zod
                            .number()
                            .min(
                              transcriptionControllerListV2ResponseItemsItemResultTranscriptionUtterancesItemChannelMinOne
                            )
                            .describe(
                              "Audio channel of where this utterance has been transcribed from"
                            ),
                          speaker: zod
                            .number()
                            .min(
                              transcriptionControllerListV2ResponseItemsItemResultTranscriptionUtterancesItemSpeakerMinOne
                            )
                            .optional()
                            .describe("If `diarization` enabled, speaker identification number"),
                          words: zod
                            .array(
                              zod.object({
                                word: zod.string().describe("Spoken word"),
                                start: zod
                                  .number()
                                  .describe("Start timestamps in seconds of the spoken word"),
                                end: zod
                                  .number()
                                  .describe("End timestamps in seconds of the spoken word"),
                                confidence: zod
                                  .number()
                                  .describe(
                                    "Confidence on the transcribed word (1 = 100% confident)"
                                  )
                              })
                            )
                            .describe("List of words of the utterance, split by timestamp"),
                          text: zod.string().describe("Transcription for this utterance"),
                          language: zod
                            .enum([
                              "af",
                              "am",
                              "ar",
                              "as",
                              "az",
                              "ba",
                              "be",
                              "bg",
                              "bn",
                              "bo",
                              "br",
                              "bs",
                              "ca",
                              "cs",
                              "cy",
                              "da",
                              "de",
                              "el",
                              "en",
                              "es",
                              "et",
                              "eu",
                              "fa",
                              "fi",
                              "fo",
                              "fr",
                              "gl",
                              "gu",
                              "ha",
                              "haw",
                              "he",
                              "hi",
                              "hr",
                              "ht",
                              "hu",
                              "hy",
                              "id",
                              "is",
                              "it",
                              "ja",
                              "jw",
                              "ka",
                              "kk",
                              "km",
                              "kn",
                              "ko",
                              "la",
                              "lb",
                              "ln",
                              "lo",
                              "lt",
                              "lv",
                              "mg",
                              "mi",
                              "mk",
                              "ml",
                              "mn",
                              "mr",
                              "ms",
                              "mt",
                              "my",
                              "ne",
                              "nl",
                              "nn",
                              "no",
                              "oc",
                              "pa",
                              "pl",
                              "ps",
                              "pt",
                              "ro",
                              "ru",
                              "sa",
                              "sd",
                              "si",
                              "sk",
                              "sl",
                              "sn",
                              "so",
                              "sq",
                              "sr",
                              "su",
                              "sv",
                              "sw",
                              "ta",
                              "te",
                              "tg",
                              "th",
                              "tk",
                              "tl",
                              "tr",
                              "tt",
                              "uk",
                              "ur",
                              "uz",
                              "vi",
                              "yi",
                              "yo",
                              "zh"
                            ])
                            .describe(
                              "Specify the language in which it will be pronounced when sound comparison occurs. Default to transcription language."
                            )
                            .describe("Spoken language in this utterance")
                        })
                      )
                      .describe("Transcribed speech utterances present in the audio")
                  })
                  .optional()
                  .describe("Transcription of the audio speech"),
                translation: zod
                  .object({
                    success: zod
                      .boolean()
                      .describe("The audio intelligence model succeeded to get a valid output"),
                    is_empty: zod
                      .boolean()
                      .describe("The audio intelligence model returned an empty value"),
                    exec_time: zod
                      .number()
                      .describe("Time audio intelligence model took to complete the task"),
                    error: zod
                      .object({
                        status_code: zod.number().describe("Status code of the addon error"),
                        exception: zod.string().describe("Reason of the addon error"),
                        message: zod.string().describe("Detailed message of the addon error")
                      })
                      .nullable()
                      .describe(
                        "`null` if `success` is `true`. Contains the error details of the failed model"
                      ),
                    results: zod
                      .array(
                        zod.object({
                          error: zod
                            .object({
                              status_code: zod.number().describe("Status code of the addon error"),
                              exception: zod.string().describe("Reason of the addon error"),
                              message: zod.string().describe("Detailed message of the addon error")
                            })
                            .nullable()
                            .describe("Contains the error details of the failed addon"),
                          full_transcript: zod
                            .string()
                            .describe(
                              "All transcription on text format without any other information"
                            ),
                          languages: zod
                            .array(
                              zod
                                .enum([
                                  "af",
                                  "am",
                                  "ar",
                                  "as",
                                  "az",
                                  "ba",
                                  "be",
                                  "bg",
                                  "bn",
                                  "bo",
                                  "br",
                                  "bs",
                                  "ca",
                                  "cs",
                                  "cy",
                                  "da",
                                  "de",
                                  "el",
                                  "en",
                                  "es",
                                  "et",
                                  "eu",
                                  "fa",
                                  "fi",
                                  "fo",
                                  "fr",
                                  "gl",
                                  "gu",
                                  "ha",
                                  "haw",
                                  "he",
                                  "hi",
                                  "hr",
                                  "ht",
                                  "hu",
                                  "hy",
                                  "id",
                                  "is",
                                  "it",
                                  "ja",
                                  "jw",
                                  "ka",
                                  "kk",
                                  "km",
                                  "kn",
                                  "ko",
                                  "la",
                                  "lb",
                                  "ln",
                                  "lo",
                                  "lt",
                                  "lv",
                                  "mg",
                                  "mi",
                                  "mk",
                                  "ml",
                                  "mn",
                                  "mr",
                                  "ms",
                                  "mt",
                                  "my",
                                  "ne",
                                  "nl",
                                  "nn",
                                  "no",
                                  "oc",
                                  "pa",
                                  "pl",
                                  "ps",
                                  "pt",
                                  "ro",
                                  "ru",
                                  "sa",
                                  "sd",
                                  "si",
                                  "sk",
                                  "sl",
                                  "sn",
                                  "so",
                                  "sq",
                                  "sr",
                                  "su",
                                  "sv",
                                  "sw",
                                  "ta",
                                  "te",
                                  "tg",
                                  "th",
                                  "tk",
                                  "tl",
                                  "tr",
                                  "tt",
                                  "uk",
                                  "ur",
                                  "uz",
                                  "vi",
                                  "wo",
                                  "yi",
                                  "yo",
                                  "zh"
                                ])
                                .describe(
                                  "Target language in `iso639-1` format you want the transcription translated to"
                                )
                            )
                            .describe(
                              "All the detected languages in the audio sorted from the most detected to the less detected"
                            ),
                          sentences: zod
                            .array(
                              zod.object({
                                success: zod
                                  .boolean()
                                  .describe(
                                    "The audio intelligence model succeeded to get a valid output"
                                  ),
                                is_empty: zod
                                  .boolean()
                                  .describe("The audio intelligence model returned an empty value"),
                                exec_time: zod
                                  .number()
                                  .describe(
                                    "Time audio intelligence model took to complete the task"
                                  ),
                                error: zod
                                  .object({
                                    status_code: zod
                                      .number()
                                      .describe("Status code of the addon error"),
                                    exception: zod.string().describe("Reason of the addon error"),
                                    message: zod
                                      .string()
                                      .describe("Detailed message of the addon error")
                                  })
                                  .nullable()
                                  .describe(
                                    "`null` if `success` is `true`. Contains the error details of the failed model"
                                  ),
                                results: zod
                                  .array(zod.string())
                                  .nullable()
                                  .describe(
                                    "If `sentences` has been enabled, transcription as sentences."
                                  )
                              })
                            )
                            .optional()
                            .describe(
                              "If `sentences` has been enabled, sentences results for this translation"
                            ),
                          subtitles: zod
                            .array(
                              zod.object({
                                format: zod
                                  .enum(["srt", "vtt"])
                                  .describe(
                                    "Subtitles formats you want your transcription to be formatted to"
                                  )
                                  .describe("Format of the current subtitle"),
                                subtitles: zod
                                  .string()
                                  .describe("Transcription on the asked subtitle format")
                              })
                            )
                            .optional()
                            .describe(
                              "If `subtitles` has been enabled, subtitles results for this translation"
                            ),
                          utterances: zod
                            .array(
                              zod.object({
                                start: zod
                                  .number()
                                  .describe("Start timestamp in seconds of this utterance"),
                                end: zod
                                  .number()
                                  .describe("End timestamp in seconds of this utterance"),
                                confidence: zod
                                  .number()
                                  .describe(
                                    "Confidence on the transcribed utterance (1 = 100% confident)"
                                  ),
                                channel: zod
                                  .number()
                                  .min(
                                    transcriptionControllerListV2ResponseItemsItemResultTranslationResultsItemUtterancesItemChannelMinOne
                                  )
                                  .describe(
                                    "Audio channel of where this utterance has been transcribed from"
                                  ),
                                speaker: zod
                                  .number()
                                  .min(
                                    transcriptionControllerListV2ResponseItemsItemResultTranslationResultsItemUtterancesItemSpeakerMinOne
                                  )
                                  .optional()
                                  .describe(
                                    "If `diarization` enabled, speaker identification number"
                                  ),
                                words: zod
                                  .array(
                                    zod.object({
                                      word: zod.string().describe("Spoken word"),
                                      start: zod
                                        .number()
                                        .describe("Start timestamps in seconds of the spoken word"),
                                      end: zod
                                        .number()
                                        .describe("End timestamps in seconds of the spoken word"),
                                      confidence: zod
                                        .number()
                                        .describe(
                                          "Confidence on the transcribed word (1 = 100% confident)"
                                        )
                                    })
                                  )
                                  .describe("List of words of the utterance, split by timestamp"),
                                text: zod.string().describe("Transcription for this utterance"),
                                language: zod
                                  .enum([
                                    "af",
                                    "am",
                                    "ar",
                                    "as",
                                    "az",
                                    "ba",
                                    "be",
                                    "bg",
                                    "bn",
                                    "bo",
                                    "br",
                                    "bs",
                                    "ca",
                                    "cs",
                                    "cy",
                                    "da",
                                    "de",
                                    "el",
                                    "en",
                                    "es",
                                    "et",
                                    "eu",
                                    "fa",
                                    "fi",
                                    "fo",
                                    "fr",
                                    "gl",
                                    "gu",
                                    "ha",
                                    "haw",
                                    "he",
                                    "hi",
                                    "hr",
                                    "ht",
                                    "hu",
                                    "hy",
                                    "id",
                                    "is",
                                    "it",
                                    "ja",
                                    "jw",
                                    "ka",
                                    "kk",
                                    "km",
                                    "kn",
                                    "ko",
                                    "la",
                                    "lb",
                                    "ln",
                                    "lo",
                                    "lt",
                                    "lv",
                                    "mg",
                                    "mi",
                                    "mk",
                                    "ml",
                                    "mn",
                                    "mr",
                                    "ms",
                                    "mt",
                                    "my",
                                    "ne",
                                    "nl",
                                    "nn",
                                    "no",
                                    "oc",
                                    "pa",
                                    "pl",
                                    "ps",
                                    "pt",
                                    "ro",
                                    "ru",
                                    "sa",
                                    "sd",
                                    "si",
                                    "sk",
                                    "sl",
                                    "sn",
                                    "so",
                                    "sq",
                                    "sr",
                                    "su",
                                    "sv",
                                    "sw",
                                    "ta",
                                    "te",
                                    "tg",
                                    "th",
                                    "tk",
                                    "tl",
                                    "tr",
                                    "tt",
                                    "uk",
                                    "ur",
                                    "uz",
                                    "vi",
                                    "yi",
                                    "yo",
                                    "zh"
                                  ])
                                  .describe(
                                    "Specify the language in which it will be pronounced when sound comparison occurs. Default to transcription language."
                                  )
                                  .describe("Spoken language in this utterance")
                              })
                            )
                            .describe("Transcribed speech utterances present in the audio")
                        })
                      )
                      .nullable()
                      .describe(
                        "List of translated transcriptions, one for each `target_languages`"
                      )
                  })
                  .optional()
                  .describe(
                    "If `translation` has been enabled, translation of the audio speech transcription"
                  ),
                summarization: zod
                  .object({
                    success: zod
                      .boolean()
                      .describe("The audio intelligence model succeeded to get a valid output"),
                    is_empty: zod
                      .boolean()
                      .describe("The audio intelligence model returned an empty value"),
                    exec_time: zod
                      .number()
                      .describe("Time audio intelligence model took to complete the task"),
                    error: zod
                      .object({
                        status_code: zod.number().describe("Status code of the addon error"),
                        exception: zod.string().describe("Reason of the addon error"),
                        message: zod.string().describe("Detailed message of the addon error")
                      })
                      .nullable()
                      .describe(
                        "`null` if `success` is `true`. Contains the error details of the failed model"
                      ),
                    results: zod
                      .string()
                      .nullable()
                      .describe("If `summarization` has been enabled, summary of the transcription")
                  })
                  .optional()
                  .describe(
                    "If `summarization` has been enabled, summarization of the audio speech transcription"
                  ),
                named_entity_recognition: zod
                  .object({
                    success: zod
                      .boolean()
                      .describe("The audio intelligence model succeeded to get a valid output"),
                    is_empty: zod
                      .boolean()
                      .describe("The audio intelligence model returned an empty value"),
                    exec_time: zod
                      .number()
                      .describe("Time audio intelligence model took to complete the task"),
                    error: zod
                      .object({
                        status_code: zod.number().describe("Status code of the addon error"),
                        exception: zod.string().describe("Reason of the addon error"),
                        message: zod.string().describe("Detailed message of the addon error")
                      })
                      .nullable()
                      .describe(
                        "`null` if `success` is `true`. Contains the error details of the failed model"
                      ),
                    entity: zod
                      .string()
                      .describe(
                        "If `named_entity_recognition` has been enabled, the detected entities."
                      )
                  })
                  .optional()
                  .describe(
                    "If `named_entity_recognition` has been enabled, the detected entities"
                  ),
                sentiment_analysis: zod
                  .object({
                    success: zod
                      .boolean()
                      .describe("The audio intelligence model succeeded to get a valid output"),
                    is_empty: zod
                      .boolean()
                      .describe("The audio intelligence model returned an empty value"),
                    exec_time: zod
                      .number()
                      .describe("Time audio intelligence model took to complete the task"),
                    error: zod
                      .object({
                        status_code: zod.number().describe("Status code of the addon error"),
                        exception: zod.string().describe("Reason of the addon error"),
                        message: zod.string().describe("Detailed message of the addon error")
                      })
                      .nullable()
                      .describe(
                        "`null` if `success` is `true`. Contains the error details of the failed model"
                      ),
                    results: zod
                      .string()
                      .describe(
                        "If `sentiment_analysis` has been enabled, Gladia will analyze the sentiments and emotions of the audio"
                      )
                  })
                  .optional()
                  .describe(
                    "If `sentiment_analysis` has been enabled, sentiment analysis of the audio speech transcription"
                  ),
                chapterization: zod
                  .object({
                    success: zod
                      .boolean()
                      .describe("The audio intelligence model succeeded to get a valid output"),
                    is_empty: zod
                      .boolean()
                      .describe("The audio intelligence model returned an empty value"),
                    exec_time: zod
                      .number()
                      .describe("Time audio intelligence model took to complete the task"),
                    error: zod
                      .object({
                        status_code: zod.number().describe("Status code of the addon error"),
                        exception: zod.string().describe("Reason of the addon error"),
                        message: zod.string().describe("Detailed message of the addon error")
                      })
                      .nullable()
                      .describe(
                        "`null` if `success` is `true`. Contains the error details of the failed model"
                      ),
                    results: zod
                      .record(zod.string(), zod.any())
                      .describe(
                        "If `chapterization` has been enabled, will generate chapters name for different parts of the given audio."
                      )
                  })
                  .optional()
                  .describe(
                    "If `chapterization` has been enabled, will generate chapters name for different parts of the given audio."
                  ),
                messages: zod
                  .array(zod.string())
                  .optional()
                  .describe("Real-Time messages sent by the server during the live transcription")
              })
              .nullish()
              .describe('Live transcription\'s result when status is \"done\"')
          })
        )
    )
    .describe("List of transcriptions")
})

/**
 * @summary Get the transcription job's metadata
 */
export const transcriptionControllerGetTranscriptV2Params = zod.object({
  id: zod.string().describe("Id of the transcription job")
})

export const transcriptionControllerGetTranscriptV2ResponseErrorCodeMin = 400

export const transcriptionControllerGetTranscriptV2ResponseErrorCodeMax = 599
export const transcriptionControllerGetTranscriptV2ResponseKindDefault = "pre-recorded"
export const transcriptionControllerGetTranscriptV2ResponseRequestParamsCustomVocabularyDefault = false
export const transcriptionControllerGetTranscriptV2ResponseRequestParamsCustomVocabularyConfigVocabularyItemIntensityMin = 0

export const transcriptionControllerGetTranscriptV2ResponseRequestParamsCustomVocabularyConfigVocabularyItemIntensityMax = 1
export const transcriptionControllerGetTranscriptV2ResponseRequestParamsCustomVocabularyConfigDefaultIntensityMin = 0

export const transcriptionControllerGetTranscriptV2ResponseRequestParamsCustomVocabularyConfigDefaultIntensityMax = 1
export const transcriptionControllerGetTranscriptV2ResponseRequestParamsDetectLanguageDefault = true
export const transcriptionControllerGetTranscriptV2ResponseRequestParamsEnableCodeSwitchingDefault = false
export const transcriptionControllerGetTranscriptV2ResponseRequestParamsCodeSwitchingConfigLanguagesDefault =
  []
export const transcriptionControllerGetTranscriptV2ResponseRequestParamsCallbackDefault = false
export const transcriptionControllerGetTranscriptV2ResponseRequestParamsCallbackConfigMethodDefault =
  "POST"
export const transcriptionControllerGetTranscriptV2ResponseRequestParamsSubtitlesDefault = false
export const transcriptionControllerGetTranscriptV2ResponseRequestParamsSubtitlesConfigFormatsDefault: string[] =
  ["srt"]
export const transcriptionControllerGetTranscriptV2ResponseRequestParamsSubtitlesConfigMinimumDurationMin = 0
export const transcriptionControllerGetTranscriptV2ResponseRequestParamsSubtitlesConfigMaximumDurationMax = 30
export const transcriptionControllerGetTranscriptV2ResponseRequestParamsSubtitlesConfigMaximumRowsPerCaptionMax = 5
export const transcriptionControllerGetTranscriptV2ResponseRequestParamsSubtitlesConfigStyleDefault =
  "default"
export const transcriptionControllerGetTranscriptV2ResponseRequestParamsDiarizationDefault = false
export const transcriptionControllerGetTranscriptV2ResponseRequestParamsDiarizationConfigMinSpeakersMin = 0
export const transcriptionControllerGetTranscriptV2ResponseRequestParamsDiarizationConfigMaxSpeakersMin = 0
export const transcriptionControllerGetTranscriptV2ResponseRequestParamsTranslationDefault = false
export const transcriptionControllerGetTranscriptV2ResponseRequestParamsTranslationConfigModelDefault =
  "base"
export const transcriptionControllerGetTranscriptV2ResponseRequestParamsTranslationConfigMatchOriginalUtterancesDefault = true
export const transcriptionControllerGetTranscriptV2ResponseRequestParamsTranslationConfigLipsyncDefault = true
export const transcriptionControllerGetTranscriptV2ResponseRequestParamsTranslationConfigContextAdaptationDefault = true
export const transcriptionControllerGetTranscriptV2ResponseRequestParamsTranslationConfigInformalDefault = false
export const transcriptionControllerGetTranscriptV2ResponseRequestParamsSummarizationDefault = false
export const transcriptionControllerGetTranscriptV2ResponseRequestParamsSummarizationConfigTypeDefault =
  "general"
export const transcriptionControllerGetTranscriptV2ResponseRequestParamsModerationDefault = false
export const transcriptionControllerGetTranscriptV2ResponseRequestParamsNamedEntityRecognitionDefault = false
export const transcriptionControllerGetTranscriptV2ResponseRequestParamsChapterizationDefault = false
export const transcriptionControllerGetTranscriptV2ResponseRequestParamsNameConsistencyDefault = false
export const transcriptionControllerGetTranscriptV2ResponseRequestParamsCustomSpellingDefault = false
export const transcriptionControllerGetTranscriptV2ResponseRequestParamsStructuredDataExtractionDefault = false
export const transcriptionControllerGetTranscriptV2ResponseRequestParamsSentimentAnalysisDefault = false
export const transcriptionControllerGetTranscriptV2ResponseRequestParamsAudioToLlmDefault = false
export const transcriptionControllerGetTranscriptV2ResponseRequestParamsSentencesDefault = false
export const transcriptionControllerGetTranscriptV2ResponseRequestParamsDisplayModeDefault = false
export const transcriptionControllerGetTranscriptV2ResponseRequestParamsPunctuationEnhancedDefault = false
export const transcriptionControllerGetTranscriptV2ResponseRequestParamsLanguageConfigLanguagesDefault =
  []
export const transcriptionControllerGetTranscriptV2ResponseRequestParamsLanguageConfigCodeSwitchingDefault = false
export const transcriptionControllerGetTranscriptV2ResponseResultTranscriptionUtterancesItemChannelMin = 0
export const transcriptionControllerGetTranscriptV2ResponseResultTranscriptionUtterancesItemSpeakerMin = 0
export const transcriptionControllerGetTranscriptV2ResponseResultTranslationResultsItemUtterancesItemChannelMin = 0
export const transcriptionControllerGetTranscriptV2ResponseResultTranslationResultsItemUtterancesItemSpeakerMin = 0
export const transcriptionControllerGetTranscriptV2ResponseResultDiarizationResultsItemChannelMin = 0
export const transcriptionControllerGetTranscriptV2ResponseResultDiarizationResultsItemSpeakerMin = 0
export const transcriptionControllerGetTranscriptV2ResponseErrorCodeMinOne = 400

export const transcriptionControllerGetTranscriptV2ResponseErrorCodeMaxOne = 599
export const transcriptionControllerGetTranscriptV2ResponseKindDefaultOne = "live"
export const transcriptionControllerGetTranscriptV2ResponseRequestParamsEncodingDefault = "wav/pcm"
export const transcriptionControllerGetTranscriptV2ResponseRequestParamsBitDepthDefault = 16
export const transcriptionControllerGetTranscriptV2ResponseRequestParamsSampleRateDefault = 16000
export const transcriptionControllerGetTranscriptV2ResponseRequestParamsChannelsDefault = 1
export const transcriptionControllerGetTranscriptV2ResponseRequestParamsChannelsMax = 8
export const transcriptionControllerGetTranscriptV2ResponseRequestParamsModelDefault = "solaria-1"
export const transcriptionControllerGetTranscriptV2ResponseRequestParamsEndpointingDefault = 0.05
export const transcriptionControllerGetTranscriptV2ResponseRequestParamsEndpointingMin = 0.01

export const transcriptionControllerGetTranscriptV2ResponseRequestParamsEndpointingMax = 10
export const transcriptionControllerGetTranscriptV2ResponseRequestParamsMaximumDurationWithoutEndpointingDefault = 5
export const transcriptionControllerGetTranscriptV2ResponseRequestParamsMaximumDurationWithoutEndpointingMin = 5

export const transcriptionControllerGetTranscriptV2ResponseRequestParamsMaximumDurationWithoutEndpointingMax = 60
export const transcriptionControllerGetTranscriptV2ResponseRequestParamsLanguageConfigLanguagesDefaultOne =
  []
export const transcriptionControllerGetTranscriptV2ResponseRequestParamsLanguageConfigCodeSwitchingDefaultOne = false
export const transcriptionControllerGetTranscriptV2ResponseRequestParamsPreProcessingAudioEnhancerDefault = false
export const transcriptionControllerGetTranscriptV2ResponseRequestParamsPreProcessingSpeechThresholdDefault = 0.6
export const transcriptionControllerGetTranscriptV2ResponseRequestParamsPreProcessingSpeechThresholdMin = 0

export const transcriptionControllerGetTranscriptV2ResponseRequestParamsPreProcessingSpeechThresholdMax = 1
export const transcriptionControllerGetTranscriptV2ResponseRequestParamsRealtimeProcessingCustomVocabularyDefault = false
export const transcriptionControllerGetTranscriptV2ResponseRequestParamsRealtimeProcessingCustomVocabularyConfigVocabularyItemIntensityMin = 0

export const transcriptionControllerGetTranscriptV2ResponseRequestParamsRealtimeProcessingCustomVocabularyConfigVocabularyItemIntensityMax = 1
export const transcriptionControllerGetTranscriptV2ResponseRequestParamsRealtimeProcessingCustomVocabularyConfigDefaultIntensityMin = 0

export const transcriptionControllerGetTranscriptV2ResponseRequestParamsRealtimeProcessingCustomVocabularyConfigDefaultIntensityMax = 1
export const transcriptionControllerGetTranscriptV2ResponseRequestParamsRealtimeProcessingCustomSpellingDefault = false
export const transcriptionControllerGetTranscriptV2ResponseRequestParamsRealtimeProcessingTranslationDefault = false
export const transcriptionControllerGetTranscriptV2ResponseRequestParamsRealtimeProcessingTranslationConfigModelDefault =
  "base"
export const transcriptionControllerGetTranscriptV2ResponseRequestParamsRealtimeProcessingTranslationConfigMatchOriginalUtterancesDefault = true
export const transcriptionControllerGetTranscriptV2ResponseRequestParamsRealtimeProcessingTranslationConfigLipsyncDefault = true
export const transcriptionControllerGetTranscriptV2ResponseRequestParamsRealtimeProcessingTranslationConfigContextAdaptationDefault = true
export const transcriptionControllerGetTranscriptV2ResponseRequestParamsRealtimeProcessingTranslationConfigInformalDefault = false
export const transcriptionControllerGetTranscriptV2ResponseRequestParamsRealtimeProcessingNamedEntityRecognitionDefault = false
export const transcriptionControllerGetTranscriptV2ResponseRequestParamsRealtimeProcessingSentimentAnalysisDefault = false
export const transcriptionControllerGetTranscriptV2ResponseRequestParamsPostProcessingSummarizationDefault = false
export const transcriptionControllerGetTranscriptV2ResponseRequestParamsPostProcessingSummarizationConfigTypeDefault =
  "general"
export const transcriptionControllerGetTranscriptV2ResponseRequestParamsPostProcessingChapterizationDefault = false
export const transcriptionControllerGetTranscriptV2ResponseRequestParamsMessagesConfigReceivePartialTranscriptsDefault = false
export const transcriptionControllerGetTranscriptV2ResponseRequestParamsMessagesConfigReceiveFinalTranscriptsDefault = true
export const transcriptionControllerGetTranscriptV2ResponseRequestParamsMessagesConfigReceiveSpeechEventsDefault = true
export const transcriptionControllerGetTranscriptV2ResponseRequestParamsMessagesConfigReceivePreProcessingEventsDefault = true
export const transcriptionControllerGetTranscriptV2ResponseRequestParamsMessagesConfigReceiveRealtimeProcessingEventsDefault = true
export const transcriptionControllerGetTranscriptV2ResponseRequestParamsMessagesConfigReceivePostProcessingEventsDefault = true
export const transcriptionControllerGetTranscriptV2ResponseRequestParamsMessagesConfigReceiveAcknowledgmentsDefault = true
export const transcriptionControllerGetTranscriptV2ResponseRequestParamsMessagesConfigReceiveErrorsDefault = true
export const transcriptionControllerGetTranscriptV2ResponseRequestParamsMessagesConfigReceiveLifecycleEventsDefault = false
export const transcriptionControllerGetTranscriptV2ResponseRequestParamsCallbackDefaultOne = false
export const transcriptionControllerGetTranscriptV2ResponseRequestParamsCallbackConfigReceivePartialTranscriptsDefault = false
export const transcriptionControllerGetTranscriptV2ResponseRequestParamsCallbackConfigReceiveFinalTranscriptsDefault = true
export const transcriptionControllerGetTranscriptV2ResponseRequestParamsCallbackConfigReceiveSpeechEventsDefault = false
export const transcriptionControllerGetTranscriptV2ResponseRequestParamsCallbackConfigReceivePreProcessingEventsDefault = true
export const transcriptionControllerGetTranscriptV2ResponseRequestParamsCallbackConfigReceiveRealtimeProcessingEventsDefault = true
export const transcriptionControllerGetTranscriptV2ResponseRequestParamsCallbackConfigReceivePostProcessingEventsDefault = true
export const transcriptionControllerGetTranscriptV2ResponseRequestParamsCallbackConfigReceiveAcknowledgmentsDefault = false
export const transcriptionControllerGetTranscriptV2ResponseRequestParamsCallbackConfigReceiveErrorsDefault = false
export const transcriptionControllerGetTranscriptV2ResponseRequestParamsCallbackConfigReceiveLifecycleEventsDefault = true
export const transcriptionControllerGetTranscriptV2ResponseResultTranscriptionUtterancesItemChannelMinOne = 0
export const transcriptionControllerGetTranscriptV2ResponseResultTranscriptionUtterancesItemSpeakerMinOne = 0
export const transcriptionControllerGetTranscriptV2ResponseResultTranslationResultsItemUtterancesItemChannelMinOne = 0
export const transcriptionControllerGetTranscriptV2ResponseResultTranslationResultsItemUtterancesItemSpeakerMinOne = 0

export const transcriptionControllerGetTranscriptV2Response = zod.discriminatedUnion("kind", [
  zod.object({
    id: zod.string().uuid().describe("Id of the job"),
    request_id: zod.string().describe("Debug id"),
    version: zod.number().describe("API version"),
    status: zod
      .enum(["queued", "processing", "done", "error"])
      .describe(
        '\"queued\": the job has been queued. \"processing\": the job is being processed. \"done\": the job has been processed and the result is available. \"error\": an error occurred during the job\'s processing.'
      ),
    created_at: zod.string().datetime({}).describe("Creation date"),
    completed_at: zod
      .string()
      .datetime({})
      .nullish()
      .describe('Completion date when status is \"done\" or \"error\"'),
    custom_metadata: zod
      .record(zod.string(), zod.any())
      .optional()
      .describe("Custom metadata given in the initial request"),
    error_code: zod
      .number()
      .min(transcriptionControllerGetTranscriptV2ResponseErrorCodeMin)
      .max(transcriptionControllerGetTranscriptV2ResponseErrorCodeMax)
      .nullish()
      .describe('HTTP status code of the error if status is \"error\"'),
    post_session_metadata: zod
      .object({})
      .describe("For debugging purposes, send data that could help to identify issues"),
    kind: zod.enum(["pre-recorded"]),
    file: zod
      .object({
        id: zod.string().describe("The file id"),
        filename: zod.string().nullable().describe("The name of the uploaded file"),
        source: zod
          .string()
          .nullable()
          .describe("The link used to download the file if audio_url was used"),
        audio_duration: zod.number().nullable().describe("Duration of the audio file"),
        number_of_channels: zod
          .number()
          .min(1)
          .nullable()
          .describe("Number of channels in the audio file")
      })
      .nullish()
      .describe('The file data you uploaded. Can be null if status is \"error\"'),
    request_params: zod
      .object({
        context_prompt: zod
          .string()
          .optional()
          .describe(
            "**[Deprecated]** Context to feed the transcription model with for possible better accuracy"
          ),
        custom_vocabulary: zod
          .boolean()
          .optional()
          .describe(
            "**[Beta]** Can be either boolean to enable custom_vocabulary for this audio or an array with specific vocabulary list to feed the transcription model with"
          ),
        custom_vocabulary_config: zod
          .object({
            vocabulary: zod
              .array(
                zod
                  .object({
                    value: zod.string().describe("The text used to replace in the transcription."),
                    intensity: zod
                      .number()
                      .min(
                        transcriptionControllerGetTranscriptV2ResponseRequestParamsCustomVocabularyConfigVocabularyItemIntensityMin
                      )
                      .max(
                        transcriptionControllerGetTranscriptV2ResponseRequestParamsCustomVocabularyConfigVocabularyItemIntensityMax
                      )
                      .optional()
                      .describe("The global intensity of the feature."),
                    pronunciations: zod
                      .array(zod.string())
                      .optional()
                      .describe("The pronunciations used in the transcription."),
                    language: zod
                      .enum([
                        "af",
                        "am",
                        "ar",
                        "as",
                        "az",
                        "ba",
                        "be",
                        "bg",
                        "bn",
                        "bo",
                        "br",
                        "bs",
                        "ca",
                        "cs",
                        "cy",
                        "da",
                        "de",
                        "el",
                        "en",
                        "es",
                        "et",
                        "eu",
                        "fa",
                        "fi",
                        "fo",
                        "fr",
                        "gl",
                        "gu",
                        "ha",
                        "haw",
                        "he",
                        "hi",
                        "hr",
                        "ht",
                        "hu",
                        "hy",
                        "id",
                        "is",
                        "it",
                        "ja",
                        "jw",
                        "ka",
                        "kk",
                        "km",
                        "kn",
                        "ko",
                        "la",
                        "lb",
                        "ln",
                        "lo",
                        "lt",
                        "lv",
                        "mg",
                        "mi",
                        "mk",
                        "ml",
                        "mn",
                        "mr",
                        "ms",
                        "mt",
                        "my",
                        "ne",
                        "nl",
                        "nn",
                        "no",
                        "oc",
                        "pa",
                        "pl",
                        "ps",
                        "pt",
                        "ro",
                        "ru",
                        "sa",
                        "sd",
                        "si",
                        "sk",
                        "sl",
                        "sn",
                        "so",
                        "sq",
                        "sr",
                        "su",
                        "sv",
                        "sw",
                        "ta",
                        "te",
                        "tg",
                        "th",
                        "tk",
                        "tl",
                        "tr",
                        "tt",
                        "uk",
                        "ur",
                        "uz",
                        "vi",
                        "yi",
                        "yo",
                        "zh"
                      ])
                      .describe(
                        "Specify the language in which it will be pronounced when sound comparison occurs. Default to transcription language."
                      )
                      .optional()
                      .describe(
                        "Specify the language in which it will be pronounced when sound comparison occurs. Default to transcription language."
                      )
                  })
                  .or(zod.string())
              )
              .describe(
                "Specific vocabulary list to feed the transcription model with. Each item can be a string or an object with the following properties: value, intensity, pronunciations, language."
              ),
            default_intensity: zod
              .number()
              .min(
                transcriptionControllerGetTranscriptV2ResponseRequestParamsCustomVocabularyConfigDefaultIntensityMin
              )
              .max(
                transcriptionControllerGetTranscriptV2ResponseRequestParamsCustomVocabularyConfigDefaultIntensityMax
              )
              .optional()
              .describe("Default intensity for the custom vocabulary")
          })
          .optional()
          .describe(
            "**[Beta]** Custom vocabulary configuration, if `custom_vocabulary` is enabled"
          ),
        detect_language: zod
          .boolean()
          .default(transcriptionControllerGetTranscriptV2ResponseRequestParamsDetectLanguageDefault)
          .describe(
            "**[Deprecated]** Use `language_config` instead. Detect the language from the given audio"
          ),
        enable_code_switching: zod
          .boolean()
          .optional()
          .describe(
            "**[Deprecated]** Use `language_config` instead.Detect multiple languages in the given audio"
          ),
        code_switching_config: zod
          .object({
            languages: zod
              .array(
                zod
                  .enum([
                    "af",
                    "am",
                    "ar",
                    "as",
                    "az",
                    "ba",
                    "be",
                    "bg",
                    "bn",
                    "bo",
                    "br",
                    "bs",
                    "ca",
                    "cs",
                    "cy",
                    "da",
                    "de",
                    "el",
                    "en",
                    "es",
                    "et",
                    "eu",
                    "fa",
                    "fi",
                    "fo",
                    "fr",
                    "gl",
                    "gu",
                    "ha",
                    "haw",
                    "he",
                    "hi",
                    "hr",
                    "ht",
                    "hu",
                    "hy",
                    "id",
                    "is",
                    "it",
                    "ja",
                    "jw",
                    "ka",
                    "kk",
                    "km",
                    "kn",
                    "ko",
                    "la",
                    "lb",
                    "ln",
                    "lo",
                    "lt",
                    "lv",
                    "mg",
                    "mi",
                    "mk",
                    "ml",
                    "mn",
                    "mr",
                    "ms",
                    "mt",
                    "my",
                    "ne",
                    "nl",
                    "nn",
                    "no",
                    "oc",
                    "pa",
                    "pl",
                    "ps",
                    "pt",
                    "ro",
                    "ru",
                    "sa",
                    "sd",
                    "si",
                    "sk",
                    "sl",
                    "sn",
                    "so",
                    "sq",
                    "sr",
                    "su",
                    "sv",
                    "sw",
                    "ta",
                    "te",
                    "tg",
                    "th",
                    "tk",
                    "tl",
                    "tr",
                    "tt",
                    "uk",
                    "ur",
                    "uz",
                    "vi",
                    "yi",
                    "yo",
                    "zh"
                  ])
                  .describe(
                    "Specify the language in which it will be pronounced when sound comparison occurs. Default to transcription language."
                  )
              )
              .default(
                transcriptionControllerGetTranscriptV2ResponseRequestParamsCodeSwitchingConfigLanguagesDefault
              )
              .describe("Specify the languages you want to use when detecting multiple languages")
          })
          .optional()
          .describe(
            "**[Deprecated]** Use `language_config` instead. Specify the configuration for code switching"
          ),
        language: zod
          .enum([
            "af",
            "am",
            "ar",
            "as",
            "az",
            "ba",
            "be",
            "bg",
            "bn",
            "bo",
            "br",
            "bs",
            "ca",
            "cs",
            "cy",
            "da",
            "de",
            "el",
            "en",
            "es",
            "et",
            "eu",
            "fa",
            "fi",
            "fo",
            "fr",
            "gl",
            "gu",
            "ha",
            "haw",
            "he",
            "hi",
            "hr",
            "ht",
            "hu",
            "hy",
            "id",
            "is",
            "it",
            "ja",
            "jw",
            "ka",
            "kk",
            "km",
            "kn",
            "ko",
            "la",
            "lb",
            "ln",
            "lo",
            "lt",
            "lv",
            "mg",
            "mi",
            "mk",
            "ml",
            "mn",
            "mr",
            "ms",
            "mt",
            "my",
            "ne",
            "nl",
            "nn",
            "no",
            "oc",
            "pa",
            "pl",
            "ps",
            "pt",
            "ro",
            "ru",
            "sa",
            "sd",
            "si",
            "sk",
            "sl",
            "sn",
            "so",
            "sq",
            "sr",
            "su",
            "sv",
            "sw",
            "ta",
            "te",
            "tg",
            "th",
            "tk",
            "tl",
            "tr",
            "tt",
            "uk",
            "ur",
            "uz",
            "vi",
            "yi",
            "yo",
            "zh"
          ])
          .describe(
            "Specify the language in which it will be pronounced when sound comparison occurs. Default to transcription language."
          )
          .optional()
          .describe(
            "**[Deprecated]** Use `language_config` instead. Set the spoken language for the given audio (ISO 639 standard)"
          ),
        callback_url: zod
          .string()
          .url()
          .optional()
          .describe(
            "**[Deprecated]** Use `callback`/`callback_config` instead. Callback URL we will do a `POST` request to with the result of the transcription"
          ),
        callback: zod
          .boolean()
          .optional()
          .describe(
            "Enable callback for this transcription. If true, the `callback_config` property will be used to customize the callback behaviour"
          ),
        callback_config: zod
          .object({
            url: zod
              .string()
              .url()
              .describe("The URL to be called with the result of the transcription"),
            method: zod
              .enum(["POST", "PUT"])
              .describe(
                "The HTTP method to be used. Allowed values are `POST` or `PUT` (default: `POST`)"
              )
              .default(
                transcriptionControllerGetTranscriptV2ResponseRequestParamsCallbackConfigMethodDefault
              )
              .describe(
                "The HTTP method to be used. Allowed values are `POST` or `PUT` (default: `POST`)"
              )
          })
          .optional()
          .describe("Customize the callback behaviour (url and http method)"),
        subtitles: zod
          .boolean()
          .optional()
          .describe("Enable subtitles generation for this transcription"),
        subtitles_config: zod
          .object({
            formats: zod
              .array(
                zod
                  .enum(["srt", "vtt"])
                  .describe("Subtitles formats you want your transcription to be formatted to")
              )
              .min(1)
              .default(
                transcriptionControllerGetTranscriptV2ResponseRequestParamsSubtitlesConfigFormatsDefault
              )
              .describe("Subtitles formats you want your transcription to be formatted to"),
            minimum_duration: zod
              .number()
              .min(
                transcriptionControllerGetTranscriptV2ResponseRequestParamsSubtitlesConfigMinimumDurationMin
              )
              .optional()
              .describe("Minimum duration of a subtitle in seconds"),
            maximum_duration: zod
              .number()
              .min(1)
              .max(
                transcriptionControllerGetTranscriptV2ResponseRequestParamsSubtitlesConfigMaximumDurationMax
              )
              .optional()
              .describe("Maximum duration of a subtitle in seconds"),
            maximum_characters_per_row: zod
              .number()
              .min(1)
              .optional()
              .describe("Maximum number of characters per row in a subtitle"),
            maximum_rows_per_caption: zod
              .number()
              .min(1)
              .max(
                transcriptionControllerGetTranscriptV2ResponseRequestParamsSubtitlesConfigMaximumRowsPerCaptionMax
              )
              .optional()
              .describe("Maximum number of rows per caption"),
            style: zod
              .enum(["default", "compliance"])
              .describe(
                "Style of the subtitles. Compliance mode refers to : https://loc.gov/preservation/digital/formats//fdd/fdd000569.shtml#:~:text=SRT%20files%20are%20basic%20text,alongside%2C%20example%3A%20%22MyVideo123 "
              )
              .default(
                transcriptionControllerGetTranscriptV2ResponseRequestParamsSubtitlesConfigStyleDefault
              )
              .describe(
                "Style of the subtitles. Compliance mode refers to : https://loc.gov/preservation/digital/formats//fdd/fdd000569.shtml#:~:text=SRT%20files%20are%20basic%20text,alongside%2C%20example%3A%20%22MyVideo123 "
              )
          })
          .optional()
          .describe("Configuration for subtitles generation if `subtitles` is enabled"),
        diarization: zod
          .boolean()
          .optional()
          .describe("Enable speaker recognition (diarization) for this audio"),
        diarization_config: zod
          .object({
            number_of_speakers: zod
              .number()
              .min(1)
              .optional()
              .describe("Exact number of speakers in the audio"),
            min_speakers: zod
              .number()
              .min(
                transcriptionControllerGetTranscriptV2ResponseRequestParamsDiarizationConfigMinSpeakersMin
              )
              .optional()
              .describe("Minimum number of speakers in the audio"),
            max_speakers: zod
              .number()
              .min(
                transcriptionControllerGetTranscriptV2ResponseRequestParamsDiarizationConfigMaxSpeakersMin
              )
              .optional()
              .describe("Maximum number of speakers in the audio")
          })
          .optional()
          .describe("Speaker recognition configuration, if `diarization` is enabled"),
        translation: zod
          .boolean()
          .optional()
          .describe("**[Beta]** Enable translation for this audio"),
        translation_config: zod
          .object({
            target_languages: zod
              .array(
                zod
                  .enum([
                    "af",
                    "am",
                    "ar",
                    "as",
                    "az",
                    "ba",
                    "be",
                    "bg",
                    "bn",
                    "bo",
                    "br",
                    "bs",
                    "ca",
                    "cs",
                    "cy",
                    "da",
                    "de",
                    "el",
                    "en",
                    "es",
                    "et",
                    "eu",
                    "fa",
                    "fi",
                    "fo",
                    "fr",
                    "gl",
                    "gu",
                    "ha",
                    "haw",
                    "he",
                    "hi",
                    "hr",
                    "ht",
                    "hu",
                    "hy",
                    "id",
                    "is",
                    "it",
                    "ja",
                    "jw",
                    "ka",
                    "kk",
                    "km",
                    "kn",
                    "ko",
                    "la",
                    "lb",
                    "ln",
                    "lo",
                    "lt",
                    "lv",
                    "mg",
                    "mi",
                    "mk",
                    "ml",
                    "mn",
                    "mr",
                    "ms",
                    "mt",
                    "my",
                    "ne",
                    "nl",
                    "nn",
                    "no",
                    "oc",
                    "pa",
                    "pl",
                    "ps",
                    "pt",
                    "ro",
                    "ru",
                    "sa",
                    "sd",
                    "si",
                    "sk",
                    "sl",
                    "sn",
                    "so",
                    "sq",
                    "sr",
                    "su",
                    "sv",
                    "sw",
                    "ta",
                    "te",
                    "tg",
                    "th",
                    "tk",
                    "tl",
                    "tr",
                    "tt",
                    "uk",
                    "ur",
                    "uz",
                    "vi",
                    "wo",
                    "yi",
                    "yo",
                    "zh"
                  ])
                  .describe(
                    "Target language in `iso639-1` format you want the transcription translated to"
                  )
              )
              .min(1)
              .describe(
                "Target language in `iso639-1` format you want the transcription translated to"
              ),
            model: zod
              .enum(["base", "enhanced"])
              .describe("Model you want the translation model to use to translate")
              .default(
                transcriptionControllerGetTranscriptV2ResponseRequestParamsTranslationConfigModelDefault
              )
              .describe("Model you want the translation model to use to translate"),
            match_original_utterances: zod
              .boolean()
              .default(
                transcriptionControllerGetTranscriptV2ResponseRequestParamsTranslationConfigMatchOriginalUtterancesDefault
              )
              .describe("Align translated utterances with the original ones"),
            lipsync: zod
              .boolean()
              .default(
                transcriptionControllerGetTranscriptV2ResponseRequestParamsTranslationConfigLipsyncDefault
              )
              .describe("Whether to apply lipsync to the translated transcription. "),
            context_adaptation: zod
              .boolean()
              .default(
                transcriptionControllerGetTranscriptV2ResponseRequestParamsTranslationConfigContextAdaptationDefault
              )
              .describe(
                "Enables or disables context-aware translation features that allow the model to adapt translations based on provided context."
              ),
            context: zod
              .string()
              .optional()
              .describe("Context information to improve translation accuracy"),
            informal: zod
              .boolean()
              .optional()
              .describe(
                "Forces the translation to use informal language forms when available in the target language."
              )
          })
          .optional()
          .describe("**[Beta]** Translation configuration, if `translation` is enabled"),
        summarization: zod
          .boolean()
          .optional()
          .describe("**[Beta]** Enable summarization for this audio"),
        summarization_config: zod
          .object({
            type: zod
              .enum(["general", "bullet_points", "concise"])
              .describe("The type of summarization to apply")
              .default(
                transcriptionControllerGetTranscriptV2ResponseRequestParamsSummarizationConfigTypeDefault
              )
              .describe("The type of summarization to apply")
          })
          .optional()
          .describe("**[Beta]** Summarization configuration, if `summarization` is enabled"),
        moderation: zod
          .boolean()
          .optional()
          .describe("**[Alpha]** Enable moderation for this audio"),
        named_entity_recognition: zod
          .boolean()
          .optional()
          .describe("**[Alpha]** Enable named entity recognition for this audio"),
        chapterization: zod
          .boolean()
          .optional()
          .describe("**[Alpha]** Enable chapterization for this audio"),
        name_consistency: zod
          .boolean()
          .optional()
          .describe("**[Alpha]** Enable names consistency for this audio"),
        custom_spelling: zod
          .boolean()
          .optional()
          .describe("**[Alpha]** Enable custom spelling for this audio"),
        custom_spelling_config: zod
          .object({
            spelling_dictionary: zod
              .record(zod.string(), zod.array(zod.string()))
              .describe("The list of spelling applied on the audio transcription")
          })
          .optional()
          .describe("**[Alpha]** Custom spelling configuration, if `custom_spelling` is enabled"),
        structured_data_extraction: zod
          .boolean()
          .optional()
          .describe("**[Alpha]** Enable structured data extraction for this audio"),
        structured_data_extraction_config: zod
          .object({
            classes: zod
              .array(zod.array(zod.unknown()))
              .min(1)
              .describe("The list of classes to extract from the audio transcription")
          })
          .optional()
          .describe(
            "**[Alpha]** Structured data extraction configuration, if `structured_data_extraction` is enabled"
          ),
        sentiment_analysis: zod
          .boolean()
          .optional()
          .describe("Enable sentiment analysis for this audio"),
        audio_to_llm: zod
          .boolean()
          .optional()
          .describe("**[Alpha]** Enable audio to llm processing for this audio"),
        audio_to_llm_config: zod
          .object({
            prompts: zod
              .array(zod.array(zod.unknown()))
              .min(1)
              .describe("The list of prompts applied on the audio transcription")
          })
          .optional()
          .describe("**[Alpha]** Audio to llm configuration, if `audio_to_llm` is enabled"),
        sentences: zod.boolean().optional().describe("Enable sentences for this audio"),
        display_mode: zod
          .boolean()
          .optional()
          .describe(
            "**[Alpha]** Allows to change the output display_mode for this audio. The output will be reordered, creating new utterances when speakers overlapped"
          ),
        punctuation_enhanced: zod
          .boolean()
          .optional()
          .describe("**[Alpha]** Use enhanced punctuation for this audio"),
        language_config: zod
          .object({
            languages: zod
              .array(
                zod
                  .enum([
                    "af",
                    "am",
                    "ar",
                    "as",
                    "az",
                    "ba",
                    "be",
                    "bg",
                    "bn",
                    "bo",
                    "br",
                    "bs",
                    "ca",
                    "cs",
                    "cy",
                    "da",
                    "de",
                    "el",
                    "en",
                    "es",
                    "et",
                    "eu",
                    "fa",
                    "fi",
                    "fo",
                    "fr",
                    "gl",
                    "gu",
                    "ha",
                    "haw",
                    "he",
                    "hi",
                    "hr",
                    "ht",
                    "hu",
                    "hy",
                    "id",
                    "is",
                    "it",
                    "ja",
                    "jw",
                    "ka",
                    "kk",
                    "km",
                    "kn",
                    "ko",
                    "la",
                    "lb",
                    "ln",
                    "lo",
                    "lt",
                    "lv",
                    "mg",
                    "mi",
                    "mk",
                    "ml",
                    "mn",
                    "mr",
                    "ms",
                    "mt",
                    "my",
                    "ne",
                    "nl",
                    "nn",
                    "no",
                    "oc",
                    "pa",
                    "pl",
                    "ps",
                    "pt",
                    "ro",
                    "ru",
                    "sa",
                    "sd",
                    "si",
                    "sk",
                    "sl",
                    "sn",
                    "so",
                    "sq",
                    "sr",
                    "su",
                    "sv",
                    "sw",
                    "ta",
                    "te",
                    "tg",
                    "th",
                    "tk",
                    "tl",
                    "tr",
                    "tt",
                    "uk",
                    "ur",
                    "uz",
                    "vi",
                    "yi",
                    "yo",
                    "zh"
                  ])
                  .describe(
                    "Specify the language in which it will be pronounced when sound comparison occurs. Default to transcription language."
                  )
              )
              .default(
                transcriptionControllerGetTranscriptV2ResponseRequestParamsLanguageConfigLanguagesDefault
              )
              .describe(
                "If one language is set, it will be used for the transcription. Otherwise, language will be auto-detected by the model."
              ),
            code_switching: zod
              .boolean()
              .optional()
              .describe(
                "If true, language will be auto-detected on each utterance. Otherwise, language will be auto-detected on first utterance and then used for the rest of the transcription. If one language is set, this option will be ignored."
              )
          })
          .optional()
          .describe("Specify the language configuration"),
        audio_url: zod.string().url().nullable()
      })
      .nullish()
      .describe(
        'Parameters used for this pre-recorded transcription. Can be null if status is \"error\"'
      ),
    result: zod
      .object({
        metadata: zod
          .object({
            audio_duration: zod.number().describe("Duration of the transcribed audio file"),
            number_of_distinct_channels: zod
              .number()
              .min(1)
              .describe("Number of distinct channels in the transcribed audio file"),
            billing_time: zod
              .number()
              .describe(
                "Billed duration in seconds (audio_duration * number_of_distinct_channels)"
              ),
            transcription_time: zod.number().describe("Duration of the transcription in seconds")
          })
          .describe("Metadata for the given transcription & audio file"),
        transcription: zod
          .object({
            full_transcript: zod
              .string()
              .describe("All transcription on text format without any other information"),
            languages: zod
              .array(
                zod
                  .enum([
                    "af",
                    "am",
                    "ar",
                    "as",
                    "az",
                    "ba",
                    "be",
                    "bg",
                    "bn",
                    "bo",
                    "br",
                    "bs",
                    "ca",
                    "cs",
                    "cy",
                    "da",
                    "de",
                    "el",
                    "en",
                    "es",
                    "et",
                    "eu",
                    "fa",
                    "fi",
                    "fo",
                    "fr",
                    "gl",
                    "gu",
                    "ha",
                    "haw",
                    "he",
                    "hi",
                    "hr",
                    "ht",
                    "hu",
                    "hy",
                    "id",
                    "is",
                    "it",
                    "ja",
                    "jw",
                    "ka",
                    "kk",
                    "km",
                    "kn",
                    "ko",
                    "la",
                    "lb",
                    "ln",
                    "lo",
                    "lt",
                    "lv",
                    "mg",
                    "mi",
                    "mk",
                    "ml",
                    "mn",
                    "mr",
                    "ms",
                    "mt",
                    "my",
                    "ne",
                    "nl",
                    "nn",
                    "no",
                    "oc",
                    "pa",
                    "pl",
                    "ps",
                    "pt",
                    "ro",
                    "ru",
                    "sa",
                    "sd",
                    "si",
                    "sk",
                    "sl",
                    "sn",
                    "so",
                    "sq",
                    "sr",
                    "su",
                    "sv",
                    "sw",
                    "ta",
                    "te",
                    "tg",
                    "th",
                    "tk",
                    "tl",
                    "tr",
                    "tt",
                    "uk",
                    "ur",
                    "uz",
                    "vi",
                    "yi",
                    "yo",
                    "zh"
                  ])
                  .describe(
                    "Specify the language in which it will be pronounced when sound comparison occurs. Default to transcription language."
                  )
              )
              .describe(
                "All the detected languages in the audio sorted from the most detected to the less detected"
              ),
            sentences: zod
              .array(
                zod.object({
                  success: zod
                    .boolean()
                    .describe("The audio intelligence model succeeded to get a valid output"),
                  is_empty: zod
                    .boolean()
                    .describe("The audio intelligence model returned an empty value"),
                  exec_time: zod
                    .number()
                    .describe("Time audio intelligence model took to complete the task"),
                  error: zod
                    .object({
                      status_code: zod.number().describe("Status code of the addon error"),
                      exception: zod.string().describe("Reason of the addon error"),
                      message: zod.string().describe("Detailed message of the addon error")
                    })
                    .nullable()
                    .describe(
                      "`null` if `success` is `true`. Contains the error details of the failed model"
                    ),
                  results: zod
                    .array(zod.string())
                    .nullable()
                    .describe("If `sentences` has been enabled, transcription as sentences.")
                })
              )
              .optional()
              .describe("If `sentences` has been enabled, sentences results"),
            subtitles: zod
              .array(
                zod.object({
                  format: zod
                    .enum(["srt", "vtt"])
                    .describe("Subtitles formats you want your transcription to be formatted to")
                    .describe("Format of the current subtitle"),
                  subtitles: zod.string().describe("Transcription on the asked subtitle format")
                })
              )
              .optional()
              .describe("If `subtitles` has been enabled, subtitles results"),
            utterances: zod
              .array(
                zod.object({
                  start: zod.number().describe("Start timestamp in seconds of this utterance"),
                  end: zod.number().describe("End timestamp in seconds of this utterance"),
                  confidence: zod
                    .number()
                    .describe("Confidence on the transcribed utterance (1 = 100% confident)"),
                  channel: zod
                    .number()
                    .min(
                      transcriptionControllerGetTranscriptV2ResponseResultTranscriptionUtterancesItemChannelMin
                    )
                    .describe("Audio channel of where this utterance has been transcribed from"),
                  speaker: zod
                    .number()
                    .min(
                      transcriptionControllerGetTranscriptV2ResponseResultTranscriptionUtterancesItemSpeakerMin
                    )
                    .optional()
                    .describe("If `diarization` enabled, speaker identification number"),
                  words: zod
                    .array(
                      zod.object({
                        word: zod.string().describe("Spoken word"),
                        start: zod
                          .number()
                          .describe("Start timestamps in seconds of the spoken word"),
                        end: zod.number().describe("End timestamps in seconds of the spoken word"),
                        confidence: zod
                          .number()
                          .describe("Confidence on the transcribed word (1 = 100% confident)")
                      })
                    )
                    .describe("List of words of the utterance, split by timestamp"),
                  text: zod.string().describe("Transcription for this utterance"),
                  language: zod
                    .enum([
                      "af",
                      "am",
                      "ar",
                      "as",
                      "az",
                      "ba",
                      "be",
                      "bg",
                      "bn",
                      "bo",
                      "br",
                      "bs",
                      "ca",
                      "cs",
                      "cy",
                      "da",
                      "de",
                      "el",
                      "en",
                      "es",
                      "et",
                      "eu",
                      "fa",
                      "fi",
                      "fo",
                      "fr",
                      "gl",
                      "gu",
                      "ha",
                      "haw",
                      "he",
                      "hi",
                      "hr",
                      "ht",
                      "hu",
                      "hy",
                      "id",
                      "is",
                      "it",
                      "ja",
                      "jw",
                      "ka",
                      "kk",
                      "km",
                      "kn",
                      "ko",
                      "la",
                      "lb",
                      "ln",
                      "lo",
                      "lt",
                      "lv",
                      "mg",
                      "mi",
                      "mk",
                      "ml",
                      "mn",
                      "mr",
                      "ms",
                      "mt",
                      "my",
                      "ne",
                      "nl",
                      "nn",
                      "no",
                      "oc",
                      "pa",
                      "pl",
                      "ps",
                      "pt",
                      "ro",
                      "ru",
                      "sa",
                      "sd",
                      "si",
                      "sk",
                      "sl",
                      "sn",
                      "so",
                      "sq",
                      "sr",
                      "su",
                      "sv",
                      "sw",
                      "ta",
                      "te",
                      "tg",
                      "th",
                      "tk",
                      "tl",
                      "tr",
                      "tt",
                      "uk",
                      "ur",
                      "uz",
                      "vi",
                      "yi",
                      "yo",
                      "zh"
                    ])
                    .describe(
                      "Specify the language in which it will be pronounced when sound comparison occurs. Default to transcription language."
                    )
                    .describe("Spoken language in this utterance")
                })
              )
              .describe("Transcribed speech utterances present in the audio")
          })
          .optional()
          .describe("Transcription of the audio speech"),
        translation: zod
          .object({
            success: zod
              .boolean()
              .describe("The audio intelligence model succeeded to get a valid output"),
            is_empty: zod
              .boolean()
              .describe("The audio intelligence model returned an empty value"),
            exec_time: zod
              .number()
              .describe("Time audio intelligence model took to complete the task"),
            error: zod
              .object({
                status_code: zod.number().describe("Status code of the addon error"),
                exception: zod.string().describe("Reason of the addon error"),
                message: zod.string().describe("Detailed message of the addon error")
              })
              .nullable()
              .describe(
                "`null` if `success` is `true`. Contains the error details of the failed model"
              ),
            results: zod
              .array(
                zod.object({
                  error: zod
                    .object({
                      status_code: zod.number().describe("Status code of the addon error"),
                      exception: zod.string().describe("Reason of the addon error"),
                      message: zod.string().describe("Detailed message of the addon error")
                    })
                    .nullable()
                    .describe("Contains the error details of the failed addon"),
                  full_transcript: zod
                    .string()
                    .describe("All transcription on text format without any other information"),
                  languages: zod
                    .array(
                      zod
                        .enum([
                          "af",
                          "am",
                          "ar",
                          "as",
                          "az",
                          "ba",
                          "be",
                          "bg",
                          "bn",
                          "bo",
                          "br",
                          "bs",
                          "ca",
                          "cs",
                          "cy",
                          "da",
                          "de",
                          "el",
                          "en",
                          "es",
                          "et",
                          "eu",
                          "fa",
                          "fi",
                          "fo",
                          "fr",
                          "gl",
                          "gu",
                          "ha",
                          "haw",
                          "he",
                          "hi",
                          "hr",
                          "ht",
                          "hu",
                          "hy",
                          "id",
                          "is",
                          "it",
                          "ja",
                          "jw",
                          "ka",
                          "kk",
                          "km",
                          "kn",
                          "ko",
                          "la",
                          "lb",
                          "ln",
                          "lo",
                          "lt",
                          "lv",
                          "mg",
                          "mi",
                          "mk",
                          "ml",
                          "mn",
                          "mr",
                          "ms",
                          "mt",
                          "my",
                          "ne",
                          "nl",
                          "nn",
                          "no",
                          "oc",
                          "pa",
                          "pl",
                          "ps",
                          "pt",
                          "ro",
                          "ru",
                          "sa",
                          "sd",
                          "si",
                          "sk",
                          "sl",
                          "sn",
                          "so",
                          "sq",
                          "sr",
                          "su",
                          "sv",
                          "sw",
                          "ta",
                          "te",
                          "tg",
                          "th",
                          "tk",
                          "tl",
                          "tr",
                          "tt",
                          "uk",
                          "ur",
                          "uz",
                          "vi",
                          "wo",
                          "yi",
                          "yo",
                          "zh"
                        ])
                        .describe(
                          "Target language in `iso639-1` format you want the transcription translated to"
                        )
                    )
                    .describe(
                      "All the detected languages in the audio sorted from the most detected to the less detected"
                    ),
                  sentences: zod
                    .array(
                      zod.object({
                        success: zod
                          .boolean()
                          .describe("The audio intelligence model succeeded to get a valid output"),
                        is_empty: zod
                          .boolean()
                          .describe("The audio intelligence model returned an empty value"),
                        exec_time: zod
                          .number()
                          .describe("Time audio intelligence model took to complete the task"),
                        error: zod
                          .object({
                            status_code: zod.number().describe("Status code of the addon error"),
                            exception: zod.string().describe("Reason of the addon error"),
                            message: zod.string().describe("Detailed message of the addon error")
                          })
                          .nullable()
                          .describe(
                            "`null` if `success` is `true`. Contains the error details of the failed model"
                          ),
                        results: zod
                          .array(zod.string())
                          .nullable()
                          .describe("If `sentences` has been enabled, transcription as sentences.")
                      })
                    )
                    .optional()
                    .describe(
                      "If `sentences` has been enabled, sentences results for this translation"
                    ),
                  subtitles: zod
                    .array(
                      zod.object({
                        format: zod
                          .enum(["srt", "vtt"])
                          .describe(
                            "Subtitles formats you want your transcription to be formatted to"
                          )
                          .describe("Format of the current subtitle"),
                        subtitles: zod
                          .string()
                          .describe("Transcription on the asked subtitle format")
                      })
                    )
                    .optional()
                    .describe(
                      "If `subtitles` has been enabled, subtitles results for this translation"
                    ),
                  utterances: zod
                    .array(
                      zod.object({
                        start: zod
                          .number()
                          .describe("Start timestamp in seconds of this utterance"),
                        end: zod.number().describe("End timestamp in seconds of this utterance"),
                        confidence: zod
                          .number()
                          .describe("Confidence on the transcribed utterance (1 = 100% confident)"),
                        channel: zod
                          .number()
                          .min(
                            transcriptionControllerGetTranscriptV2ResponseResultTranslationResultsItemUtterancesItemChannelMin
                          )
                          .describe(
                            "Audio channel of where this utterance has been transcribed from"
                          ),
                        speaker: zod
                          .number()
                          .min(
                            transcriptionControllerGetTranscriptV2ResponseResultTranslationResultsItemUtterancesItemSpeakerMin
                          )
                          .optional()
                          .describe("If `diarization` enabled, speaker identification number"),
                        words: zod
                          .array(
                            zod.object({
                              word: zod.string().describe("Spoken word"),
                              start: zod
                                .number()
                                .describe("Start timestamps in seconds of the spoken word"),
                              end: zod
                                .number()
                                .describe("End timestamps in seconds of the spoken word"),
                              confidence: zod
                                .number()
                                .describe("Confidence on the transcribed word (1 = 100% confident)")
                            })
                          )
                          .describe("List of words of the utterance, split by timestamp"),
                        text: zod.string().describe("Transcription for this utterance"),
                        language: zod
                          .enum([
                            "af",
                            "am",
                            "ar",
                            "as",
                            "az",
                            "ba",
                            "be",
                            "bg",
                            "bn",
                            "bo",
                            "br",
                            "bs",
                            "ca",
                            "cs",
                            "cy",
                            "da",
                            "de",
                            "el",
                            "en",
                            "es",
                            "et",
                            "eu",
                            "fa",
                            "fi",
                            "fo",
                            "fr",
                            "gl",
                            "gu",
                            "ha",
                            "haw",
                            "he",
                            "hi",
                            "hr",
                            "ht",
                            "hu",
                            "hy",
                            "id",
                            "is",
                            "it",
                            "ja",
                            "jw",
                            "ka",
                            "kk",
                            "km",
                            "kn",
                            "ko",
                            "la",
                            "lb",
                            "ln",
                            "lo",
                            "lt",
                            "lv",
                            "mg",
                            "mi",
                            "mk",
                            "ml",
                            "mn",
                            "mr",
                            "ms",
                            "mt",
                            "my",
                            "ne",
                            "nl",
                            "nn",
                            "no",
                            "oc",
                            "pa",
                            "pl",
                            "ps",
                            "pt",
                            "ro",
                            "ru",
                            "sa",
                            "sd",
                            "si",
                            "sk",
                            "sl",
                            "sn",
                            "so",
                            "sq",
                            "sr",
                            "su",
                            "sv",
                            "sw",
                            "ta",
                            "te",
                            "tg",
                            "th",
                            "tk",
                            "tl",
                            "tr",
                            "tt",
                            "uk",
                            "ur",
                            "uz",
                            "vi",
                            "yi",
                            "yo",
                            "zh"
                          ])
                          .describe(
                            "Specify the language in which it will be pronounced when sound comparison occurs. Default to transcription language."
                          )
                          .describe("Spoken language in this utterance")
                      })
                    )
                    .describe("Transcribed speech utterances present in the audio")
                })
              )
              .nullable()
              .describe("List of translated transcriptions, one for each `target_languages`")
          })
          .optional()
          .describe(
            "If `translation` has been enabled, translation of the audio speech transcription"
          ),
        summarization: zod
          .object({
            success: zod
              .boolean()
              .describe("The audio intelligence model succeeded to get a valid output"),
            is_empty: zod
              .boolean()
              .describe("The audio intelligence model returned an empty value"),
            exec_time: zod
              .number()
              .describe("Time audio intelligence model took to complete the task"),
            error: zod
              .object({
                status_code: zod.number().describe("Status code of the addon error"),
                exception: zod.string().describe("Reason of the addon error"),
                message: zod.string().describe("Detailed message of the addon error")
              })
              .nullable()
              .describe(
                "`null` if `success` is `true`. Contains the error details of the failed model"
              ),
            results: zod
              .string()
              .nullable()
              .describe("If `summarization` has been enabled, summary of the transcription")
          })
          .optional()
          .describe(
            "If `summarization` has been enabled, summarization of the audio speech transcription"
          ),
        moderation: zod
          .object({
            success: zod
              .boolean()
              .describe("The audio intelligence model succeeded to get a valid output"),
            is_empty: zod
              .boolean()
              .describe("The audio intelligence model returned an empty value"),
            exec_time: zod
              .number()
              .describe("Time audio intelligence model took to complete the task"),
            error: zod
              .object({
                status_code: zod.number().describe("Status code of the addon error"),
                exception: zod.string().describe("Reason of the addon error"),
                message: zod.string().describe("Detailed message of the addon error")
              })
              .nullable()
              .describe(
                "`null` if `success` is `true`. Contains the error details of the failed model"
              ),
            results: zod
              .string()
              .nullable()
              .describe("If `moderation` has been enabled, moderated transcription")
          })
          .optional()
          .describe(
            "If `moderation` has been enabled, moderation of the audio speech transcription"
          ),
        named_entity_recognition: zod
          .object({
            success: zod
              .boolean()
              .describe("The audio intelligence model succeeded to get a valid output"),
            is_empty: zod
              .boolean()
              .describe("The audio intelligence model returned an empty value"),
            exec_time: zod
              .number()
              .describe("Time audio intelligence model took to complete the task"),
            error: zod
              .object({
                status_code: zod.number().describe("Status code of the addon error"),
                exception: zod.string().describe("Reason of the addon error"),
                message: zod.string().describe("Detailed message of the addon error")
              })
              .nullable()
              .describe(
                "`null` if `success` is `true`. Contains the error details of the failed model"
              ),
            entity: zod
              .string()
              .describe("If `named_entity_recognition` has been enabled, the detected entities.")
          })
          .optional()
          .describe("If `named_entity_recognition` has been enabled, the detected entities"),
        name_consistency: zod
          .object({
            success: zod
              .boolean()
              .describe("The audio intelligence model succeeded to get a valid output"),
            is_empty: zod
              .boolean()
              .describe("The audio intelligence model returned an empty value"),
            exec_time: zod
              .number()
              .describe("Time audio intelligence model took to complete the task"),
            error: zod
              .object({
                status_code: zod.number().describe("Status code of the addon error"),
                exception: zod.string().describe("Reason of the addon error"),
                message: zod.string().describe("Detailed message of the addon error")
              })
              .nullable()
              .describe(
                "`null` if `success` is `true`. Contains the error details of the failed model"
              ),
            results: zod
              .string()
              .describe(
                "If `name_consistency` has been enabled, Gladia will improve the consistency of the names across the transcription"
              )
          })
          .optional()
          .describe(
            "If `name_consistency` has been enabled, Gladia will improve consistency of the names accross the transcription"
          ),
        speaker_reidentification: zod
          .object({
            success: zod
              .boolean()
              .describe("The audio intelligence model succeeded to get a valid output"),
            is_empty: zod
              .boolean()
              .describe("The audio intelligence model returned an empty value"),
            exec_time: zod
              .number()
              .describe("Time audio intelligence model took to complete the task"),
            error: zod
              .object({
                status_code: zod.number().describe("Status code of the addon error"),
                exception: zod.string().describe("Reason of the addon error"),
                message: zod.string().describe("Detailed message of the addon error")
              })
              .nullable()
              .describe(
                "`null` if `success` is `true`. Contains the error details of the failed model"
              ),
            results: zod
              .string()
              .describe(
                "If `speaker_reidentification` has been enabled, results of the AI speaker reidentification."
              )
          })
          .optional()
          .describe(
            "If `speaker_reidentification` has been enabled, results of the AI speaker reidentification."
          ),
        structured_data_extraction: zod
          .object({
            success: zod
              .boolean()
              .describe("The audio intelligence model succeeded to get a valid output"),
            is_empty: zod
              .boolean()
              .describe("The audio intelligence model returned an empty value"),
            exec_time: zod
              .number()
              .describe("Time audio intelligence model took to complete the task"),
            error: zod
              .object({
                status_code: zod.number().describe("Status code of the addon error"),
                exception: zod.string().describe("Reason of the addon error"),
                message: zod.string().describe("Detailed message of the addon error")
              })
              .nullable()
              .describe(
                "`null` if `success` is `true`. Contains the error details of the failed model"
              ),
            results: zod
              .string()
              .describe(
                "If `structured_data_extraction` has been enabled, results of the AI structured data extraction for the defined classes."
              )
          })
          .optional()
          .describe(
            "If `structured_data_extraction` has been enabled, structured data extraction results"
          ),
        sentiment_analysis: zod
          .object({
            success: zod
              .boolean()
              .describe("The audio intelligence model succeeded to get a valid output"),
            is_empty: zod
              .boolean()
              .describe("The audio intelligence model returned an empty value"),
            exec_time: zod
              .number()
              .describe("Time audio intelligence model took to complete the task"),
            error: zod
              .object({
                status_code: zod.number().describe("Status code of the addon error"),
                exception: zod.string().describe("Reason of the addon error"),
                message: zod.string().describe("Detailed message of the addon error")
              })
              .nullable()
              .describe(
                "`null` if `success` is `true`. Contains the error details of the failed model"
              ),
            results: zod
              .string()
              .describe(
                "If `sentiment_analysis` has been enabled, Gladia will analyze the sentiments and emotions of the audio"
              )
          })
          .optional()
          .describe(
            "If `sentiment_analysis` has been enabled, sentiment analysis of the audio speech transcription"
          ),
        audio_to_llm: zod
          .object({
            success: zod
              .boolean()
              .describe("The audio intelligence model succeeded to get a valid output"),
            is_empty: zod
              .boolean()
              .describe("The audio intelligence model returned an empty value"),
            exec_time: zod
              .number()
              .describe("Time audio intelligence model took to complete the task"),
            error: zod
              .object({
                status_code: zod.number().describe("Status code of the addon error"),
                exception: zod.string().describe("Reason of the addon error"),
                message: zod.string().describe("Detailed message of the addon error")
              })
              .nullable()
              .describe(
                "`null` if `success` is `true`. Contains the error details of the failed model"
              ),
            results: zod
              .array(
                zod.object({
                  success: zod
                    .boolean()
                    .describe("The audio intelligence model succeeded to get a valid output"),
                  is_empty: zod
                    .boolean()
                    .describe("The audio intelligence model returned an empty value"),
                  exec_time: zod
                    .number()
                    .describe("Time audio intelligence model took to complete the task"),
                  error: zod
                    .object({
                      status_code: zod.number().describe("Status code of the addon error"),
                      exception: zod.string().describe("Reason of the addon error"),
                      message: zod.string().describe("Detailed message of the addon error")
                    })
                    .nullable()
                    .describe(
                      "`null` if `success` is `true`. Contains the error details of the failed model"
                    ),
                  results: zod
                    .object({
                      prompt: zod.string().nullable().describe("The prompt used"),
                      response: zod.string().nullable().describe("The result of the AI analysis")
                    })
                    .nullable()
                    .describe("The result from a specific prompt")
                })
              )
              .nullable()
              .describe("If `audio_to_llm` has been enabled, results of the AI custom analysis")
          })
          .optional()
          .describe(
            "If `audio_to_llm` has been enabled, audio to llm results of the audio speech transcription"
          ),
        sentences: zod
          .object({
            success: zod
              .boolean()
              .describe("The audio intelligence model succeeded to get a valid output"),
            is_empty: zod
              .boolean()
              .describe("The audio intelligence model returned an empty value"),
            exec_time: zod
              .number()
              .describe("Time audio intelligence model took to complete the task"),
            error: zod
              .object({
                status_code: zod.number().describe("Status code of the addon error"),
                exception: zod.string().describe("Reason of the addon error"),
                message: zod.string().describe("Detailed message of the addon error")
              })
              .nullable()
              .describe(
                "`null` if `success` is `true`. Contains the error details of the failed model"
              ),
            results: zod
              .array(zod.string())
              .nullable()
              .describe("If `sentences` has been enabled, transcription as sentences.")
          })
          .optional()
          .describe(
            "If `sentences` has been enabled, sentences of the audio speech transcription. Deprecated: content will move to the `transcription` object."
          ),
        display_mode: zod
          .object({
            success: zod
              .boolean()
              .describe("The audio intelligence model succeeded to get a valid output"),
            is_empty: zod
              .boolean()
              .describe("The audio intelligence model returned an empty value"),
            exec_time: zod
              .number()
              .describe("Time audio intelligence model took to complete the task"),
            error: zod
              .object({
                status_code: zod.number().describe("Status code of the addon error"),
                exception: zod.string().describe("Reason of the addon error"),
                message: zod.string().describe("Detailed message of the addon error")
              })
              .nullable()
              .describe(
                "`null` if `success` is `true`. Contains the error details of the failed model"
              ),
            results: zod
              .array(zod.string())
              .nullable()
              .describe(
                "If `display_mode` has been enabled, proposes an alternative display output."
              )
          })
          .optional()
          .describe(
            "If `display_mode` has been enabled, the output will be reordered, creating new utterances when speakers overlapped"
          ),
        chapterization: zod
          .object({
            success: zod
              .boolean()
              .describe("The audio intelligence model succeeded to get a valid output"),
            is_empty: zod
              .boolean()
              .describe("The audio intelligence model returned an empty value"),
            exec_time: zod
              .number()
              .describe("Time audio intelligence model took to complete the task"),
            error: zod
              .object({
                status_code: zod.number().describe("Status code of the addon error"),
                exception: zod.string().describe("Reason of the addon error"),
                message: zod.string().describe("Detailed message of the addon error")
              })
              .nullable()
              .describe(
                "`null` if `success` is `true`. Contains the error details of the failed model"
              ),
            results: zod
              .record(zod.string(), zod.any())
              .describe(
                "If `chapterization` has been enabled, will generate chapters name for different parts of the given audio."
              )
          })
          .optional()
          .describe(
            "If `chapterization` has been enabled, will generate chapters name for different parts of the given audio."
          ),
        diarization: zod
          .object({
            success: zod
              .boolean()
              .describe("The audio intelligence model succeeded to get a valid output"),
            is_empty: zod
              .boolean()
              .describe("The audio intelligence model returned an empty value"),
            exec_time: zod
              .number()
              .describe("Time audio intelligence model took to complete the task"),
            error: zod
              .object({
                status_code: zod.number().describe("Status code of the addon error"),
                exception: zod.string().describe("Reason of the addon error"),
                message: zod.string().describe("Detailed message of the addon error")
              })
              .nullable()
              .describe(
                "`null` if `success` is `true`. Contains the error details of the failed model"
              ),
            results: zod
              .array(
                zod.object({
                  start: zod.number().describe("Start timestamp in seconds of this utterance"),
                  end: zod.number().describe("End timestamp in seconds of this utterance"),
                  confidence: zod
                    .number()
                    .describe("Confidence on the transcribed utterance (1 = 100% confident)"),
                  channel: zod
                    .number()
                    .min(
                      transcriptionControllerGetTranscriptV2ResponseResultDiarizationResultsItemChannelMin
                    )
                    .describe("Audio channel of where this utterance has been transcribed from"),
                  speaker: zod
                    .number()
                    .min(
                      transcriptionControllerGetTranscriptV2ResponseResultDiarizationResultsItemSpeakerMin
                    )
                    .optional()
                    .describe("If `diarization` enabled, speaker identification number"),
                  words: zod
                    .array(
                      zod.object({
                        word: zod.string().describe("Spoken word"),
                        start: zod
                          .number()
                          .describe("Start timestamps in seconds of the spoken word"),
                        end: zod.number().describe("End timestamps in seconds of the spoken word"),
                        confidence: zod
                          .number()
                          .describe("Confidence on the transcribed word (1 = 100% confident)")
                      })
                    )
                    .describe("List of words of the utterance, split by timestamp"),
                  text: zod.string().describe("Transcription for this utterance"),
                  language: zod
                    .enum([
                      "af",
                      "am",
                      "ar",
                      "as",
                      "az",
                      "ba",
                      "be",
                      "bg",
                      "bn",
                      "bo",
                      "br",
                      "bs",
                      "ca",
                      "cs",
                      "cy",
                      "da",
                      "de",
                      "el",
                      "en",
                      "es",
                      "et",
                      "eu",
                      "fa",
                      "fi",
                      "fo",
                      "fr",
                      "gl",
                      "gu",
                      "ha",
                      "haw",
                      "he",
                      "hi",
                      "hr",
                      "ht",
                      "hu",
                      "hy",
                      "id",
                      "is",
                      "it",
                      "ja",
                      "jw",
                      "ka",
                      "kk",
                      "km",
                      "kn",
                      "ko",
                      "la",
                      "lb",
                      "ln",
                      "lo",
                      "lt",
                      "lv",
                      "mg",
                      "mi",
                      "mk",
                      "ml",
                      "mn",
                      "mr",
                      "ms",
                      "mt",
                      "my",
                      "ne",
                      "nl",
                      "nn",
                      "no",
                      "oc",
                      "pa",
                      "pl",
                      "ps",
                      "pt",
                      "ro",
                      "ru",
                      "sa",
                      "sd",
                      "si",
                      "sk",
                      "sl",
                      "sn",
                      "so",
                      "sq",
                      "sr",
                      "su",
                      "sv",
                      "sw",
                      "ta",
                      "te",
                      "tg",
                      "th",
                      "tk",
                      "tl",
                      "tr",
                      "tt",
                      "uk",
                      "ur",
                      "uz",
                      "vi",
                      "yi",
                      "yo",
                      "zh"
                    ])
                    .describe(
                      "Specify the language in which it will be pronounced when sound comparison occurs. Default to transcription language."
                    )
                    .describe("Spoken language in this utterance")
                })
              )
              .describe(
                "[Deprecated] If `diarization` has been enabled, the diarization result will appear here"
              )
          })
          .optional()
          .describe(
            "If `diarization` has been requested and an error has occurred, the result will appear here"
          )
      })
      .nullish()
      .describe('Pre-recorded transcription\'s result when status is \"done\"')
  }),
  zod.object({
    id: zod.string().uuid().describe("Id of the job"),
    request_id: zod.string().describe("Debug id"),
    version: zod.number().describe("API version"),
    status: zod
      .enum(["queued", "processing", "done", "error"])
      .describe(
        '\"queued\": the job has been queued. \"processing\": the job is being processed. \"done\": the job has been processed and the result is available. \"error\": an error occurred during the job\'s processing.'
      ),
    created_at: zod.string().datetime({}).describe("Creation date"),
    completed_at: zod
      .string()
      .datetime({})
      .nullish()
      .describe('Completion date when status is \"done\" or \"error\"'),
    custom_metadata: zod
      .record(zod.string(), zod.any())
      .optional()
      .describe("Custom metadata given in the initial request"),
    error_code: zod
      .number()
      .min(transcriptionControllerGetTranscriptV2ResponseErrorCodeMinOne)
      .max(transcriptionControllerGetTranscriptV2ResponseErrorCodeMaxOne)
      .nullish()
      .describe('HTTP status code of the error if status is \"error\"'),
    post_session_metadata: zod
      .object({})
      .describe("For debugging purposes, send data that could help to identify issues"),
    kind: zod.enum(["live"]),
    file: zod
      .object({
        id: zod.string().describe("The file id"),
        filename: zod.string().nullable().describe("The name of the uploaded file"),
        source: zod
          .string()
          .nullable()
          .describe("The link used to download the file if audio_url was used"),
        audio_duration: zod.number().nullable().describe("Duration of the audio file"),
        number_of_channels: zod
          .number()
          .min(1)
          .nullable()
          .describe("Number of channels in the audio file")
      })
      .nullish()
      .describe('The file data you uploaded. Can be null if status is \"error\"'),
    request_params: zod
      .object({
        encoding: zod
          .enum(["wav/pcm", "wav/alaw", "wav/ulaw"])
          .describe(
            "The encoding format of the audio stream. Supported formats: \n- PCM: 8, 16, 24, and 32 bits \n- A-law: 8 bits \n- Œº-law: 8 bits \n\nNote: No need to add WAV headers to raw audio as the API supports both formats."
          )
          .default(transcriptionControllerGetTranscriptV2ResponseRequestParamsEncodingDefault)
          .describe(
            "The encoding format of the audio stream. Supported formats: \n- PCM: 8, 16, 24, and 32 bits \n- A-law: 8 bits \n- Œº-law: 8 bits \n\nNote: No need to add WAV headers to raw audio as the API supports both formats."
          ),
        bit_depth: zod
          .literal(8)
          .or(zod.literal(16))
          .or(zod.literal(24))
          .or(zod.literal(32))
          .describe("The bit depth of the audio stream")
          .default(transcriptionControllerGetTranscriptV2ResponseRequestParamsBitDepthDefault)
          .describe("The bit depth of the audio stream"),
        sample_rate: zod
          .literal(8000)
          .or(zod.literal(16000))
          .or(zod.literal(32000))
          .or(zod.literal(44100))
          .or(zod.literal(48000))
          .describe("The sample rate of the audio stream")
          .default(transcriptionControllerGetTranscriptV2ResponseRequestParamsSampleRateDefault)
          .describe("The sample rate of the audio stream"),
        channels: zod
          .number()
          .min(1)
          .max(transcriptionControllerGetTranscriptV2ResponseRequestParamsChannelsMax)
          .default(transcriptionControllerGetTranscriptV2ResponseRequestParamsChannelsDefault)
          .describe("The number of channels of the audio stream"),
        model: zod
          .enum(["solaria-1"])
          .describe('The model used to process the audio. \"solaria-1\" is used by default.')
          .default(transcriptionControllerGetTranscriptV2ResponseRequestParamsModelDefault)
          .describe('The model used to process the audio. \"solaria-1\" is used by default.'),
        endpointing: zod
          .number()
          .min(transcriptionControllerGetTranscriptV2ResponseRequestParamsEndpointingMin)
          .max(transcriptionControllerGetTranscriptV2ResponseRequestParamsEndpointingMax)
          .default(transcriptionControllerGetTranscriptV2ResponseRequestParamsEndpointingDefault)
          .describe(
            "The endpointing duration in seconds. Endpointing is the duration of silence which will cause an utterance to be considered as finished"
          ),
        maximum_duration_without_endpointing: zod
          .number()
          .min(
            transcriptionControllerGetTranscriptV2ResponseRequestParamsMaximumDurationWithoutEndpointingMin
          )
          .max(
            transcriptionControllerGetTranscriptV2ResponseRequestParamsMaximumDurationWithoutEndpointingMax
          )
          .default(
            transcriptionControllerGetTranscriptV2ResponseRequestParamsMaximumDurationWithoutEndpointingDefault
          )
          .describe(
            "The maximum duration in seconds without endpointing. If endpointing is not detected after this duration, current utterance will be considered as finished"
          ),
        language_config: zod
          .object({
            languages: zod
              .array(
                zod
                  .enum([
                    "af",
                    "am",
                    "ar",
                    "as",
                    "az",
                    "ba",
                    "be",
                    "bg",
                    "bn",
                    "bo",
                    "br",
                    "bs",
                    "ca",
                    "cs",
                    "cy",
                    "da",
                    "de",
                    "el",
                    "en",
                    "es",
                    "et",
                    "eu",
                    "fa",
                    "fi",
                    "fo",
                    "fr",
                    "gl",
                    "gu",
                    "ha",
                    "haw",
                    "he",
                    "hi",
                    "hr",
                    "ht",
                    "hu",
                    "hy",
                    "id",
                    "is",
                    "it",
                    "ja",
                    "jw",
                    "ka",
                    "kk",
                    "km",
                    "kn",
                    "ko",
                    "la",
                    "lb",
                    "ln",
                    "lo",
                    "lt",
                    "lv",
                    "mg",
                    "mi",
                    "mk",
                    "ml",
                    "mn",
                    "mr",
                    "ms",
                    "mt",
                    "my",
                    "ne",
                    "nl",
                    "nn",
                    "no",
                    "oc",
                    "pa",
                    "pl",
                    "ps",
                    "pt",
                    "ro",
                    "ru",
                    "sa",
                    "sd",
                    "si",
                    "sk",
                    "sl",
                    "sn",
                    "so",
                    "sq",
                    "sr",
                    "su",
                    "sv",
                    "sw",
                    "ta",
                    "te",
                    "tg",
                    "th",
                    "tk",
                    "tl",
                    "tr",
                    "tt",
                    "uk",
                    "ur",
                    "uz",
                    "vi",
                    "yi",
                    "yo",
                    "zh"
                  ])
                  .describe(
                    "Specify the language in which it will be pronounced when sound comparison occurs. Default to transcription language."
                  )
              )
              .default(
                transcriptionControllerGetTranscriptV2ResponseRequestParamsLanguageConfigLanguagesDefaultOne
              )
              .describe(
                "If one language is set, it will be used for the transcription. Otherwise, language will be auto-detected by the model."
              ),
            code_switching: zod
              .boolean()
              .optional()
              .describe(
                "If true, language will be auto-detected on each utterance. Otherwise, language will be auto-detected on first utterance and then used for the rest of the transcription. If one language is set, this option will be ignored."
              )
          })
          .optional()
          .describe("Specify the language configuration"),
        pre_processing: zod
          .object({
            audio_enhancer: zod
              .boolean()
              .optional()
              .describe(
                "If true, apply pre-processing to the audio stream to enhance the quality."
              ),
            speech_threshold: zod
              .number()
              .min(
                transcriptionControllerGetTranscriptV2ResponseRequestParamsPreProcessingSpeechThresholdMin
              )
              .max(
                transcriptionControllerGetTranscriptV2ResponseRequestParamsPreProcessingSpeechThresholdMax
              )
              .default(
                transcriptionControllerGetTranscriptV2ResponseRequestParamsPreProcessingSpeechThresholdDefault
              )
              .describe(
                "Sensitivity configuration for Speech Threshold. A value close to 1 will apply stricter thresholds, making it less likely to detect background sounds as speech."
              )
          })
          .optional()
          .describe("Specify the pre-processing configuration"),
        realtime_processing: zod
          .object({
            custom_vocabulary: zod
              .boolean()
              .optional()
              .describe("If true, enable custom vocabulary for the transcription."),
            custom_vocabulary_config: zod
              .object({
                vocabulary: zod
                  .array(
                    zod
                      .object({
                        value: zod
                          .string()
                          .describe("The text used to replace in the transcription."),
                        intensity: zod
                          .number()
                          .min(
                            transcriptionControllerGetTranscriptV2ResponseRequestParamsRealtimeProcessingCustomVocabularyConfigVocabularyItemIntensityMin
                          )
                          .max(
                            transcriptionControllerGetTranscriptV2ResponseRequestParamsRealtimeProcessingCustomVocabularyConfigVocabularyItemIntensityMax
                          )
                          .optional()
                          .describe("The global intensity of the feature."),
                        pronunciations: zod
                          .array(zod.string())
                          .optional()
                          .describe("The pronunciations used in the transcription."),
                        language: zod
                          .enum([
                            "af",
                            "am",
                            "ar",
                            "as",
                            "az",
                            "ba",
                            "be",
                            "bg",
                            "bn",
                            "bo",
                            "br",
                            "bs",
                            "ca",
                            "cs",
                            "cy",
                            "da",
                            "de",
                            "el",
                            "en",
                            "es",
                            "et",
                            "eu",
                            "fa",
                            "fi",
                            "fo",
                            "fr",
                            "gl",
                            "gu",
                            "ha",
                            "haw",
                            "he",
                            "hi",
                            "hr",
                            "ht",
                            "hu",
                            "hy",
                            "id",
                            "is",
                            "it",
                            "ja",
                            "jw",
                            "ka",
                            "kk",
                            "km",
                            "kn",
                            "ko",
                            "la",
                            "lb",
                            "ln",
                            "lo",
                            "lt",
                            "lv",
                            "mg",
                            "mi",
                            "mk",
                            "ml",
                            "mn",
                            "mr",
                            "ms",
                            "mt",
                            "my",
                            "ne",
                            "nl",
                            "nn",
                            "no",
                            "oc",
                            "pa",
                            "pl",
                            "ps",
                            "pt",
                            "ro",
                            "ru",
                            "sa",
                            "sd",
                            "si",
                            "sk",
                            "sl",
                            "sn",
                            "so",
                            "sq",
                            "sr",
                            "su",
                            "sv",
                            "sw",
                            "ta",
                            "te",
                            "tg",
                            "th",
                            "tk",
                            "tl",
                            "tr",
                            "tt",
                            "uk",
                            "ur",
                            "uz",
                            "vi",
                            "yi",
                            "yo",
                            "zh"
                          ])
                          .describe(
                            "Specify the language in which it will be pronounced when sound comparison occurs. Default to transcription language."
                          )
                          .optional()
                          .describe(
                            "Specify the language in which it will be pronounced when sound comparison occurs. Default to transcription language."
                          )
                      })
                      .or(zod.string())
                  )
                  .describe(
                    "Specific vocabulary list to feed the transcription model with. Each item can be a string or an object with the following properties: value, intensity, pronunciations, language."
                  ),
                default_intensity: zod
                  .number()
                  .min(
                    transcriptionControllerGetTranscriptV2ResponseRequestParamsRealtimeProcessingCustomVocabularyConfigDefaultIntensityMin
                  )
                  .max(
                    transcriptionControllerGetTranscriptV2ResponseRequestParamsRealtimeProcessingCustomVocabularyConfigDefaultIntensityMax
                  )
                  .optional()
                  .describe("Default intensity for the custom vocabulary")
              })
              .optional()
              .describe("Custom vocabulary configuration, if `custom_vocabulary` is enabled"),
            custom_spelling: zod
              .boolean()
              .optional()
              .describe("If true, enable custom spelling for the transcription."),
            custom_spelling_config: zod
              .object({
                spelling_dictionary: zod
                  .record(zod.string(), zod.array(zod.string()))
                  .describe("The list of spelling applied on the audio transcription")
              })
              .optional()
              .describe("Custom spelling configuration, if `custom_spelling` is enabled"),
            translation: zod
              .boolean()
              .optional()
              .describe("If true, enable translation for the transcription"),
            translation_config: zod
              .object({
                target_languages: zod
                  .array(
                    zod
                      .enum([
                        "af",
                        "am",
                        "ar",
                        "as",
                        "az",
                        "ba",
                        "be",
                        "bg",
                        "bn",
                        "bo",
                        "br",
                        "bs",
                        "ca",
                        "cs",
                        "cy",
                        "da",
                        "de",
                        "el",
                        "en",
                        "es",
                        "et",
                        "eu",
                        "fa",
                        "fi",
                        "fo",
                        "fr",
                        "gl",
                        "gu",
                        "ha",
                        "haw",
                        "he",
                        "hi",
                        "hr",
                        "ht",
                        "hu",
                        "hy",
                        "id",
                        "is",
                        "it",
                        "ja",
                        "jw",
                        "ka",
                        "kk",
                        "km",
                        "kn",
                        "ko",
                        "la",
                        "lb",
                        "ln",
                        "lo",
                        "lt",
                        "lv",
                        "mg",
                        "mi",
                        "mk",
                        "ml",
                        "mn",
                        "mr",
                        "ms",
                        "mt",
                        "my",
                        "ne",
                        "nl",
                        "nn",
                        "no",
                        "oc",
                        "pa",
                        "pl",
                        "ps",
                        "pt",
                        "ro",
                        "ru",
                        "sa",
                        "sd",
                        "si",
                        "sk",
                        "sl",
                        "sn",
                        "so",
                        "sq",
                        "sr",
                        "su",
                        "sv",
                        "sw",
                        "ta",
                        "te",
                        "tg",
                        "th",
                        "tk",
                        "tl",
                        "tr",
                        "tt",
                        "uk",
                        "ur",
                        "uz",
                        "vi",
                        "wo",
                        "yi",
                        "yo",
                        "zh"
                      ])
                      .describe(
                        "Target language in `iso639-1` format you want the transcription translated to"
                      )
                  )
                  .min(1)
                  .describe(
                    "Target language in `iso639-1` format you want the transcription translated to"
                  ),
                model: zod
                  .enum(["base", "enhanced"])
                  .describe("Model you want the translation model to use to translate")
                  .default(
                    transcriptionControllerGetTranscriptV2ResponseRequestParamsRealtimeProcessingTranslationConfigModelDefault
                  )
                  .describe("Model you want the translation model to use to translate"),
                match_original_utterances: zod
                  .boolean()
                  .default(
                    transcriptionControllerGetTranscriptV2ResponseRequestParamsRealtimeProcessingTranslationConfigMatchOriginalUtterancesDefault
                  )
                  .describe("Align translated utterances with the original ones"),
                lipsync: zod
                  .boolean()
                  .default(
                    transcriptionControllerGetTranscriptV2ResponseRequestParamsRealtimeProcessingTranslationConfigLipsyncDefault
                  )
                  .describe("Whether to apply lipsync to the translated transcription. "),
                context_adaptation: zod
                  .boolean()
                  .default(
                    transcriptionControllerGetTranscriptV2ResponseRequestParamsRealtimeProcessingTranslationConfigContextAdaptationDefault
                  )
                  .describe(
                    "Enables or disables context-aware translation features that allow the model to adapt translations based on provided context."
                  ),
                context: zod
                  .string()
                  .optional()
                  .describe("Context information to improve translation accuracy"),
                informal: zod
                  .boolean()
                  .optional()
                  .describe(
                    "Forces the translation to use informal language forms when available in the target language."
                  )
              })
              .optional()
              .describe("Translation configuration, if `translation` is enabled"),
            named_entity_recognition: zod
              .boolean()
              .optional()
              .describe("If true, enable named entity recognition for the transcription."),
            sentiment_analysis: zod
              .boolean()
              .optional()
              .describe("If true, enable sentiment analysis for the transcription.")
          })
          .optional()
          .describe("Specify the realtime processing configuration"),
        post_processing: zod
          .object({
            summarization: zod
              .boolean()
              .optional()
              .describe("If true, generates summarization for the whole transcription."),
            summarization_config: zod
              .object({
                type: zod
                  .enum(["general", "bullet_points", "concise"])
                  .describe("The type of summarization to apply")
                  .default(
                    transcriptionControllerGetTranscriptV2ResponseRequestParamsPostProcessingSummarizationConfigTypeDefault
                  )
                  .describe("The type of summarization to apply")
              })
              .optional()
              .describe("Summarization configuration, if `summarization` is enabled"),
            chapterization: zod
              .boolean()
              .optional()
              .describe("If true, generates chapters for the whole transcription.")
          })
          .optional()
          .describe("Specify the post-processing configuration"),
        messages_config: zod
          .object({
            receive_partial_transcripts: zod
              .boolean()
              .optional()
              .describe("If true, partial transcript will be sent to websocket."),
            receive_final_transcripts: zod
              .boolean()
              .default(
                transcriptionControllerGetTranscriptV2ResponseRequestParamsMessagesConfigReceiveFinalTranscriptsDefault
              )
              .describe("If true, final transcript will be sent to websocket."),
            receive_speech_events: zod
              .boolean()
              .default(
                transcriptionControllerGetTranscriptV2ResponseRequestParamsMessagesConfigReceiveSpeechEventsDefault
              )
              .describe("If true, begin and end speech events will be sent to websocket."),
            receive_pre_processing_events: zod
              .boolean()
              .default(
                transcriptionControllerGetTranscriptV2ResponseRequestParamsMessagesConfigReceivePreProcessingEventsDefault
              )
              .describe("If true, pre-processing events will be sent to websocket."),
            receive_realtime_processing_events: zod
              .boolean()
              .default(
                transcriptionControllerGetTranscriptV2ResponseRequestParamsMessagesConfigReceiveRealtimeProcessingEventsDefault
              )
              .describe("If true, realtime processing events will be sent to websocket."),
            receive_post_processing_events: zod
              .boolean()
              .default(
                transcriptionControllerGetTranscriptV2ResponseRequestParamsMessagesConfigReceivePostProcessingEventsDefault
              )
              .describe("If true, post-processing events will be sent to websocket."),
            receive_acknowledgments: zod
              .boolean()
              .default(
                transcriptionControllerGetTranscriptV2ResponseRequestParamsMessagesConfigReceiveAcknowledgmentsDefault
              )
              .describe("If true, acknowledgments will be sent to websocket."),
            receive_errors: zod
              .boolean()
              .default(
                transcriptionControllerGetTranscriptV2ResponseRequestParamsMessagesConfigReceiveErrorsDefault
              )
              .describe("If true, errors will be sent to websocket."),
            receive_lifecycle_events: zod
              .boolean()
              .optional()
              .describe("If true, lifecycle events will be sent to websocket.")
          })
          .optional()
          .describe("Specify the websocket messages configuration"),
        callback: zod
          .boolean()
          .optional()
          .describe("If true, messages will be sent to configured url."),
        callback_config: zod
          .object({
            url: zod
              .string()
              .url()
              .optional()
              .describe("URL on which we will do a `POST` request with configured messages"),
            receive_partial_transcripts: zod
              .boolean()
              .optional()
              .describe("If true, partial transcript will be sent to the defined callback."),
            receive_final_transcripts: zod
              .boolean()
              .default(
                transcriptionControllerGetTranscriptV2ResponseRequestParamsCallbackConfigReceiveFinalTranscriptsDefault
              )
              .describe("If true, final transcript will be sent to the defined callback."),
            receive_speech_events: zod
              .boolean()
              .optional()
              .describe(
                "If true, begin and end speech events will be sent to the defined callback."
              ),
            receive_pre_processing_events: zod
              .boolean()
              .default(
                transcriptionControllerGetTranscriptV2ResponseRequestParamsCallbackConfigReceivePreProcessingEventsDefault
              )
              .describe("If true, pre-processing events will be sent to the defined callback."),
            receive_realtime_processing_events: zod
              .boolean()
              .default(
                transcriptionControllerGetTranscriptV2ResponseRequestParamsCallbackConfigReceiveRealtimeProcessingEventsDefault
              )
              .describe(
                "If true, realtime processing events will be sent to the defined callback."
              ),
            receive_post_processing_events: zod
              .boolean()
              .default(
                transcriptionControllerGetTranscriptV2ResponseRequestParamsCallbackConfigReceivePostProcessingEventsDefault
              )
              .describe("If true, post-processing events will be sent to the defined callback."),
            receive_acknowledgments: zod
              .boolean()
              .optional()
              .describe("If true, acknowledgments will be sent to the defined callback."),
            receive_errors: zod
              .boolean()
              .optional()
              .describe("If true, errors will be sent to the defined callback."),
            receive_lifecycle_events: zod
              .boolean()
              .default(
                transcriptionControllerGetTranscriptV2ResponseRequestParamsCallbackConfigReceiveLifecycleEventsDefault
              )
              .describe("If true, lifecycle events will be sent to the defined callback.")
          })
          .optional()
          .describe("Specify the callback configuration")
      })
      .nullish()
      .describe('Parameters used for this live transcription. Can be null if status is \"error\"'),
    result: zod
      .object({
        metadata: zod
          .object({
            audio_duration: zod.number().describe("Duration of the transcribed audio file"),
            number_of_distinct_channels: zod
              .number()
              .min(1)
              .describe("Number of distinct channels in the transcribed audio file"),
            billing_time: zod
              .number()
              .describe(
                "Billed duration in seconds (audio_duration * number_of_distinct_channels)"
              ),
            transcription_time: zod.number().describe("Duration of the transcription in seconds")
          })
          .describe("Metadata for the given transcription & audio file"),
        transcription: zod
          .object({
            full_transcript: zod
              .string()
              .describe("All transcription on text format without any other information"),
            languages: zod
              .array(
                zod
                  .enum([
                    "af",
                    "am",
                    "ar",
                    "as",
                    "az",
                    "ba",
                    "be",
                    "bg",
                    "bn",
                    "bo",
                    "br",
                    "bs",
                    "ca",
                    "cs",
                    "cy",
                    "da",
                    "de",
                    "el",
                    "en",
                    "es",
                    "et",
                    "eu",
                    "fa",
                    "fi",
                    "fo",
                    "fr",
                    "gl",
                    "gu",
                    "ha",
                    "haw",
                    "he",
                    "hi",
                    "hr",
                    "ht",
                    "hu",
                    "hy",
                    "id",
                    "is",
                    "it",
                    "ja",
                    "jw",
                    "ka",
                    "kk",
                    "km",
                    "kn",
                    "ko",
                    "la",
                    "lb",
                    "ln",
                    "lo",
                    "lt",
                    "lv",
                    "mg",
                    "mi",
                    "mk",
                    "ml",
                    "mn",
                    "mr",
                    "ms",
                    "mt",
                    "my",
                    "ne",
                    "nl",
                    "nn",
                    "no",
                    "oc",
                    "pa",
                    "pl",
                    "ps",
                    "pt",
                    "ro",
                    "ru",
                    "sa",
                    "sd",
                    "si",
                    "sk",
                    "sl",
                    "sn",
                    "so",
                    "sq",
                    "sr",
                    "su",
                    "sv",
                    "sw",
                    "ta",
                    "te",
                    "tg",
                    "th",
                    "tk",
                    "tl",
                    "tr",
                    "tt",
                    "uk",
                    "ur",
                    "uz",
                    "vi",
                    "yi",
                    "yo",
                    "zh"
                  ])
                  .describe(
                    "Specify the language in which it will be pronounced when sound comparison occurs. Default to transcription language."
                  )
              )
              .describe(
                "All the detected languages in the audio sorted from the most detected to the less detected"
              ),
            sentences: zod
              .array(
                zod.object({
                  success: zod
                    .boolean()
                    .describe("The audio intelligence model succeeded to get a valid output"),
                  is_empty: zod
                    .boolean()
                    .describe("The audio intelligence model returned an empty value"),
                  exec_time: zod
                    .number()
                    .describe("Time audio intelligence model took to complete the task"),
                  error: zod
                    .object({
                      status_code: zod.number().describe("Status code of the addon error"),
                      exception: zod.string().describe("Reason of the addon error"),
                      message: zod.string().describe("Detailed message of the addon error")
                    })
                    .nullable()
                    .describe(
                      "`null` if `success` is `true`. Contains the error details of the failed model"
                    ),
                  results: zod
                    .array(zod.string())
                    .nullable()
                    .describe("If `sentences` has been enabled, transcription as sentences.")
                })
              )
              .optional()
              .describe("If `sentences` has been enabled, sentences results"),
            subtitles: zod
              .array(
                zod.object({
                  format: zod
                    .enum(["srt", "vtt"])
                    .describe("Subtitles formats you want your transcription to be formatted to")
                    .describe("Format of the current subtitle"),
                  subtitles: zod.string().describe("Transcription on the asked subtitle format")
                })
              )
              .optional()
              .describe("If `subtitles` has been enabled, subtitles results"),
            utterances: zod
              .array(
                zod.object({
                  start: zod.number().describe("Start timestamp in seconds of this utterance"),
                  end: zod.number().describe("End timestamp in seconds of this utterance"),
                  confidence: zod
                    .number()
                    .describe("Confidence on the transcribed utterance (1 = 100% confident)"),
                  channel: zod
                    .number()
                    .min(
                      transcriptionControllerGetTranscriptV2ResponseResultTranscriptionUtterancesItemChannelMinOne
                    )
                    .describe("Audio channel of where this utterance has been transcribed from"),
                  speaker: zod
                    .number()
                    .min(
                      transcriptionControllerGetTranscriptV2ResponseResultTranscriptionUtterancesItemSpeakerMinOne
                    )
                    .optional()
                    .describe("If `diarization` enabled, speaker identification number"),
                  words: zod
                    .array(
                      zod.object({
                        word: zod.string().describe("Spoken word"),
                        start: zod
                          .number()
                          .describe("Start timestamps in seconds of the spoken word"),
                        end: zod.number().describe("End timestamps in seconds of the spoken word"),
                        confidence: zod
                          .number()
                          .describe("Confidence on the transcribed word (1 = 100% confident)")
                      })
                    )
                    .describe("List of words of the utterance, split by timestamp"),
                  text: zod.string().describe("Transcription for this utterance"),
                  language: zod
                    .enum([
                      "af",
                      "am",
                      "ar",
                      "as",
                      "az",
                      "ba",
                      "be",
                      "bg",
                      "bn",
                      "bo",
                      "br",
                      "bs",
                      "ca",
                      "cs",
                      "cy",
                      "da",
                      "de",
                      "el",
                      "en",
                      "es",
                      "et",
                      "eu",
                      "fa",
                      "fi",
                      "fo",
                      "fr",
                      "gl",
                      "gu",
                      "ha",
                      "haw",
                      "he",
                      "hi",
                      "hr",
                      "ht",
                      "hu",
                      "hy",
                      "id",
                      "is",
                      "it",
                      "ja",
                      "jw",
                      "ka",
                      "kk",
                      "km",
                      "kn",
                      "ko",
                      "la",
                      "lb",
                      "ln",
                      "lo",
                      "lt",
                      "lv",
                      "mg",
                      "mi",
                      "mk",
                      "ml",
                      "mn",
                      "mr",
                      "ms",
                      "mt",
                      "my",
                      "ne",
                      "nl",
                      "nn",
                      "no",
                      "oc",
                      "pa",
                      "pl",
                      "ps",
                      "pt",
                      "ro",
                      "ru",
                      "sa",
                      "sd",
                      "si",
                      "sk",
                      "sl",
                      "sn",
                      "so",
                      "sq",
                      "sr",
                      "su",
                      "sv",
                      "sw",
                      "ta",
                      "te",
                      "tg",
                      "th",
                      "tk",
                      "tl",
                      "tr",
                      "tt",
                      "uk",
                      "ur",
                      "uz",
                      "vi",
                      "yi",
                      "yo",
                      "zh"
                    ])
                    .describe(
                      "Specify the language in which it will be pronounced when sound comparison occurs. Default to transcription language."
                    )
                    .describe("Spoken language in this utterance")
                })
              )
              .describe("Transcribed speech utterances present in the audio")
          })
          .optional()
          .describe("Transcription of the audio speech"),
        translation: zod
          .object({
            success: zod
              .boolean()
              .describe("The audio intelligence model succeeded to get a valid output"),
            is_empty: zod
              .boolean()
              .describe("The audio intelligence model returned an empty value"),
            exec_time: zod
              .number()
              .describe("Time audio intelligence model took to complete the task"),
            error: zod
              .object({
                status_code: zod.number().describe("Status code of the addon error"),
                exception: zod.string().describe("Reason of the addon error"),
                message: zod.string().describe("Detailed message of the addon error")
              })
              .nullable()
              .describe(
                "`null` if `success` is `true`. Contains the error details of the failed model"
              ),
            results: zod
              .array(
                zod.object({
                  error: zod
                    .object({
                      status_code: zod.number().describe("Status code of the addon error"),
                      exception: zod.string().describe("Reason of the addon error"),
                      message: zod.string().describe("Detailed message of the addon error")
                    })
                    .nullable()
                    .describe("Contains the error details of the failed addon"),
                  full_transcript: zod
                    .string()
                    .describe("All transcription on text format without any other information"),
                  languages: zod
                    .array(
                      zod
                        .enum([
                          "af",
                          "am",
                          "ar",
                          "as",
                          "az",
                          "ba",
                          "be",
                          "bg",
                          "bn",
                          "bo",
                          "br",
                          "bs",
                          "ca",
                          "cs",
                          "cy",
                          "da",
                          "de",
                          "el",
                          "en",
                          "es",
                          "et",
                          "eu",
                          "fa",
                          "fi",
                          "fo",
                          "fr",
                          "gl",
                          "gu",
                          "ha",
                          "haw",
                          "he",
                          "hi",
                          "hr",
                          "ht",
                          "hu",
                          "hy",
                          "id",
                          "is",
                          "it",
                          "ja",
                          "jw",
                          "ka",
                          "kk",
                          "km",
                          "kn",
                          "ko",
                          "la",
                          "lb",
                          "ln",
                          "lo",
                          "lt",
                          "lv",
                          "mg",
                          "mi",
                          "mk",
                          "ml",
                          "mn",
                          "mr",
                          "ms",
                          "mt",
                          "my",
                          "ne",
                          "nl",
                          "nn",
                          "no",
                          "oc",
                          "pa",
                          "pl",
                          "ps",
                          "pt",
                          "ro",
                          "ru",
                          "sa",
                          "sd",
                          "si",
                          "sk",
                          "sl",
                          "sn",
                          "so",
                          "sq",
                          "sr",
                          "su",
                          "sv",
                          "sw",
                          "ta",
                          "te",
                          "tg",
                          "th",
                          "tk",
                          "tl",
                          "tr",
                          "tt",
                          "uk",
                          "ur",
                          "uz",
                          "vi",
                          "wo",
                          "yi",
                          "yo",
                          "zh"
                        ])
                        .describe(
                          "Target language in `iso639-1` format you want the transcription translated to"
                        )
                    )
                    .describe(
                      "All the detected languages in the audio sorted from the most detected to the less detected"
                    ),
                  sentences: zod
                    .array(
                      zod.object({
                        success: zod
                          .boolean()
                          .describe("The audio intelligence model succeeded to get a valid output"),
                        is_empty: zod
                          .boolean()
                          .describe("The audio intelligence model returned an empty value"),
                        exec_time: zod
                          .number()
                          .describe("Time audio intelligence model took to complete the task"),
                        error: zod
                          .object({
                            status_code: zod.number().describe("Status code of the addon error"),
                            exception: zod.string().describe("Reason of the addon error"),
                            message: zod.string().describe("Detailed message of the addon error")
                          })
                          .nullable()
                          .describe(
                            "`null` if `success` is `true`. Contains the error details of the failed model"
                          ),
                        results: zod
                          .array(zod.string())
                          .nullable()
                          .describe("If `sentences` has been enabled, transcription as sentences.")
                      })
                    )
                    .optional()
                    .describe(
                      "If `sentences` has been enabled, sentences results for this translation"
                    ),
                  subtitles: zod
                    .array(
                      zod.object({
                        format: zod
                          .enum(["srt", "vtt"])
                          .describe(
                            "Subtitles formats you want your transcription to be formatted to"
                          )
                          .describe("Format of the current subtitle"),
                        subtitles: zod
                          .string()
                          .describe("Transcription on the asked subtitle format")
                      })
                    )
                    .optional()
                    .describe(
                      "If `subtitles` has been enabled, subtitles results for this translation"
                    ),
                  utterances: zod
                    .array(
                      zod.object({
                        start: zod
                          .number()
                          .describe("Start timestamp in seconds of this utterance"),
                        end: zod.number().describe("End timestamp in seconds of this utterance"),
                        confidence: zod
                          .number()
                          .describe("Confidence on the transcribed utterance (1 = 100% confident)"),
                        channel: zod
                          .number()
                          .min(
                            transcriptionControllerGetTranscriptV2ResponseResultTranslationResultsItemUtterancesItemChannelMinOne
                          )
                          .describe(
                            "Audio channel of where this utterance has been transcribed from"
                          ),
                        speaker: zod
                          .number()
                          .min(
                            transcriptionControllerGetTranscriptV2ResponseResultTranslationResultsItemUtterancesItemSpeakerMinOne
                          )
                          .optional()
                          .describe("If `diarization` enabled, speaker identification number"),
                        words: zod
                          .array(
                            zod.object({
                              word: zod.string().describe("Spoken word"),
                              start: zod
                                .number()
                                .describe("Start timestamps in seconds of the spoken word"),
                              end: zod
                                .number()
                                .describe("End timestamps in seconds of the spoken word"),
                              confidence: zod
                                .number()
                                .describe("Confidence on the transcribed word (1 = 100% confident)")
                            })
                          )
                          .describe("List of words of the utterance, split by timestamp"),
                        text: zod.string().describe("Transcription for this utterance"),
                        language: zod
                          .enum([
                            "af",
                            "am",
                            "ar",
                            "as",
                            "az",
                            "ba",
                            "be",
                            "bg",
                            "bn",
                            "bo",
                            "br",
                            "bs",
                            "ca",
                            "cs",
                            "cy",
                            "da",
                            "de",
                            "el",
                            "en",
                            "es",
                            "et",
                            "eu",
                            "fa",
                            "fi",
                            "fo",
                            "fr",
                            "gl",
                            "gu",
                            "ha",
                            "haw",
                            "he",
                            "hi",
                            "hr",
                            "ht",
                            "hu",
                            "hy",
                            "id",
                            "is",
                            "it",
                            "ja",
                            "jw",
                            "ka",
                            "kk",
                            "km",
                            "kn",
                            "ko",
                            "la",
                            "lb",
                            "ln",
                            "lo",
                            "lt",
                            "lv",
                            "mg",
                            "mi",
                            "mk",
                            "ml",
                            "mn",
                            "mr",
                            "ms",
                            "mt",
                            "my",
                            "ne",
                            "nl",
                            "nn",
                            "no",
                            "oc",
                            "pa",
                            "pl",
                            "ps",
                            "pt",
                            "ro",
                            "ru",
                            "sa",
                            "sd",
                            "si",
                            "sk",
                            "sl",
                            "sn",
                            "so",
                            "sq",
                            "sr",
                            "su",
                            "sv",
                            "sw",
                            "ta",
                            "te",
                            "tg",
                            "th",
                            "tk",
                            "tl",
                            "tr",
                            "tt",
                            "uk",
                            "ur",
                            "uz",
                            "vi",
                            "yi",
                            "yo",
                            "zh"
                          ])
                          .describe(
                            "Specify the language in which it will be pronounced when sound comparison occurs. Default to transcription language."
                          )
                          .describe("Spoken language in this utterance")
                      })
                    )
                    .describe("Transcribed speech utterances present in the audio")
                })
              )
              .nullable()
              .describe("List of translated transcriptions, one for each `target_languages`")
          })
          .optional()
          .describe(
            "If `translation` has been enabled, translation of the audio speech transcription"
          ),
        summarization: zod
          .object({
            success: zod
              .boolean()
              .describe("The audio intelligence model succeeded to get a valid output"),
            is_empty: zod
              .boolean()
              .describe("The audio intelligence model returned an empty value"),
            exec_time: zod
              .number()
              .describe("Time audio intelligence model took to complete the task"),
            error: zod
              .object({
                status_code: zod.number().describe("Status code of the addon error"),
                exception: zod.string().describe("Reason of the addon error"),
                message: zod.string().describe("Detailed message of the addon error")
              })
              .nullable()
              .describe(
                "`null` if `success` is `true`. Contains the error details of the failed model"
              ),
            results: zod
              .string()
              .nullable()
              .describe("If `summarization` has been enabled, summary of the transcription")
          })
          .optional()
          .describe(
            "If `summarization` has been enabled, summarization of the audio speech transcription"
          ),
        named_entity_recognition: zod
          .object({
            success: zod
              .boolean()
              .describe("The audio intelligence model succeeded to get a valid output"),
            is_empty: zod
              .boolean()
              .describe("The audio intelligence model returned an empty value"),
            exec_time: zod
              .number()
              .describe("Time audio intelligence model took to complete the task"),
            error: zod
              .object({
                status_code: zod.number().describe("Status code of the addon error"),
                exception: zod.string().describe("Reason of the addon error"),
                message: zod.string().describe("Detailed message of the addon error")
              })
              .nullable()
              .describe(
                "`null` if `success` is `true`. Contains the error details of the failed model"
              ),
            entity: zod
              .string()
              .describe("If `named_entity_recognition` has been enabled, the detected entities.")
          })
          .optional()
          .describe("If `named_entity_recognition` has been enabled, the detected entities"),
        sentiment_analysis: zod
          .object({
            success: zod
              .boolean()
              .describe("The audio intelligence model succeeded to get a valid output"),
            is_empty: zod
              .boolean()
              .describe("The audio intelligence model returned an empty value"),
            exec_time: zod
              .number()
              .describe("Time audio intelligence model took to complete the task"),
            error: zod
              .object({
                status_code: zod.number().describe("Status code of the addon error"),
                exception: zod.string().describe("Reason of the addon error"),
                message: zod.string().describe("Detailed message of the addon error")
              })
              .nullable()
              .describe(
                "`null` if `success` is `true`. Contains the error details of the failed model"
              ),
            results: zod
              .string()
              .describe(
                "If `sentiment_analysis` has been enabled, Gladia will analyze the sentiments and emotions of the audio"
              )
          })
          .optional()
          .describe(
            "If `sentiment_analysis` has been enabled, sentiment analysis of the audio speech transcription"
          ),
        chapterization: zod
          .object({
            success: zod
              .boolean()
              .describe("The audio intelligence model succeeded to get a valid output"),
            is_empty: zod
              .boolean()
              .describe("The audio intelligence model returned an empty value"),
            exec_time: zod
              .number()
              .describe("Time audio intelligence model took to complete the task"),
            error: zod
              .object({
                status_code: zod.number().describe("Status code of the addon error"),
                exception: zod.string().describe("Reason of the addon error"),
                message: zod.string().describe("Detailed message of the addon error")
              })
              .nullable()
              .describe(
                "`null` if `success` is `true`. Contains the error details of the failed model"
              ),
            results: zod
              .record(zod.string(), zod.any())
              .describe(
                "If `chapterization` has been enabled, will generate chapters name for different parts of the given audio."
              )
          })
          .optional()
          .describe(
            "If `chapterization` has been enabled, will generate chapters name for different parts of the given audio."
          ),
        messages: zod
          .array(zod.string())
          .optional()
          .describe("Real-Time messages sent by the server during the live transcription")
      })
      .nullish()
      .describe('Live transcription\'s result when status is \"done\"')
  })
])

/**
 * @summary Delete the transcription job
 */
export const transcriptionControllerDeleteTranscriptV2Params = zod.object({
  id: zod.string().describe("Id of the transcription job")
})

/**
 * @summary Download the audio file used for this transcription job
 */
export const transcriptionControllerGetAudioV2Params = zod.object({
  id: zod.string().describe("Id of the transcription job")
})

export const audioToTextControllerAudioTranscriptionBodyAudioUrlDefault =
  "http://files.gladia.io/example/audio-transcription/split_infinity.wav"
export const audioToTextControllerAudioTranscriptionBodyLanguageBehaviourDefault =
  "automatic single language"
export const audioToTextControllerAudioTranscriptionBodyToggleDiarizationDefault = false
export const audioToTextControllerAudioTranscriptionBodyToggleDirectTranslateDefault = false
export const audioToTextControllerAudioTranscriptionBodyOutputFormatDefault = "json"
export const audioToTextControllerAudioTranscriptionBodyToggleNoiseReductionDefault = false
export const audioToTextControllerAudioTranscriptionBodyToggleAccurateWordsTimestampsDefault = false

export const audioToTextControllerAudioTranscriptionBody = zod.object({
  audio: zod.instanceof(File).optional(),
  audio_url: zod.string().default(audioToTextControllerAudioTranscriptionBodyAudioUrlDefault),
  language_behaviour: zod
    .enum(["automatic single language", "automatic multiple languages", "manual"])
    .default(audioToTextControllerAudioTranscriptionBodyLanguageBehaviourDefault),
  language: zod
    .enum([
      "afrikaans",
      "albanian",
      "amharic",
      "arabic",
      "armenian",
      "assamese",
      "azerbaijani",
      "bashkir",
      "basque",
      "belarusian",
      "bengali",
      "bosnian",
      "breton",
      "bulgarian",
      "catalan",
      "chinese",
      "croatian",
      "czech",
      "danish",
      "dutch",
      "english",
      "estonian",
      "faroese",
      "finnish",
      "french",
      "galician",
      "georgian",
      "german",
      "greek",
      "gujarati",
      "haitian creole",
      "hausa",
      "hawaiian",
      "hebrew",
      "hindi",
      "hungarian",
      "icelandic",
      "indonesian",
      "italian",
      "japanese",
      "javanese",
      "kannada",
      "kazakh",
      "khmer",
      "korean",
      "lao",
      "latin",
      "latvian",
      "lingala",
      "lithuanian",
      "luxembourgish",
      "macedonian",
      "malagasy",
      "malay",
      "malayalam",
      "maltese",
      "maori",
      "marathi",
      "mongolian",
      "myanmar",
      "nepali",
      "norwegian",
      "nynorsk",
      "occitan",
      "pashto",
      "persian",
      "polish",
      "portuguese",
      "punjabi",
      "romanian",
      "russian",
      "sanskrit",
      "serbian",
      "shona",
      "sindhi",
      "sinhala",
      "slovak",
      "slovenian",
      "somali",
      "spanish",
      "sundanese",
      "swahili",
      "swedish",
      "tagalog",
      "tajik",
      "tamil",
      "tatar",
      "telugu",
      "thai",
      "tibetan",
      "turkish",
      "turkmen",
      "ukrainian",
      "urdu",
      "uzbek",
      "vietnamese",
      "welsh",
      "yiddish",
      "yoruba"
    ])
    .optional(),
  transcription_hint: zod.string().optional(),
  toggle_diarization: zod.boolean().optional(),
  diarization_num_speakers: zod.number().optional(),
  diarization_min_speakers: zod.number().optional(),
  diarization_max_speakers: zod.number().optional(),
  toggle_direct_translate: zod.boolean().optional(),
  target_translation_language: zod
    .enum([
      "afrikaans",
      "albanian",
      "amharic",
      "arabic",
      "armenian",
      "assamese",
      "azerbaijani",
      "bashkir",
      "basque",
      "belarusian",
      "bengali",
      "bosnian",
      "breton",
      "bulgarian",
      "catalan",
      "chinese",
      "croatian",
      "czech",
      "danish",
      "dutch",
      "english",
      "estonian",
      "faroese",
      "finnish",
      "french",
      "galician",
      "georgian",
      "german",
      "greek",
      "gujarati",
      "haitian creole",
      "hausa",
      "hawaiian",
      "hebrew",
      "hindi",
      "hungarian",
      "icelandic",
      "indonesian",
      "italian",
      "japanese",
      "javanese",
      "kannada",
      "kazakh",
      "khmer",
      "korean",
      "lao",
      "latin",
      "latvian",
      "lingala",
      "lithuanian",
      "luxembourgish",
      "macedonian",
      "malagasy",
      "malay",
      "malayalam",
      "maltese",
      "maori",
      "marathi",
      "mongolian",
      "myanmar",
      "nepali",
      "norwegian",
      "nynorsk",
      "occitan",
      "pashto",
      "persian",
      "polish",
      "portuguese",
      "punjabi",
      "romanian",
      "russian",
      "sanskrit",
      "serbian",
      "shona",
      "sindhi",
      "sinhala",
      "slovak",
      "slovenian",
      "somali",
      "spanish",
      "sundanese",
      "swahili",
      "swedish",
      "tagalog",
      "tajik",
      "tamil",
      "tatar",
      "telugu",
      "thai",
      "tibetan",
      "turkish",
      "turkmen",
      "ukrainian",
      "urdu",
      "uzbek",
      "vietnamese",
      "welsh",
      "wolof",
      "yiddish",
      "yoruba"
    ])
    .optional(),
  output_format: zod
    .enum(["json", "srt", "vtt", "plain", "txt"])
    .default(audioToTextControllerAudioTranscriptionBodyOutputFormatDefault),
  toggle_noise_reduction: zod.boolean().optional(),
  toggle_accurate_words_timestamps: zod.boolean().optional(),
  webhook_url: zod.string().optional()
})

export const videoToTextControllerVideoTranscriptionBodyVideoUrlDefault =
  "http://files.gladia.io/example/audio-transcription/split_infinity.wav"
export const videoToTextControllerVideoTranscriptionBodyLanguageBehaviourDefault =
  "automatic single language"
export const videoToTextControllerVideoTranscriptionBodyToggleDiarizationDefault = false
export const videoToTextControllerVideoTranscriptionBodyToggleDirectTranslateDefault = false
export const videoToTextControllerVideoTranscriptionBodyOutputFormatDefault = "json"
export const videoToTextControllerVideoTranscriptionBodyToggleNoiseReductionDefault = false
export const videoToTextControllerVideoTranscriptionBodyToggleAccurateWordsTimestampsDefault = false

export const videoToTextControllerVideoTranscriptionBody = zod.object({
  video: zod.instanceof(File).optional(),
  video_url: zod.string().default(videoToTextControllerVideoTranscriptionBodyVideoUrlDefault),
  language_behaviour: zod
    .enum(["automatic single language", "automatic multiple languages", "manual"])
    .default(videoToTextControllerVideoTranscriptionBodyLanguageBehaviourDefault),
  language: zod
    .enum([
      "afrikaans",
      "albanian",
      "amharic",
      "arabic",
      "armenian",
      "assamese",
      "azerbaijani",
      "bashkir",
      "basque",
      "belarusian",
      "bengali",
      "bosnian",
      "breton",
      "bulgarian",
      "catalan",
      "chinese",
      "croatian",
      "czech",
      "danish",
      "dutch",
      "english",
      "estonian",
      "faroese",
      "finnish",
      "french",
      "galician",
      "georgian",
      "german",
      "greek",
      "gujarati",
      "haitian creole",
      "hausa",
      "hawaiian",
      "hebrew",
      "hindi",
      "hungarian",
      "icelandic",
      "indonesian",
      "italian",
      "japanese",
      "javanese",
      "kannada",
      "kazakh",
      "khmer",
      "korean",
      "lao",
      "latin",
      "latvian",
      "lingala",
      "lithuanian",
      "luxembourgish",
      "macedonian",
      "malagasy",
      "malay",
      "malayalam",
      "maltese",
      "maori",
      "marathi",
      "mongolian",
      "myanmar",
      "nepali",
      "norwegian",
      "nynorsk",
      "occitan",
      "pashto",
      "persian",
      "polish",
      "portuguese",
      "punjabi",
      "romanian",
      "russian",
      "sanskrit",
      "serbian",
      "shona",
      "sindhi",
      "sinhala",
      "slovak",
      "slovenian",
      "somali",
      "spanish",
      "sundanese",
      "swahili",
      "swedish",
      "tagalog",
      "tajik",
      "tamil",
      "tatar",
      "telugu",
      "thai",
      "tibetan",
      "turkish",
      "turkmen",
      "ukrainian",
      "urdu",
      "uzbek",
      "vietnamese",
      "welsh",
      "yiddish",
      "yoruba"
    ])
    .optional(),
  transcription_hint: zod.string().optional(),
  toggle_diarization: zod.boolean().optional(),
  diarization_num_speakers: zod.number().optional(),
  diarization_min_speakers: zod.number().optional(),
  diarization_max_speakers: zod.number().optional(),
  toggle_direct_translate: zod.boolean().optional(),
  target_translation_language: zod
    .enum([
      "afrikaans",
      "albanian",
      "amharic",
      "arabic",
      "armenian",
      "assamese",
      "azerbaijani",
      "bashkir",
      "basque",
      "belarusian",
      "bengali",
      "bosnian",
      "breton",
      "bulgarian",
      "catalan",
      "chinese",
      "croatian",
      "czech",
      "danish",
      "dutch",
      "english",
      "estonian",
      "faroese",
      "finnish",
      "french",
      "galician",
      "georgian",
      "german",
      "greek",
      "gujarati",
      "haitian creole",
      "hausa",
      "hawaiian",
      "hebrew",
      "hindi",
      "hungarian",
      "icelandic",
      "indonesian",
      "italian",
      "japanese",
      "javanese",
      "kannada",
      "kazakh",
      "khmer",
      "korean",
      "lao",
      "latin",
      "latvian",
      "lingala",
      "lithuanian",
      "luxembourgish",
      "macedonian",
      "malagasy",
      "malay",
      "malayalam",
      "maltese",
      "maori",
      "marathi",
      "mongolian",
      "myanmar",
      "nepali",
      "norwegian",
      "nynorsk",
      "occitan",
      "pashto",
      "persian",
      "polish",
      "portuguese",
      "punjabi",
      "romanian",
      "russian",
      "sanskrit",
      "serbian",
      "shona",
      "sindhi",
      "sinhala",
      "slovak",
      "slovenian",
      "somali",
      "spanish",
      "sundanese",
      "swahili",
      "swedish",
      "tagalog",
      "tajik",
      "tamil",
      "tatar",
      "telugu",
      "thai",
      "tibetan",
      "turkish",
      "turkmen",
      "ukrainian",
      "urdu",
      "uzbek",
      "vietnamese",
      "welsh",
      "wolof",
      "yiddish",
      "yoruba"
    ])
    .optional(),
  output_format: zod
    .enum(["json", "srt", "vtt", "plain", "txt"])
    .default(videoToTextControllerVideoTranscriptionBodyOutputFormatDefault),
  toggle_noise_reduction: zod.boolean().optional(),
  toggle_accurate_words_timestamps: zod.boolean().optional(),
  webhook_url: zod.string().optional()
})

/**
 * @summary Get the history of all your jobs
 */
export const historyControllerGetListV1QueryOffsetDefault = 0
export const historyControllerGetListV1QueryOffsetMin = 0
export const historyControllerGetListV1QueryLimitDefault = 20

export const historyControllerGetListV1QueryParams = zod.object({
  offset: zod
    .number()
    .min(historyControllerGetListV1QueryOffsetMin)
    .optional()
    .describe("The starting point for pagination. A value of 0 starts from the first item."),
  limit: zod
    .number()
    .min(1)
    .default(historyControllerGetListV1QueryLimitDefault)
    .describe(
      "The maximum number of items to return. Useful for pagination and controlling data payload size."
    ),
  date: zod
    .string()
    .datetime({})
    .optional()
    .describe("Filter items relevant to a specific date in ISO format (YYYY-MM-DD)."),
  before_date: zod
    .string()
    .datetime({})
    .optional()
    .describe("Include items that occurred before the specified date in ISO format."),
  after_date: zod
    .string()
    .datetime({})
    .optional()
    .describe(
      "Filter for items after the specified date. Use with `before_date` for a range. Date in ISO format."
    ),
  status: zod
    .array(zod.enum(["queued", "processing", "done", "error"]))
    .optional()
    .describe(
      "Filter the list based on item status. Accepts multiple values from the predefined list."
    ),
  custom_metadata: zod.record(zod.string(), zod.any()).optional(),
  kind: zod
    .array(zod.enum(["pre-recorded", "live"]))
    .optional()
    .describe(
      "Filter the list based on the item type. Supports multiple values from the predefined list."
    )
})

export const historyControllerGetListV1ResponseItemsItemErrorCodeMin = 400

export const historyControllerGetListV1ResponseItemsItemErrorCodeMax = 599
export const historyControllerGetListV1ResponseItemsItemKindDefault = "pre-recorded"
export const historyControllerGetListV1ResponseItemsItemRequestParamsCustomVocabularyDefault = false
export const historyControllerGetListV1ResponseItemsItemRequestParamsCustomVocabularyConfigVocabularyItemIntensityMin = 0

export const historyControllerGetListV1ResponseItemsItemRequestParamsCustomVocabularyConfigVocabularyItemIntensityMax = 1
export const historyControllerGetListV1ResponseItemsItemRequestParamsCustomVocabularyConfigDefaultIntensityMin = 0

export const historyControllerGetListV1ResponseItemsItemRequestParamsCustomVocabularyConfigDefaultIntensityMax = 1
export const historyControllerGetListV1ResponseItemsItemRequestParamsDetectLanguageDefault = true
export const historyControllerGetListV1ResponseItemsItemRequestParamsEnableCodeSwitchingDefault = false
export const historyControllerGetListV1ResponseItemsItemRequestParamsCodeSwitchingConfigLanguagesDefault =
  []
export const historyControllerGetListV1ResponseItemsItemRequestParamsCallbackDefault = false
export const historyControllerGetListV1ResponseItemsItemRequestParamsCallbackConfigMethodDefault =
  "POST"
export const historyControllerGetListV1ResponseItemsItemRequestParamsSubtitlesDefault = false
export const historyControllerGetListV1ResponseItemsItemRequestParamsSubtitlesConfigFormatsDefault: string[] =
  ["srt"]
export const historyControllerGetListV1ResponseItemsItemRequestParamsSubtitlesConfigMinimumDurationMin = 0
export const historyControllerGetListV1ResponseItemsItemRequestParamsSubtitlesConfigMaximumDurationMax = 30
export const historyControllerGetListV1ResponseItemsItemRequestParamsSubtitlesConfigMaximumRowsPerCaptionMax = 5
export const historyControllerGetListV1ResponseItemsItemRequestParamsSubtitlesConfigStyleDefault =
  "default"
export const historyControllerGetListV1ResponseItemsItemRequestParamsDiarizationDefault = false
export const historyControllerGetListV1ResponseItemsItemRequestParamsDiarizationConfigMinSpeakersMin = 0
export const historyControllerGetListV1ResponseItemsItemRequestParamsDiarizationConfigMaxSpeakersMin = 0
export const historyControllerGetListV1ResponseItemsItemRequestParamsTranslationDefault = false
export const historyControllerGetListV1ResponseItemsItemRequestParamsTranslationConfigModelDefault =
  "base"
export const historyControllerGetListV1ResponseItemsItemRequestParamsTranslationConfigMatchOriginalUtterancesDefault = true
export const historyControllerGetListV1ResponseItemsItemRequestParamsTranslationConfigLipsyncDefault = true
export const historyControllerGetListV1ResponseItemsItemRequestParamsTranslationConfigContextAdaptationDefault = true
export const historyControllerGetListV1ResponseItemsItemRequestParamsTranslationConfigInformalDefault = false
export const historyControllerGetListV1ResponseItemsItemRequestParamsSummarizationDefault = false
export const historyControllerGetListV1ResponseItemsItemRequestParamsSummarizationConfigTypeDefault =
  "general"
export const historyControllerGetListV1ResponseItemsItemRequestParamsModerationDefault = false
export const historyControllerGetListV1ResponseItemsItemRequestParamsNamedEntityRecognitionDefault = false
export const historyControllerGetListV1ResponseItemsItemRequestParamsChapterizationDefault = false
export const historyControllerGetListV1ResponseItemsItemRequestParamsNameConsistencyDefault = false
export const historyControllerGetListV1ResponseItemsItemRequestParamsCustomSpellingDefault = false
export const historyControllerGetListV1ResponseItemsItemRequestParamsStructuredDataExtractionDefault = false
export const historyControllerGetListV1ResponseItemsItemRequestParamsSentimentAnalysisDefault = false
export const historyControllerGetListV1ResponseItemsItemRequestParamsAudioToLlmDefault = false
export const historyControllerGetListV1ResponseItemsItemRequestParamsSentencesDefault = false
export const historyControllerGetListV1ResponseItemsItemRequestParamsDisplayModeDefault = false
export const historyControllerGetListV1ResponseItemsItemRequestParamsPunctuationEnhancedDefault = false
export const historyControllerGetListV1ResponseItemsItemRequestParamsLanguageConfigLanguagesDefault =
  []
export const historyControllerGetListV1ResponseItemsItemRequestParamsLanguageConfigCodeSwitchingDefault = false
export const historyControllerGetListV1ResponseItemsItemResultTranscriptionUtterancesItemChannelMin = 0
export const historyControllerGetListV1ResponseItemsItemResultTranscriptionUtterancesItemSpeakerMin = 0
export const historyControllerGetListV1ResponseItemsItemResultTranslationResultsItemUtterancesItemChannelMin = 0
export const historyControllerGetListV1ResponseItemsItemResultTranslationResultsItemUtterancesItemSpeakerMin = 0
export const historyControllerGetListV1ResponseItemsItemResultDiarizationResultsItemChannelMin = 0
export const historyControllerGetListV1ResponseItemsItemResultDiarizationResultsItemSpeakerMin = 0
export const historyControllerGetListV1ResponseItemsItemErrorCodeMinOne = 400

export const historyControllerGetListV1ResponseItemsItemErrorCodeMaxOne = 599
export const historyControllerGetListV1ResponseItemsItemKindDefaultOne = "live"
export const historyControllerGetListV1ResponseItemsItemRequestParamsEncodingDefault = "wav/pcm"
export const historyControllerGetListV1ResponseItemsItemRequestParamsBitDepthDefault = 16
export const historyControllerGetListV1ResponseItemsItemRequestParamsSampleRateDefault = 16000
export const historyControllerGetListV1ResponseItemsItemRequestParamsChannelsDefault = 1
export const historyControllerGetListV1ResponseItemsItemRequestParamsChannelsMax = 8
export const historyControllerGetListV1ResponseItemsItemRequestParamsModelDefault = "solaria-1"
export const historyControllerGetListV1ResponseItemsItemRequestParamsEndpointingDefault = 0.05
export const historyControllerGetListV1ResponseItemsItemRequestParamsEndpointingMin = 0.01

export const historyControllerGetListV1ResponseItemsItemRequestParamsEndpointingMax = 10
export const historyControllerGetListV1ResponseItemsItemRequestParamsMaximumDurationWithoutEndpointingDefault = 5
export const historyControllerGetListV1ResponseItemsItemRequestParamsMaximumDurationWithoutEndpointingMin = 5

export const historyControllerGetListV1ResponseItemsItemRequestParamsMaximumDurationWithoutEndpointingMax = 60
export const historyControllerGetListV1ResponseItemsItemRequestParamsLanguageConfigLanguagesDefaultOne =
  []
export const historyControllerGetListV1ResponseItemsItemRequestParamsLanguageConfigCodeSwitchingDefaultOne = false
export const historyControllerGetListV1ResponseItemsItemRequestParamsPreProcessingAudioEnhancerDefault = false
export const historyControllerGetListV1ResponseItemsItemRequestParamsPreProcessingSpeechThresholdDefault = 0.6
export const historyControllerGetListV1ResponseItemsItemRequestParamsPreProcessingSpeechThresholdMin = 0

export const historyControllerGetListV1ResponseItemsItemRequestParamsPreProcessingSpeechThresholdMax = 1
export const historyControllerGetListV1ResponseItemsItemRequestParamsRealtimeProcessingCustomVocabularyDefault = false
export const historyControllerGetListV1ResponseItemsItemRequestParamsRealtimeProcessingCustomVocabularyConfigVocabularyItemIntensityMin = 0

export const historyControllerGetListV1ResponseItemsItemRequestParamsRealtimeProcessingCustomVocabularyConfigVocabularyItemIntensityMax = 1
export const historyControllerGetListV1ResponseItemsItemRequestParamsRealtimeProcessingCustomVocabularyConfigDefaultIntensityMin = 0

export const historyControllerGetListV1ResponseItemsItemRequestParamsRealtimeProcessingCustomVocabularyConfigDefaultIntensityMax = 1
export const historyControllerGetListV1ResponseItemsItemRequestParamsRealtimeProcessingCustomSpellingDefault = false
export const historyControllerGetListV1ResponseItemsItemRequestParamsRealtimeProcessingTranslationDefault = false
export const historyControllerGetListV1ResponseItemsItemRequestParamsRealtimeProcessingTranslationConfigModelDefault =
  "base"
export const historyControllerGetListV1ResponseItemsItemRequestParamsRealtimeProcessingTranslationConfigMatchOriginalUtterancesDefault = true
export const historyControllerGetListV1ResponseItemsItemRequestParamsRealtimeProcessingTranslationConfigLipsyncDefault = true
export const historyControllerGetListV1ResponseItemsItemRequestParamsRealtimeProcessingTranslationConfigContextAdaptationDefault = true
export const historyControllerGetListV1ResponseItemsItemRequestParamsRealtimeProcessingTranslationConfigInformalDefault = false
export const historyControllerGetListV1ResponseItemsItemRequestParamsRealtimeProcessingNamedEntityRecognitionDefault = false
export const historyControllerGetListV1ResponseItemsItemRequestParamsRealtimeProcessingSentimentAnalysisDefault = false
export const historyControllerGetListV1ResponseItemsItemRequestParamsPostProcessingSummarizationDefault = false
export const historyControllerGetListV1ResponseItemsItemRequestParamsPostProcessingSummarizationConfigTypeDefault =
  "general"
export const historyControllerGetListV1ResponseItemsItemRequestParamsPostProcessingChapterizationDefault = false
export const historyControllerGetListV1ResponseItemsItemRequestParamsMessagesConfigReceivePartialTranscriptsDefault = false
export const historyControllerGetListV1ResponseItemsItemRequestParamsMessagesConfigReceiveFinalTranscriptsDefault = true
export const historyControllerGetListV1ResponseItemsItemRequestParamsMessagesConfigReceiveSpeechEventsDefault = true
export const historyControllerGetListV1ResponseItemsItemRequestParamsMessagesConfigReceivePreProcessingEventsDefault = true
export const historyControllerGetListV1ResponseItemsItemRequestParamsMessagesConfigReceiveRealtimeProcessingEventsDefault = true
export const historyControllerGetListV1ResponseItemsItemRequestParamsMessagesConfigReceivePostProcessingEventsDefault = true
export const historyControllerGetListV1ResponseItemsItemRequestParamsMessagesConfigReceiveAcknowledgmentsDefault = true
export const historyControllerGetListV1ResponseItemsItemRequestParamsMessagesConfigReceiveErrorsDefault = true
export const historyControllerGetListV1ResponseItemsItemRequestParamsMessagesConfigReceiveLifecycleEventsDefault = false
export const historyControllerGetListV1ResponseItemsItemRequestParamsCallbackDefaultOne = false
export const historyControllerGetListV1ResponseItemsItemRequestParamsCallbackConfigReceivePartialTranscriptsDefault = false
export const historyControllerGetListV1ResponseItemsItemRequestParamsCallbackConfigReceiveFinalTranscriptsDefault = true
export const historyControllerGetListV1ResponseItemsItemRequestParamsCallbackConfigReceiveSpeechEventsDefault = false
export const historyControllerGetListV1ResponseItemsItemRequestParamsCallbackConfigReceivePreProcessingEventsDefault = true
export const historyControllerGetListV1ResponseItemsItemRequestParamsCallbackConfigReceiveRealtimeProcessingEventsDefault = true
export const historyControllerGetListV1ResponseItemsItemRequestParamsCallbackConfigReceivePostProcessingEventsDefault = true
export const historyControllerGetListV1ResponseItemsItemRequestParamsCallbackConfigReceiveAcknowledgmentsDefault = false
export const historyControllerGetListV1ResponseItemsItemRequestParamsCallbackConfigReceiveErrorsDefault = false
export const historyControllerGetListV1ResponseItemsItemRequestParamsCallbackConfigReceiveLifecycleEventsDefault = true
export const historyControllerGetListV1ResponseItemsItemResultTranscriptionUtterancesItemChannelMinOne = 0
export const historyControllerGetListV1ResponseItemsItemResultTranscriptionUtterancesItemSpeakerMinOne = 0
export const historyControllerGetListV1ResponseItemsItemResultTranslationResultsItemUtterancesItemChannelMinOne = 0
export const historyControllerGetListV1ResponseItemsItemResultTranslationResultsItemUtterancesItemSpeakerMinOne = 0

export const historyControllerGetListV1Response = zod.object({
  first: zod.string().url().describe("URL to fetch the first page"),
  current: zod.string().url().describe("URL to fetch the current page"),
  next: zod.string().url().nullable().describe("URL to fetch the next page"),
  items: zod
    .array(
      zod
        .object({
          id: zod.string().uuid().describe("Id of the job"),
          request_id: zod.string().describe("Debug id"),
          version: zod.number().describe("API version"),
          status: zod
            .enum(["queued", "processing", "done", "error"])
            .describe(
              '\"queued\": the job has been queued. \"processing\": the job is being processed. \"done\": the job has been processed and the result is available. \"error\": an error occurred during the job\'s processing.'
            ),
          created_at: zod.string().datetime({}).describe("Creation date"),
          completed_at: zod
            .string()
            .datetime({})
            .nullish()
            .describe('Completion date when status is \"done\" or \"error\"'),
          custom_metadata: zod
            .record(zod.string(), zod.any())
            .optional()
            .describe("Custom metadata given in the initial request"),
          error_code: zod
            .number()
            .min(historyControllerGetListV1ResponseItemsItemErrorCodeMin)
            .max(historyControllerGetListV1ResponseItemsItemErrorCodeMax)
            .nullish()
            .describe('HTTP status code of the error if status is \"error\"'),
          post_session_metadata: zod
            .object({})
            .describe("For debugging purposes, send data that could help to identify issues"),
          kind: zod.enum(["pre-recorded"]),
          file: zod
            .object({
              id: zod.string().describe("The file id"),
              filename: zod.string().nullable().describe("The name of the uploaded file"),
              source: zod
                .string()
                .nullable()
                .describe("The link used to download the file if audio_url was used"),
              audio_duration: zod.number().nullable().describe("Duration of the audio file"),
              number_of_channels: zod
                .number()
                .min(1)
                .nullable()
                .describe("Number of channels in the audio file")
            })
            .nullish()
            .describe('The file data you uploaded. Can be null if status is \"error\"'),
          request_params: zod
            .object({
              context_prompt: zod
                .string()
                .optional()
                .describe(
                  "**[Deprecated]** Context to feed the transcription model with for possible better accuracy"
                ),
              custom_vocabulary: zod
                .boolean()
                .optional()
                .describe(
                  "**[Beta]** Can be either boolean to enable custom_vocabulary for this audio or an array with specific vocabulary list to feed the transcription model with"
                ),
              custom_vocabulary_config: zod
                .object({
                  vocabulary: zod
                    .array(
                      zod
                        .object({
                          value: zod
                            .string()
                            .describe("The text used to replace in the transcription."),
                          intensity: zod
                            .number()
                            .min(
                              historyControllerGetListV1ResponseItemsItemRequestParamsCustomVocabularyConfigVocabularyItemIntensityMin
                            )
                            .max(
                              historyControllerGetListV1ResponseItemsItemRequestParamsCustomVocabularyConfigVocabularyItemIntensityMax
                            )
                            .optional()
                            .describe("The global intensity of the feature."),
                          pronunciations: zod
                            .array(zod.string())
                            .optional()
                            .describe("The pronunciations used in the transcription."),
                          language: zod
                            .enum([
                              "af",
                              "am",
                              "ar",
                              "as",
                              "az",
                              "ba",
                              "be",
                              "bg",
                              "bn",
                              "bo",
                              "br",
                              "bs",
                              "ca",
                              "cs",
                              "cy",
                              "da",
                              "de",
                              "el",
                              "en",
                              "es",
                              "et",
                              "eu",
                              "fa",
                              "fi",
                              "fo",
                              "fr",
                              "gl",
                              "gu",
                              "ha",
                              "haw",
                              "he",
                              "hi",
                              "hr",
                              "ht",
                              "hu",
                              "hy",
                              "id",
                              "is",
                              "it",
                              "ja",
                              "jw",
                              "ka",
                              "kk",
                              "km",
                              "kn",
                              "ko",
                              "la",
                              "lb",
                              "ln",
                              "lo",
                              "lt",
                              "lv",
                              "mg",
                              "mi",
                              "mk",
                              "ml",
                              "mn",
                              "mr",
                              "ms",
                              "mt",
                              "my",
                              "ne",
                              "nl",
                              "nn",
                              "no",
                              "oc",
                              "pa",
                              "pl",
                              "ps",
                              "pt",
                              "ro",
                              "ru",
                              "sa",
                              "sd",
                              "si",
                              "sk",
                              "sl",
                              "sn",
                              "so",
                              "sq",
                              "sr",
                              "su",
                              "sv",
                              "sw",
                              "ta",
                              "te",
                              "tg",
                              "th",
                              "tk",
                              "tl",
                              "tr",
                              "tt",
                              "uk",
                              "ur",
                              "uz",
                              "vi",
                              "yi",
                              "yo",
                              "zh"
                            ])
                            .describe(
                              "Specify the language in which it will be pronounced when sound comparison occurs. Default to transcription language."
                            )
                            .optional()
                            .describe(
                              "Specify the language in which it will be pronounced when sound comparison occurs. Default to transcription language."
                            )
                        })
                        .or(zod.string())
                    )
                    .describe(
                      "Specific vocabulary list to feed the transcription model with. Each item can be a string or an object with the following properties: value, intensity, pronunciations, language."
                    ),
                  default_intensity: zod
                    .number()
                    .min(
                      historyControllerGetListV1ResponseItemsItemRequestParamsCustomVocabularyConfigDefaultIntensityMin
                    )
                    .max(
                      historyControllerGetListV1ResponseItemsItemRequestParamsCustomVocabularyConfigDefaultIntensityMax
                    )
                    .optional()
                    .describe("Default intensity for the custom vocabulary")
                })
                .optional()
                .describe(
                  "**[Beta]** Custom vocabulary configuration, if `custom_vocabulary` is enabled"
                ),
              detect_language: zod
                .boolean()
                .default(
                  historyControllerGetListV1ResponseItemsItemRequestParamsDetectLanguageDefault
                )
                .describe(
                  "**[Deprecated]** Use `language_config` instead. Detect the language from the given audio"
                ),
              enable_code_switching: zod
                .boolean()
                .optional()
                .describe(
                  "**[Deprecated]** Use `language_config` instead.Detect multiple languages in the given audio"
                ),
              code_switching_config: zod
                .object({
                  languages: zod
                    .array(
                      zod
                        .enum([
                          "af",
                          "am",
                          "ar",
                          "as",
                          "az",
                          "ba",
                          "be",
                          "bg",
                          "bn",
                          "bo",
                          "br",
                          "bs",
                          "ca",
                          "cs",
                          "cy",
                          "da",
                          "de",
                          "el",
                          "en",
                          "es",
                          "et",
                          "eu",
                          "fa",
                          "fi",
                          "fo",
                          "fr",
                          "gl",
                          "gu",
                          "ha",
                          "haw",
                          "he",
                          "hi",
                          "hr",
                          "ht",
                          "hu",
                          "hy",
                          "id",
                          "is",
                          "it",
                          "ja",
                          "jw",
                          "ka",
                          "kk",
                          "km",
                          "kn",
                          "ko",
                          "la",
                          "lb",
                          "ln",
                          "lo",
                          "lt",
                          "lv",
                          "mg",
                          "mi",
                          "mk",
                          "ml",
                          "mn",
                          "mr",
                          "ms",
                          "mt",
                          "my",
                          "ne",
                          "nl",
                          "nn",
                          "no",
                          "oc",
                          "pa",
                          "pl",
                          "ps",
                          "pt",
                          "ro",
                          "ru",
                          "sa",
                          "sd",
                          "si",
                          "sk",
                          "sl",
                          "sn",
                          "so",
                          "sq",
                          "sr",
                          "su",
                          "sv",
                          "sw",
                          "ta",
                          "te",
                          "tg",
                          "th",
                          "tk",
                          "tl",
                          "tr",
                          "tt",
                          "uk",
                          "ur",
                          "uz",
                          "vi",
                          "yi",
                          "yo",
                          "zh"
                        ])
                        .describe(
                          "Specify the language in which it will be pronounced when sound comparison occurs. Default to transcription language."
                        )
                    )
                    .default(
                      historyControllerGetListV1ResponseItemsItemRequestParamsCodeSwitchingConfigLanguagesDefault
                    )
                    .describe(
                      "Specify the languages you want to use when detecting multiple languages"
                    )
                })
                .optional()
                .describe(
                  "**[Deprecated]** Use `language_config` instead. Specify the configuration for code switching"
                ),
              language: zod
                .enum([
                  "af",
                  "am",
                  "ar",
                  "as",
                  "az",
                  "ba",
                  "be",
                  "bg",
                  "bn",
                  "bo",
                  "br",
                  "bs",
                  "ca",
                  "cs",
                  "cy",
                  "da",
                  "de",
                  "el",
                  "en",
                  "es",
                  "et",
                  "eu",
                  "fa",
                  "fi",
                  "fo",
                  "fr",
                  "gl",
                  "gu",
                  "ha",
                  "haw",
                  "he",
                  "hi",
                  "hr",
                  "ht",
                  "hu",
                  "hy",
                  "id",
                  "is",
                  "it",
                  "ja",
                  "jw",
                  "ka",
                  "kk",
                  "km",
                  "kn",
                  "ko",
                  "la",
                  "lb",
                  "ln",
                  "lo",
                  "lt",
                  "lv",
                  "mg",
                  "mi",
                  "mk",
                  "ml",
                  "mn",
                  "mr",
                  "ms",
                  "mt",
                  "my",
                  "ne",
                  "nl",
                  "nn",
                  "no",
                  "oc",
                  "pa",
                  "pl",
                  "ps",
                  "pt",
                  "ro",
                  "ru",
                  "sa",
                  "sd",
                  "si",
                  "sk",
                  "sl",
                  "sn",
                  "so",
                  "sq",
                  "sr",
                  "su",
                  "sv",
                  "sw",
                  "ta",
                  "te",
                  "tg",
                  "th",
                  "tk",
                  "tl",
                  "tr",
                  "tt",
                  "uk",
                  "ur",
                  "uz",
                  "vi",
                  "yi",
                  "yo",
                  "zh"
                ])
                .describe(
                  "Specify the language in which it will be pronounced when sound comparison occurs. Default to transcription language."
                )
                .optional()
                .describe(
                  "**[Deprecated]** Use `language_config` instead. Set the spoken language for the given audio (ISO 639 standard)"
                ),
              callback_url: zod
                .string()
                .url()
                .optional()
                .describe(
                  "**[Deprecated]** Use `callback`/`callback_config` instead. Callback URL we will do a `POST` request to with the result of the transcription"
                ),
              callback: zod
                .boolean()
                .optional()
                .describe(
                  "Enable callback for this transcription. If true, the `callback_config` property will be used to customize the callback behaviour"
                ),
              callback_config: zod
                .object({
                  url: zod
                    .string()
                    .url()
                    .describe("The URL to be called with the result of the transcription"),
                  method: zod
                    .enum(["POST", "PUT"])
                    .describe(
                      "The HTTP method to be used. Allowed values are `POST` or `PUT` (default: `POST`)"
                    )
                    .default(
                      historyControllerGetListV1ResponseItemsItemRequestParamsCallbackConfigMethodDefault
                    )
                    .describe(
                      "The HTTP method to be used. Allowed values are `POST` or `PUT` (default: `POST`)"
                    )
                })
                .optional()
                .describe("Customize the callback behaviour (url and http method)"),
              subtitles: zod
                .boolean()
                .optional()
                .describe("Enable subtitles generation for this transcription"),
              subtitles_config: zod
                .object({
                  formats: zod
                    .array(
                      zod
                        .enum(["srt", "vtt"])
                        .describe(
                          "Subtitles formats you want your transcription to be formatted to"
                        )
                    )
                    .min(1)
                    .default(
                      historyControllerGetListV1ResponseItemsItemRequestParamsSubtitlesConfigFormatsDefault
                    )
                    .describe("Subtitles formats you want your transcription to be formatted to"),
                  minimum_duration: zod
                    .number()
                    .min(
                      historyControllerGetListV1ResponseItemsItemRequestParamsSubtitlesConfigMinimumDurationMin
                    )
                    .optional()
                    .describe("Minimum duration of a subtitle in seconds"),
                  maximum_duration: zod
                    .number()
                    .min(1)
                    .max(
                      historyControllerGetListV1ResponseItemsItemRequestParamsSubtitlesConfigMaximumDurationMax
                    )
                    .optional()
                    .describe("Maximum duration of a subtitle in seconds"),
                  maximum_characters_per_row: zod
                    .number()
                    .min(1)
                    .optional()
                    .describe("Maximum number of characters per row in a subtitle"),
                  maximum_rows_per_caption: zod
                    .number()
                    .min(1)
                    .max(
                      historyControllerGetListV1ResponseItemsItemRequestParamsSubtitlesConfigMaximumRowsPerCaptionMax
                    )
                    .optional()
                    .describe("Maximum number of rows per caption"),
                  style: zod
                    .enum(["default", "compliance"])
                    .describe(
                      "Style of the subtitles. Compliance mode refers to : https://loc.gov/preservation/digital/formats//fdd/fdd000569.shtml#:~:text=SRT%20files%20are%20basic%20text,alongside%2C%20example%3A%20%22MyVideo123 "
                    )
                    .default(
                      historyControllerGetListV1ResponseItemsItemRequestParamsSubtitlesConfigStyleDefault
                    )
                    .describe(
                      "Style of the subtitles. Compliance mode refers to : https://loc.gov/preservation/digital/formats//fdd/fdd000569.shtml#:~:text=SRT%20files%20are%20basic%20text,alongside%2C%20example%3A%20%22MyVideo123 "
                    )
                })
                .optional()
                .describe("Configuration for subtitles generation if `subtitles` is enabled"),
              diarization: zod
                .boolean()
                .optional()
                .describe("Enable speaker recognition (diarization) for this audio"),
              diarization_config: zod
                .object({
                  number_of_speakers: zod
                    .number()
                    .min(1)
                    .optional()
                    .describe("Exact number of speakers in the audio"),
                  min_speakers: zod
                    .number()
                    .min(
                      historyControllerGetListV1ResponseItemsItemRequestParamsDiarizationConfigMinSpeakersMin
                    )
                    .optional()
                    .describe("Minimum number of speakers in the audio"),
                  max_speakers: zod
                    .number()
                    .min(
                      historyControllerGetListV1ResponseItemsItemRequestParamsDiarizationConfigMaxSpeakersMin
                    )
                    .optional()
                    .describe("Maximum number of speakers in the audio")
                })
                .optional()
                .describe("Speaker recognition configuration, if `diarization` is enabled"),
              translation: zod
                .boolean()
                .optional()
                .describe("**[Beta]** Enable translation for this audio"),
              translation_config: zod
                .object({
                  target_languages: zod
                    .array(
                      zod
                        .enum([
                          "af",
                          "am",
                          "ar",
                          "as",
                          "az",
                          "ba",
                          "be",
                          "bg",
                          "bn",
                          "bo",
                          "br",
                          "bs",
                          "ca",
                          "cs",
                          "cy",
                          "da",
                          "de",
                          "el",
                          "en",
                          "es",
                          "et",
                          "eu",
                          "fa",
                          "fi",
                          "fo",
                          "fr",
                          "gl",
                          "gu",
                          "ha",
                          "haw",
                          "he",
                          "hi",
                          "hr",
                          "ht",
                          "hu",
                          "hy",
                          "id",
                          "is",
                          "it",
                          "ja",
                          "jw",
                          "ka",
                          "kk",
                          "km",
                          "kn",
                          "ko",
                          "la",
                          "lb",
                          "ln",
                          "lo",
                          "lt",
                          "lv",
                          "mg",
                          "mi",
                          "mk",
                          "ml",
                          "mn",
                          "mr",
                          "ms",
                          "mt",
                          "my",
                          "ne",
                          "nl",
                          "nn",
                          "no",
                          "oc",
                          "pa",
                          "pl",
                          "ps",
                          "pt",
                          "ro",
                          "ru",
                          "sa",
                          "sd",
                          "si",
                          "sk",
                          "sl",
                          "sn",
                          "so",
                          "sq",
                          "sr",
                          "su",
                          "sv",
                          "sw",
                          "ta",
                          "te",
                          "tg",
                          "th",
                          "tk",
                          "tl",
                          "tr",
                          "tt",
                          "uk",
                          "ur",
                          "uz",
                          "vi",
                          "wo",
                          "yi",
                          "yo",
                          "zh"
                        ])
                        .describe(
                          "Target language in `iso639-1` format you want the transcription translated to"
                        )
                    )
                    .min(1)
                    .describe(
                      "Target language in `iso639-1` format you want the transcription translated to"
                    ),
                  model: zod
                    .enum(["base", "enhanced"])
                    .describe("Model you want the translation model to use to translate")
                    .default(
                      historyControllerGetListV1ResponseItemsItemRequestParamsTranslationConfigModelDefault
                    )
                    .describe("Model you want the translation model to use to translate"),
                  match_original_utterances: zod
                    .boolean()
                    .default(
                      historyControllerGetListV1ResponseItemsItemRequestParamsTranslationConfigMatchOriginalUtterancesDefault
                    )
                    .describe("Align translated utterances with the original ones"),
                  lipsync: zod
                    .boolean()
                    .default(
                      historyControllerGetListV1ResponseItemsItemRequestParamsTranslationConfigLipsyncDefault
                    )
                    .describe("Whether to apply lipsync to the translated transcription. "),
                  context_adaptation: zod
                    .boolean()
                    .default(
                      historyControllerGetListV1ResponseItemsItemRequestParamsTranslationConfigContextAdaptationDefault
                    )
                    .describe(
                      "Enables or disables context-aware translation features that allow the model to adapt translations based on provided context."
                    ),
                  context: zod
                    .string()
                    .optional()
                    .describe("Context information to improve translation accuracy"),
                  informal: zod
                    .boolean()
                    .optional()
                    .describe(
                      "Forces the translation to use informal language forms when available in the target language."
                    )
                })
                .optional()
                .describe("**[Beta]** Translation configuration, if `translation` is enabled"),
              summarization: zod
                .boolean()
                .optional()
                .describe("**[Beta]** Enable summarization for this audio"),
              summarization_config: zod
                .object({
                  type: zod
                    .enum(["general", "bullet_points", "concise"])
                    .describe("The type of summarization to apply")
                    .default(
                      historyControllerGetListV1ResponseItemsItemRequestParamsSummarizationConfigTypeDefault
                    )
                    .describe("The type of summarization to apply")
                })
                .optional()
                .describe("**[Beta]** Summarization configuration, if `summarization` is enabled"),
              moderation: zod
                .boolean()
                .optional()
                .describe("**[Alpha]** Enable moderation for this audio"),
              named_entity_recognition: zod
                .boolean()
                .optional()
                .describe("**[Alpha]** Enable named entity recognition for this audio"),
              chapterization: zod
                .boolean()
                .optional()
                .describe("**[Alpha]** Enable chapterization for this audio"),
              name_consistency: zod
                .boolean()
                .optional()
                .describe("**[Alpha]** Enable names consistency for this audio"),
              custom_spelling: zod
                .boolean()
                .optional()
                .describe("**[Alpha]** Enable custom spelling for this audio"),
              custom_spelling_config: zod
                .object({
                  spelling_dictionary: zod
                    .record(zod.string(), zod.array(zod.string()))
                    .describe("The list of spelling applied on the audio transcription")
                })
                .optional()
                .describe(
                  "**[Alpha]** Custom spelling configuration, if `custom_spelling` is enabled"
                ),
              structured_data_extraction: zod
                .boolean()
                .optional()
                .describe("**[Alpha]** Enable structured data extraction for this audio"),
              structured_data_extraction_config: zod
                .object({
                  classes: zod
                    .array(zod.array(zod.unknown()))
                    .min(1)
                    .describe("The list of classes to extract from the audio transcription")
                })
                .optional()
                .describe(
                  "**[Alpha]** Structured data extraction configuration, if `structured_data_extraction` is enabled"
                ),
              sentiment_analysis: zod
                .boolean()
                .optional()
                .describe("Enable sentiment analysis for this audio"),
              audio_to_llm: zod
                .boolean()
                .optional()
                .describe("**[Alpha]** Enable audio to llm processing for this audio"),
              audio_to_llm_config: zod
                .object({
                  prompts: zod
                    .array(zod.array(zod.unknown()))
                    .min(1)
                    .describe("The list of prompts applied on the audio transcription")
                })
                .optional()
                .describe("**[Alpha]** Audio to llm configuration, if `audio_to_llm` is enabled"),
              sentences: zod.boolean().optional().describe("Enable sentences for this audio"),
              display_mode: zod
                .boolean()
                .optional()
                .describe(
                  "**[Alpha]** Allows to change the output display_mode for this audio. The output will be reordered, creating new utterances when speakers overlapped"
                ),
              punctuation_enhanced: zod
                .boolean()
                .optional()
                .describe("**[Alpha]** Use enhanced punctuation for this audio"),
              language_config: zod
                .object({
                  languages: zod
                    .array(
                      zod
                        .enum([
                          "af",
                          "am",
                          "ar",
                          "as",
                          "az",
                          "ba",
                          "be",
                          "bg",
                          "bn",
                          "bo",
                          "br",
                          "bs",
                          "ca",
                          "cs",
                          "cy",
                          "da",
                          "de",
                          "el",
                          "en",
                          "es",
                          "et",
                          "eu",
                          "fa",
                          "fi",
                          "fo",
                          "fr",
                          "gl",
                          "gu",
                          "ha",
                          "haw",
                          "he",
                          "hi",
                          "hr",
                          "ht",
                          "hu",
                          "hy",
                          "id",
                          "is",
                          "it",
                          "ja",
                          "jw",
                          "ka",
                          "kk",
                          "km",
                          "kn",
                          "ko",
                          "la",
                          "lb",
                          "ln",
                          "lo",
                          "lt",
                          "lv",
                          "mg",
                          "mi",
                          "mk",
                          "ml",
                          "mn",
                          "mr",
                          "ms",
                          "mt",
                          "my",
                          "ne",
                          "nl",
                          "nn",
                          "no",
                          "oc",
                          "pa",
                          "pl",
                          "ps",
                          "pt",
                          "ro",
                          "ru",
                          "sa",
                          "sd",
                          "si",
                          "sk",
                          "sl",
                          "sn",
                          "so",
                          "sq",
                          "sr",
                          "su",
                          "sv",
                          "sw",
                          "ta",
                          "te",
                          "tg",
                          "th",
                          "tk",
                          "tl",
                          "tr",
                          "tt",
                          "uk",
                          "ur",
                          "uz",
                          "vi",
                          "yi",
                          "yo",
                          "zh"
                        ])
                        .describe(
                          "Specify the language in which it will be pronounced when sound comparison occurs. Default to transcription language."
                        )
                    )
                    .default(
                      historyControllerGetListV1ResponseItemsItemRequestParamsLanguageConfigLanguagesDefault
                    )
                    .describe(
                      "If one language is set, it will be used for the transcription. Otherwise, language will be auto-detected by the model."
                    ),
                  code_switching: zod
                    .boolean()
                    .optional()
                    .describe(
                      "If true, language will be auto-detected on each utterance. Otherwise, language will be auto-detected on first utterance and then used for the rest of the transcription. If one language is set, this option will be ignored."
                    )
                })
                .optional()
                .describe("Specify the language configuration"),
              audio_url: zod.string().url().nullable()
            })
            .nullish()
            .describe(
              'Parameters used for this pre-recorded transcription. Can be null if status is \"error\"'
            ),
          result: zod
            .object({
              metadata: zod
                .object({
                  audio_duration: zod.number().describe("Duration of the transcribed audio file"),
                  number_of_distinct_channels: zod
                    .number()
                    .min(1)
                    .describe("Number of distinct channels in the transcribed audio file"),
                  billing_time: zod
                    .number()
                    .describe(
                      "Billed duration in seconds (audio_duration * number_of_distinct_channels)"
                    ),
                  transcription_time: zod
                    .number()
                    .describe("Duration of the transcription in seconds")
                })
                .describe("Metadata for the given transcription & audio file"),
              transcription: zod
                .object({
                  full_transcript: zod
                    .string()
                    .describe("All transcription on text format without any other information"),
                  languages: zod
                    .array(
                      zod
                        .enum([
                          "af",
                          "am",
                          "ar",
                          "as",
                          "az",
                          "ba",
                          "be",
                          "bg",
                          "bn",
                          "bo",
                          "br",
                          "bs",
                          "ca",
                          "cs",
                          "cy",
                          "da",
                          "de",
                          "el",
                          "en",
                          "es",
                          "et",
                          "eu",
                          "fa",
                          "fi",
                          "fo",
                          "fr",
                          "gl",
                          "gu",
                          "ha",
                          "haw",
                          "he",
                          "hi",
                          "hr",
                          "ht",
                          "hu",
                          "hy",
                          "id",
                          "is",
                          "it",
                          "ja",
                          "jw",
                          "ka",
                          "kk",
                          "km",
                          "kn",
                          "ko",
                          "la",
                          "lb",
                          "ln",
                          "lo",
                          "lt",
                          "lv",
                          "mg",
                          "mi",
                          "mk",
                          "ml",
                          "mn",
                          "mr",
                          "ms",
                          "mt",
                          "my",
                          "ne",
                          "nl",
                          "nn",
                          "no",
                          "oc",
                          "pa",
                          "pl",
                          "ps",
                          "pt",
                          "ro",
                          "ru",
                          "sa",
                          "sd",
                          "si",
                          "sk",
                          "sl",
                          "sn",
                          "so",
                          "sq",
                          "sr",
                          "su",
                          "sv",
                          "sw",
                          "ta",
                          "te",
                          "tg",
                          "th",
                          "tk",
                          "tl",
                          "tr",
                          "tt",
                          "uk",
                          "ur",
                          "uz",
                          "vi",
                          "yi",
                          "yo",
                          "zh"
                        ])
                        .describe(
                          "Specify the language in which it will be pronounced when sound comparison occurs. Default to transcription language."
                        )
                    )
                    .describe(
                      "All the detected languages in the audio sorted from the most detected to the less detected"
                    ),
                  sentences: zod
                    .array(
                      zod.object({
                        success: zod
                          .boolean()
                          .describe("The audio intelligence model succeeded to get a valid output"),
                        is_empty: zod
                          .boolean()
                          .describe("The audio intelligence model returned an empty value"),
                        exec_time: zod
                          .number()
                          .describe("Time audio intelligence model took to complete the task"),
                        error: zod
                          .object({
                            status_code: zod.number().describe("Status code of the addon error"),
                            exception: zod.string().describe("Reason of the addon error"),
                            message: zod.string().describe("Detailed message of the addon error")
                          })
                          .nullable()
                          .describe(
                            "`null` if `success` is `true`. Contains the error details of the failed model"
                          ),
                        results: zod
                          .array(zod.string())
                          .nullable()
                          .describe("If `sentences` has been enabled, transcription as sentences.")
                      })
                    )
                    .optional()
                    .describe("If `sentences` has been enabled, sentences results"),
                  subtitles: zod
                    .array(
                      zod.object({
                        format: zod
                          .enum(["srt", "vtt"])
                          .describe(
                            "Subtitles formats you want your transcription to be formatted to"
                          )
                          .describe("Format of the current subtitle"),
                        subtitles: zod
                          .string()
                          .describe("Transcription on the asked subtitle format")
                      })
                    )
                    .optional()
                    .describe("If `subtitles` has been enabled, subtitles results"),
                  utterances: zod
                    .array(
                      zod.object({
                        start: zod
                          .number()
                          .describe("Start timestamp in seconds of this utterance"),
                        end: zod.number().describe("End timestamp in seconds of this utterance"),
                        confidence: zod
                          .number()
                          .describe("Confidence on the transcribed utterance (1 = 100% confident)"),
                        channel: zod
                          .number()
                          .min(
                            historyControllerGetListV1ResponseItemsItemResultTranscriptionUtterancesItemChannelMin
                          )
                          .describe(
                            "Audio channel of where this utterance has been transcribed from"
                          ),
                        speaker: zod
                          .number()
                          .min(
                            historyControllerGetListV1ResponseItemsItemResultTranscriptionUtterancesItemSpeakerMin
                          )
                          .optional()
                          .describe("If `diarization` enabled, speaker identification number"),
                        words: zod
                          .array(
                            zod.object({
                              word: zod.string().describe("Spoken word"),
                              start: zod
                                .number()
                                .describe("Start timestamps in seconds of the spoken word"),
                              end: zod
                                .number()
                                .describe("End timestamps in seconds of the spoken word"),
                              confidence: zod
                                .number()
                                .describe("Confidence on the transcribed word (1 = 100% confident)")
                            })
                          )
                          .describe("List of words of the utterance, split by timestamp"),
                        text: zod.string().describe("Transcription for this utterance"),
                        language: zod
                          .enum([
                            "af",
                            "am",
                            "ar",
                            "as",
                            "az",
                            "ba",
                            "be",
                            "bg",
                            "bn",
                            "bo",
                            "br",
                            "bs",
                            "ca",
                            "cs",
                            "cy",
                            "da",
                            "de",
                            "el",
                            "en",
                            "es",
                            "et",
                            "eu",
                            "fa",
                            "fi",
                            "fo",
                            "fr",
                            "gl",
                            "gu",
                            "ha",
                            "haw",
                            "he",
                            "hi",
                            "hr",
                            "ht",
                            "hu",
                            "hy",
                            "id",
                            "is",
                            "it",
                            "ja",
                            "jw",
                            "ka",
                            "kk",
                            "km",
                            "kn",
                            "ko",
                            "la",
                            "lb",
                            "ln",
                            "lo",
                            "lt",
                            "lv",
                            "mg",
                            "mi",
                            "mk",
                            "ml",
                            "mn",
                            "mr",
                            "ms",
                            "mt",
                            "my",
                            "ne",
                            "nl",
                            "nn",
                            "no",
                            "oc",
                            "pa",
                            "pl",
                            "ps",
                            "pt",
                            "ro",
                            "ru",
                            "sa",
                            "sd",
                            "si",
                            "sk",
                            "sl",
                            "sn",
                            "so",
                            "sq",
                            "sr",
                            "su",
                            "sv",
                            "sw",
                            "ta",
                            "te",
                            "tg",
                            "th",
                            "tk",
                            "tl",
                            "tr",
                            "tt",
                            "uk",
                            "ur",
                            "uz",
                            "vi",
                            "yi",
                            "yo",
                            "zh"
                          ])
                          .describe(
                            "Specify the language in which it will be pronounced when sound comparison occurs. Default to transcription language."
                          )
                          .describe("Spoken language in this utterance")
                      })
                    )
                    .describe("Transcribed speech utterances present in the audio")
                })
                .optional()
                .describe("Transcription of the audio speech"),
              translation: zod
                .object({
                  success: zod
                    .boolean()
                    .describe("The audio intelligence model succeeded to get a valid output"),
                  is_empty: zod
                    .boolean()
                    .describe("The audio intelligence model returned an empty value"),
                  exec_time: zod
                    .number()
                    .describe("Time audio intelligence model took to complete the task"),
                  error: zod
                    .object({
                      status_code: zod.number().describe("Status code of the addon error"),
                      exception: zod.string().describe("Reason of the addon error"),
                      message: zod.string().describe("Detailed message of the addon error")
                    })
                    .nullable()
                    .describe(
                      "`null` if `success` is `true`. Contains the error details of the failed model"
                    ),
                  results: zod
                    .array(
                      zod.object({
                        error: zod
                          .object({
                            status_code: zod.number().describe("Status code of the addon error"),
                            exception: zod.string().describe("Reason of the addon error"),
                            message: zod.string().describe("Detailed message of the addon error")
                          })
                          .nullable()
                          .describe("Contains the error details of the failed addon"),
                        full_transcript: zod
                          .string()
                          .describe(
                            "All transcription on text format without any other information"
                          ),
                        languages: zod
                          .array(
                            zod
                              .enum([
                                "af",
                                "am",
                                "ar",
                                "as",
                                "az",
                                "ba",
                                "be",
                                "bg",
                                "bn",
                                "bo",
                                "br",
                                "bs",
                                "ca",
                                "cs",
                                "cy",
                                "da",
                                "de",
                                "el",
                                "en",
                                "es",
                                "et",
                                "eu",
                                "fa",
                                "fi",
                                "fo",
                                "fr",
                                "gl",
                                "gu",
                                "ha",
                                "haw",
                                "he",
                                "hi",
                                "hr",
                                "ht",
                                "hu",
                                "hy",
                                "id",
                                "is",
                                "it",
                                "ja",
                                "jw",
                                "ka",
                                "kk",
                                "km",
                                "kn",
                                "ko",
                                "la",
                                "lb",
                                "ln",
                                "lo",
                                "lt",
                                "lv",
                                "mg",
                                "mi",
                                "mk",
                                "ml",
                                "mn",
                                "mr",
                                "ms",
                                "mt",
                                "my",
                                "ne",
                                "nl",
                                "nn",
                                "no",
                                "oc",
                                "pa",
                                "pl",
                                "ps",
                                "pt",
                                "ro",
                                "ru",
                                "sa",
                                "sd",
                                "si",
                                "sk",
                                "sl",
                                "sn",
                                "so",
                                "sq",
                                "sr",
                                "su",
                                "sv",
                                "sw",
                                "ta",
                                "te",
                                "tg",
                                "th",
                                "tk",
                                "tl",
                                "tr",
                                "tt",
                                "uk",
                                "ur",
                                "uz",
                                "vi",
                                "wo",
                                "yi",
                                "yo",
                                "zh"
                              ])
                              .describe(
                                "Target language in `iso639-1` format you want the transcription translated to"
                              )
                          )
                          .describe(
                            "All the detected languages in the audio sorted from the most detected to the less detected"
                          ),
                        sentences: zod
                          .array(
                            zod.object({
                              success: zod
                                .boolean()
                                .describe(
                                  "The audio intelligence model succeeded to get a valid output"
                                ),
                              is_empty: zod
                                .boolean()
                                .describe("The audio intelligence model returned an empty value"),
                              exec_time: zod
                                .number()
                                .describe(
                                  "Time audio intelligence model took to complete the task"
                                ),
                              error: zod
                                .object({
                                  status_code: zod
                                    .number()
                                    .describe("Status code of the addon error"),
                                  exception: zod.string().describe("Reason of the addon error"),
                                  message: zod
                                    .string()
                                    .describe("Detailed message of the addon error")
                                })
                                .nullable()
                                .describe(
                                  "`null` if `success` is `true`. Contains the error details of the failed model"
                                ),
                              results: zod
                                .array(zod.string())
                                .nullable()
                                .describe(
                                  "If `sentences` has been enabled, transcription as sentences."
                                )
                            })
                          )
                          .optional()
                          .describe(
                            "If `sentences` has been enabled, sentences results for this translation"
                          ),
                        subtitles: zod
                          .array(
                            zod.object({
                              format: zod
                                .enum(["srt", "vtt"])
                                .describe(
                                  "Subtitles formats you want your transcription to be formatted to"
                                )
                                .describe("Format of the current subtitle"),
                              subtitles: zod
                                .string()
                                .describe("Transcription on the asked subtitle format")
                            })
                          )
                          .optional()
                          .describe(
                            "If `subtitles` has been enabled, subtitles results for this translation"
                          ),
                        utterances: zod
                          .array(
                            zod.object({
                              start: zod
                                .number()
                                .describe("Start timestamp in seconds of this utterance"),
                              end: zod
                                .number()
                                .describe("End timestamp in seconds of this utterance"),
                              confidence: zod
                                .number()
                                .describe(
                                  "Confidence on the transcribed utterance (1 = 100% confident)"
                                ),
                              channel: zod
                                .number()
                                .min(
                                  historyControllerGetListV1ResponseItemsItemResultTranslationResultsItemUtterancesItemChannelMin
                                )
                                .describe(
                                  "Audio channel of where this utterance has been transcribed from"
                                ),
                              speaker: zod
                                .number()
                                .min(
                                  historyControllerGetListV1ResponseItemsItemResultTranslationResultsItemUtterancesItemSpeakerMin
                                )
                                .optional()
                                .describe(
                                  "If `diarization` enabled, speaker identification number"
                                ),
                              words: zod
                                .array(
                                  zod.object({
                                    word: zod.string().describe("Spoken word"),
                                    start: zod
                                      .number()
                                      .describe("Start timestamps in seconds of the spoken word"),
                                    end: zod
                                      .number()
                                      .describe("End timestamps in seconds of the spoken word"),
                                    confidence: zod
                                      .number()
                                      .describe(
                                        "Confidence on the transcribed word (1 = 100% confident)"
                                      )
                                  })
                                )
                                .describe("List of words of the utterance, split by timestamp"),
                              text: zod.string().describe("Transcription for this utterance"),
                              language: zod
                                .enum([
                                  "af",
                                  "am",
                                  "ar",
                                  "as",
                                  "az",
                                  "ba",
                                  "be",
                                  "bg",
                                  "bn",
                                  "bo",
                                  "br",
                                  "bs",
                                  "ca",
                                  "cs",
                                  "cy",
                                  "da",
                                  "de",
                                  "el",
                                  "en",
                                  "es",
                                  "et",
                                  "eu",
                                  "fa",
                                  "fi",
                                  "fo",
                                  "fr",
                                  "gl",
                                  "gu",
                                  "ha",
                                  "haw",
                                  "he",
                                  "hi",
                                  "hr",
                                  "ht",
                                  "hu",
                                  "hy",
                                  "id",
                                  "is",
                                  "it",
                                  "ja",
                                  "jw",
                                  "ka",
                                  "kk",
                                  "km",
                                  "kn",
                                  "ko",
                                  "la",
                                  "lb",
                                  "ln",
                                  "lo",
                                  "lt",
                                  "lv",
                                  "mg",
                                  "mi",
                                  "mk",
                                  "ml",
                                  "mn",
                                  "mr",
                                  "ms",
                                  "mt",
                                  "my",
                                  "ne",
                                  "nl",
                                  "nn",
                                  "no",
                                  "oc",
                                  "pa",
                                  "pl",
                                  "ps",
                                  "pt",
                                  "ro",
                                  "ru",
                                  "sa",
                                  "sd",
                                  "si",
                                  "sk",
                                  "sl",
                                  "sn",
                                  "so",
                                  "sq",
                                  "sr",
                                  "su",
                                  "sv",
                                  "sw",
                                  "ta",
                                  "te",
                                  "tg",
                                  "th",
                                  "tk",
                                  "tl",
                                  "tr",
                                  "tt",
                                  "uk",
                                  "ur",
                                  "uz",
                                  "vi",
                                  "yi",
                                  "yo",
                                  "zh"
                                ])
                                .describe(
                                  "Specify the language in which it will be pronounced when sound comparison occurs. Default to transcription language."
                                )
                                .describe("Spoken language in this utterance")
                            })
                          )
                          .describe("Transcribed speech utterances present in the audio")
                      })
                    )
                    .nullable()
                    .describe("List of translated transcriptions, one for each `target_languages`")
                })
                .optional()
                .describe(
                  "If `translation` has been enabled, translation of the audio speech transcription"
                ),
              summarization: zod
                .object({
                  success: zod
                    .boolean()
                    .describe("The audio intelligence model succeeded to get a valid output"),
                  is_empty: zod
                    .boolean()
                    .describe("The audio intelligence model returned an empty value"),
                  exec_time: zod
                    .number()
                    .describe("Time audio intelligence model took to complete the task"),
                  error: zod
                    .object({
                      status_code: zod.number().describe("Status code of the addon error"),
                      exception: zod.string().describe("Reason of the addon error"),
                      message: zod.string().describe("Detailed message of the addon error")
                    })
                    .nullable()
                    .describe(
                      "`null` if `success` is `true`. Contains the error details of the failed model"
                    ),
                  results: zod
                    .string()
                    .nullable()
                    .describe("If `summarization` has been enabled, summary of the transcription")
                })
                .optional()
                .describe(
                  "If `summarization` has been enabled, summarization of the audio speech transcription"
                ),
              moderation: zod
                .object({
                  success: zod
                    .boolean()
                    .describe("The audio intelligence model succeeded to get a valid output"),
                  is_empty: zod
                    .boolean()
                    .describe("The audio intelligence model returned an empty value"),
                  exec_time: zod
                    .number()
                    .describe("Time audio intelligence model took to complete the task"),
                  error: zod
                    .object({
                      status_code: zod.number().describe("Status code of the addon error"),
                      exception: zod.string().describe("Reason of the addon error"),
                      message: zod.string().describe("Detailed message of the addon error")
                    })
                    .nullable()
                    .describe(
                      "`null` if `success` is `true`. Contains the error details of the failed model"
                    ),
                  results: zod
                    .string()
                    .nullable()
                    .describe("If `moderation` has been enabled, moderated transcription")
                })
                .optional()
                .describe(
                  "If `moderation` has been enabled, moderation of the audio speech transcription"
                ),
              named_entity_recognition: zod
                .object({
                  success: zod
                    .boolean()
                    .describe("The audio intelligence model succeeded to get a valid output"),
                  is_empty: zod
                    .boolean()
                    .describe("The audio intelligence model returned an empty value"),
                  exec_time: zod
                    .number()
                    .describe("Time audio intelligence model took to complete the task"),
                  error: zod
                    .object({
                      status_code: zod.number().describe("Status code of the addon error"),
                      exception: zod.string().describe("Reason of the addon error"),
                      message: zod.string().describe("Detailed message of the addon error")
                    })
                    .nullable()
                    .describe(
                      "`null` if `success` is `true`. Contains the error details of the failed model"
                    ),
                  entity: zod
                    .string()
                    .describe(
                      "If `named_entity_recognition` has been enabled, the detected entities."
                    )
                })
                .optional()
                .describe("If `named_entity_recognition` has been enabled, the detected entities"),
              name_consistency: zod
                .object({
                  success: zod
                    .boolean()
                    .describe("The audio intelligence model succeeded to get a valid output"),
                  is_empty: zod
                    .boolean()
                    .describe("The audio intelligence model returned an empty value"),
                  exec_time: zod
                    .number()
                    .describe("Time audio intelligence model took to complete the task"),
                  error: zod
                    .object({
                      status_code: zod.number().describe("Status code of the addon error"),
                      exception: zod.string().describe("Reason of the addon error"),
                      message: zod.string().describe("Detailed message of the addon error")
                    })
                    .nullable()
                    .describe(
                      "`null` if `success` is `true`. Contains the error details of the failed model"
                    ),
                  results: zod
                    .string()
                    .describe(
                      "If `name_consistency` has been enabled, Gladia will improve the consistency of the names across the transcription"
                    )
                })
                .optional()
                .describe(
                  "If `name_consistency` has been enabled, Gladia will improve consistency of the names accross the transcription"
                ),
              speaker_reidentification: zod
                .object({
                  success: zod
                    .boolean()
                    .describe("The audio intelligence model succeeded to get a valid output"),
                  is_empty: zod
                    .boolean()
                    .describe("The audio intelligence model returned an empty value"),
                  exec_time: zod
                    .number()
                    .describe("Time audio intelligence model took to complete the task"),
                  error: zod
                    .object({
                      status_code: zod.number().describe("Status code of the addon error"),
                      exception: zod.string().describe("Reason of the addon error"),
                      message: zod.string().describe("Detailed message of the addon error")
                    })
                    .nullable()
                    .describe(
                      "`null` if `success` is `true`. Contains the error details of the failed model"
                    ),
                  results: zod
                    .string()
                    .describe(
                      "If `speaker_reidentification` has been enabled, results of the AI speaker reidentification."
                    )
                })
                .optional()
                .describe(
                  "If `speaker_reidentification` has been enabled, results of the AI speaker reidentification."
                ),
              structured_data_extraction: zod
                .object({
                  success: zod
                    .boolean()
                    .describe("The audio intelligence model succeeded to get a valid output"),
                  is_empty: zod
                    .boolean()
                    .describe("The audio intelligence model returned an empty value"),
                  exec_time: zod
                    .number()
                    .describe("Time audio intelligence model took to complete the task"),
                  error: zod
                    .object({
                      status_code: zod.number().describe("Status code of the addon error"),
                      exception: zod.string().describe("Reason of the addon error"),
                      message: zod.string().describe("Detailed message of the addon error")
                    })
                    .nullable()
                    .describe(
                      "`null` if `success` is `true`. Contains the error details of the failed model"
                    ),
                  results: zod
                    .string()
                    .describe(
                      "If `structured_data_extraction` has been enabled, results of the AI structured data extraction for the defined classes."
                    )
                })
                .optional()
                .describe(
                  "If `structured_data_extraction` has been enabled, structured data extraction results"
                ),
              sentiment_analysis: zod
                .object({
                  success: zod
                    .boolean()
                    .describe("The audio intelligence model succeeded to get a valid output"),
                  is_empty: zod
                    .boolean()
                    .describe("The audio intelligence model returned an empty value"),
                  exec_time: zod
                    .number()
                    .describe("Time audio intelligence model took to complete the task"),
                  error: zod
                    .object({
                      status_code: zod.number().describe("Status code of the addon error"),
                      exception: zod.string().describe("Reason of the addon error"),
                      message: zod.string().describe("Detailed message of the addon error")
                    })
                    .nullable()
                    .describe(
                      "`null` if `success` is `true`. Contains the error details of the failed model"
                    ),
                  results: zod
                    .string()
                    .describe(
                      "If `sentiment_analysis` has been enabled, Gladia will analyze the sentiments and emotions of the audio"
                    )
                })
                .optional()
                .describe(
                  "If `sentiment_analysis` has been enabled, sentiment analysis of the audio speech transcription"
                ),
              audio_to_llm: zod
                .object({
                  success: zod
                    .boolean()
                    .describe("The audio intelligence model succeeded to get a valid output"),
                  is_empty: zod
                    .boolean()
                    .describe("The audio intelligence model returned an empty value"),
                  exec_time: zod
                    .number()
                    .describe("Time audio intelligence model took to complete the task"),
                  error: zod
                    .object({
                      status_code: zod.number().describe("Status code of the addon error"),
                      exception: zod.string().describe("Reason of the addon error"),
                      message: zod.string().describe("Detailed message of the addon error")
                    })
                    .nullable()
                    .describe(
                      "`null` if `success` is `true`. Contains the error details of the failed model"
                    ),
                  results: zod
                    .array(
                      zod.object({
                        success: zod
                          .boolean()
                          .describe("The audio intelligence model succeeded to get a valid output"),
                        is_empty: zod
                          .boolean()
                          .describe("The audio intelligence model returned an empty value"),
                        exec_time: zod
                          .number()
                          .describe("Time audio intelligence model took to complete the task"),
                        error: zod
                          .object({
                            status_code: zod.number().describe("Status code of the addon error"),
                            exception: zod.string().describe("Reason of the addon error"),
                            message: zod.string().describe("Detailed message of the addon error")
                          })
                          .nullable()
                          .describe(
                            "`null` if `success` is `true`. Contains the error details of the failed model"
                          ),
                        results: zod
                          .object({
                            prompt: zod.string().nullable().describe("The prompt used"),
                            response: zod
                              .string()
                              .nullable()
                              .describe("The result of the AI analysis")
                          })
                          .nullable()
                          .describe("The result from a specific prompt")
                      })
                    )
                    .nullable()
                    .describe(
                      "If `audio_to_llm` has been enabled, results of the AI custom analysis"
                    )
                })
                .optional()
                .describe(
                  "If `audio_to_llm` has been enabled, audio to llm results of the audio speech transcription"
                ),
              sentences: zod
                .object({
                  success: zod
                    .boolean()
                    .describe("The audio intelligence model succeeded to get a valid output"),
                  is_empty: zod
                    .boolean()
                    .describe("The audio intelligence model returned an empty value"),
                  exec_time: zod
                    .number()
                    .describe("Time audio intelligence model took to complete the task"),
                  error: zod
                    .object({
                      status_code: zod.number().describe("Status code of the addon error"),
                      exception: zod.string().describe("Reason of the addon error"),
                      message: zod.string().describe("Detailed message of the addon error")
                    })
                    .nullable()
                    .describe(
                      "`null` if `success` is `true`. Contains the error details of the failed model"
                    ),
                  results: zod
                    .array(zod.string())
                    .nullable()
                    .describe("If `sentences` has been enabled, transcription as sentences.")
                })
                .optional()
                .describe(
                  "If `sentences` has been enabled, sentences of the audio speech transcription. Deprecated: content will move to the `transcription` object."
                ),
              display_mode: zod
                .object({
                  success: zod
                    .boolean()
                    .describe("The audio intelligence model succeeded to get a valid output"),
                  is_empty: zod
                    .boolean()
                    .describe("The audio intelligence model returned an empty value"),
                  exec_time: zod
                    .number()
                    .describe("Time audio intelligence model took to complete the task"),
                  error: zod
                    .object({
                      status_code: zod.number().describe("Status code of the addon error"),
                      exception: zod.string().describe("Reason of the addon error"),
                      message: zod.string().describe("Detailed message of the addon error")
                    })
                    .nullable()
                    .describe(
                      "`null` if `success` is `true`. Contains the error details of the failed model"
                    ),
                  results: zod
                    .array(zod.string())
                    .nullable()
                    .describe(
                      "If `display_mode` has been enabled, proposes an alternative display output."
                    )
                })
                .optional()
                .describe(
                  "If `display_mode` has been enabled, the output will be reordered, creating new utterances when speakers overlapped"
                ),
              chapterization: zod
                .object({
                  success: zod
                    .boolean()
                    .describe("The audio intelligence model succeeded to get a valid output"),
                  is_empty: zod
                    .boolean()
                    .describe("The audio intelligence model returned an empty value"),
                  exec_time: zod
                    .number()
                    .describe("Time audio intelligence model took to complete the task"),
                  error: zod
                    .object({
                      status_code: zod.number().describe("Status code of the addon error"),
                      exception: zod.string().describe("Reason of the addon error"),
                      message: zod.string().describe("Detailed message of the addon error")
                    })
                    .nullable()
                    .describe(
                      "`null` if `success` is `true`. Contains the error details of the failed model"
                    ),
                  results: zod
                    .record(zod.string(), zod.any())
                    .describe(
                      "If `chapterization` has been enabled, will generate chapters name for different parts of the given audio."
                    )
                })
                .optional()
                .describe(
                  "If `chapterization` has been enabled, will generate chapters name for different parts of the given audio."
                ),
              diarization: zod
                .object({
                  success: zod
                    .boolean()
                    .describe("The audio intelligence model succeeded to get a valid output"),
                  is_empty: zod
                    .boolean()
                    .describe("The audio intelligence model returned an empty value"),
                  exec_time: zod
                    .number()
                    .describe("Time audio intelligence model took to complete the task"),
                  error: zod
                    .object({
                      status_code: zod.number().describe("Status code of the addon error"),
                      exception: zod.string().describe("Reason of the addon error"),
                      message: zod.string().describe("Detailed message of the addon error")
                    })
                    .nullable()
                    .describe(
                      "`null` if `success` is `true`. Contains the error details of the failed model"
                    ),
                  results: zod
                    .array(
                      zod.object({
                        start: zod
                          .number()
                          .describe("Start timestamp in seconds of this utterance"),
                        end: zod.number().describe("End timestamp in seconds of this utterance"),
                        confidence: zod
                          .number()
                          .describe("Confidence on the transcribed utterance (1 = 100% confident)"),
                        channel: zod
                          .number()
                          .min(
                            historyControllerGetListV1ResponseItemsItemResultDiarizationResultsItemChannelMin
                          )
                          .describe(
                            "Audio channel of where this utterance has been transcribed from"
                          ),
                        speaker: zod
                          .number()
                          .min(
                            historyControllerGetListV1ResponseItemsItemResultDiarizationResultsItemSpeakerMin
                          )
                          .optional()
                          .describe("If `diarization` enabled, speaker identification number"),
                        words: zod
                          .array(
                            zod.object({
                              word: zod.string().describe("Spoken word"),
                              start: zod
                                .number()
                                .describe("Start timestamps in seconds of the spoken word"),
                              end: zod
                                .number()
                                .describe("End timestamps in seconds of the spoken word"),
                              confidence: zod
                                .number()
                                .describe("Confidence on the transcribed word (1 = 100% confident)")
                            })
                          )
                          .describe("List of words of the utterance, split by timestamp"),
                        text: zod.string().describe("Transcription for this utterance"),
                        language: zod
                          .enum([
                            "af",
                            "am",
                            "ar",
                            "as",
                            "az",
                            "ba",
                            "be",
                            "bg",
                            "bn",
                            "bo",
                            "br",
                            "bs",
                            "ca",
                            "cs",
                            "cy",
                            "da",
                            "de",
                            "el",
                            "en",
                            "es",
                            "et",
                            "eu",
                            "fa",
                            "fi",
                            "fo",
                            "fr",
                            "gl",
                            "gu",
                            "ha",
                            "haw",
                            "he",
                            "hi",
                            "hr",
                            "ht",
                            "hu",
                            "hy",
                            "id",
                            "is",
                            "it",
                            "ja",
                            "jw",
                            "ka",
                            "kk",
                            "km",
                            "kn",
                            "ko",
                            "la",
                            "lb",
                            "ln",
                            "lo",
                            "lt",
                            "lv",
                            "mg",
                            "mi",
                            "mk",
                            "ml",
                            "mn",
                            "mr",
                            "ms",
                            "mt",
                            "my",
                            "ne",
                            "nl",
                            "nn",
                            "no",
                            "oc",
                            "pa",
                            "pl",
                            "ps",
                            "pt",
                            "ro",
                            "ru",
                            "sa",
                            "sd",
                            "si",
                            "sk",
                            "sl",
                            "sn",
                            "so",
                            "sq",
                            "sr",
                            "su",
                            "sv",
                            "sw",
                            "ta",
                            "te",
                            "tg",
                            "th",
                            "tk",
                            "tl",
                            "tr",
                            "tt",
                            "uk",
                            "ur",
                            "uz",
                            "vi",
                            "yi",
                            "yo",
                            "zh"
                          ])
                          .describe(
                            "Specify the language in which it will be pronounced when sound comparison occurs. Default to transcription language."
                          )
                          .describe("Spoken language in this utterance")
                      })
                    )
                    .describe(
                      "[Deprecated] If `diarization` has been enabled, the diarization result will appear here"
                    )
                })
                .optional()
                .describe(
                  "If `diarization` has been requested and an error has occurred, the result will appear here"
                )
            })
            .nullish()
            .describe('Pre-recorded transcription\'s result when status is \"done\"')
        })
        .or(
          zod.object({
            id: zod.string().uuid().describe("Id of the job"),
            request_id: zod.string().describe("Debug id"),
            version: zod.number().describe("API version"),
            status: zod
              .enum(["queued", "processing", "done", "error"])
              .describe(
                '\"queued\": the job has been queued. \"processing\": the job is being processed. \"done\": the job has been processed and the result is available. \"error\": an error occurred during the job\'s processing.'
              ),
            created_at: zod.string().datetime({}).describe("Creation date"),
            completed_at: zod
              .string()
              .datetime({})
              .nullish()
              .describe('Completion date when status is \"done\" or \"error\"'),
            custom_metadata: zod
              .record(zod.string(), zod.any())
              .optional()
              .describe("Custom metadata given in the initial request"),
            error_code: zod
              .number()
              .min(historyControllerGetListV1ResponseItemsItemErrorCodeMinOne)
              .max(historyControllerGetListV1ResponseItemsItemErrorCodeMaxOne)
              .nullish()
              .describe('HTTP status code of the error if status is \"error\"'),
            post_session_metadata: zod
              .object({})
              .describe("For debugging purposes, send data that could help to identify issues"),
            kind: zod.enum(["live"]),
            file: zod
              .object({
                id: zod.string().describe("The file id"),
                filename: zod.string().nullable().describe("The name of the uploaded file"),
                source: zod
                  .string()
                  .nullable()
                  .describe("The link used to download the file if audio_url was used"),
                audio_duration: zod.number().nullable().describe("Duration of the audio file"),
                number_of_channels: zod
                  .number()
                  .min(1)
                  .nullable()
                  .describe("Number of channels in the audio file")
              })
              .nullish()
              .describe('The file data you uploaded. Can be null if status is \"error\"'),
            request_params: zod
              .object({
                encoding: zod
                  .enum(["wav/pcm", "wav/alaw", "wav/ulaw"])
                  .describe(
                    "The encoding format of the audio stream. Supported formats: \n- PCM: 8, 16, 24, and 32 bits \n- A-law: 8 bits \n- Œº-law: 8 bits \n\nNote: No need to add WAV headers to raw audio as the API supports both formats."
                  )
                  .default(historyControllerGetListV1ResponseItemsItemRequestParamsEncodingDefault)
                  .describe(
                    "The encoding format of the audio stream. Supported formats: \n- PCM: 8, 16, 24, and 32 bits \n- A-law: 8 bits \n- Œº-law: 8 bits \n\nNote: No need to add WAV headers to raw audio as the API supports both formats."
                  ),
                bit_depth: zod
                  .literal(8)
                  .or(zod.literal(16))
                  .or(zod.literal(24))
                  .or(zod.literal(32))
                  .describe("The bit depth of the audio stream")
                  .default(historyControllerGetListV1ResponseItemsItemRequestParamsBitDepthDefault)
                  .describe("The bit depth of the audio stream"),
                sample_rate: zod
                  .literal(8000)
                  .or(zod.literal(16000))
                  .or(zod.literal(32000))
                  .or(zod.literal(44100))
                  .or(zod.literal(48000))
                  .describe("The sample rate of the audio stream")
                  .default(
                    historyControllerGetListV1ResponseItemsItemRequestParamsSampleRateDefault
                  )
                  .describe("The sample rate of the audio stream"),
                channels: zod
                  .number()
                  .min(1)
                  .max(historyControllerGetListV1ResponseItemsItemRequestParamsChannelsMax)
                  .default(historyControllerGetListV1ResponseItemsItemRequestParamsChannelsDefault)
                  .describe("The number of channels of the audio stream"),
                model: zod
                  .enum(["solaria-1"])
                  .describe(
                    'The model used to process the audio. \"solaria-1\" is used by default.'
                  )
                  .default(historyControllerGetListV1ResponseItemsItemRequestParamsModelDefault)
                  .describe(
                    'The model used to process the audio. \"solaria-1\" is used by default.'
                  ),
                endpointing: zod
                  .number()
                  .min(historyControllerGetListV1ResponseItemsItemRequestParamsEndpointingMin)
                  .max(historyControllerGetListV1ResponseItemsItemRequestParamsEndpointingMax)
                  .default(
                    historyControllerGetListV1ResponseItemsItemRequestParamsEndpointingDefault
                  )
                  .describe(
                    "The endpointing duration in seconds. Endpointing is the duration of silence which will cause an utterance to be considered as finished"
                  ),
                maximum_duration_without_endpointing: zod
                  .number()
                  .min(
                    historyControllerGetListV1ResponseItemsItemRequestParamsMaximumDurationWithoutEndpointingMin
                  )
                  .max(
                    historyControllerGetListV1ResponseItemsItemRequestParamsMaximumDurationWithoutEndpointingMax
                  )
                  .default(
                    historyControllerGetListV1ResponseItemsItemRequestParamsMaximumDurationWithoutEndpointingDefault
                  )
                  .describe(
                    "The maximum duration in seconds without endpointing. If endpointing is not detected after this duration, current utterance will be considered as finished"
                  ),
                language_config: zod
                  .object({
                    languages: zod
                      .array(
                        zod
                          .enum([
                            "af",
                            "am",
                            "ar",
                            "as",
                            "az",
                            "ba",
                            "be",
                            "bg",
                            "bn",
                            "bo",
                            "br",
                            "bs",
                            "ca",
                            "cs",
                            "cy",
                            "da",
                            "de",
                            "el",
                            "en",
                            "es",
                            "et",
                            "eu",
                            "fa",
                            "fi",
                            "fo",
                            "fr",
                            "gl",
                            "gu",
                            "ha",
                            "haw",
                            "he",
                            "hi",
                            "hr",
                            "ht",
                            "hu",
                            "hy",
                            "id",
                            "is",
                            "it",
                            "ja",
                            "jw",
                            "ka",
                            "kk",
                            "km",
                            "kn",
                            "ko",
                            "la",
                            "lb",
                            "ln",
                            "lo",
                            "lt",
                            "lv",
                            "mg",
                            "mi",
                            "mk",
                            "ml",
                            "mn",
                            "mr",
                            "ms",
                            "mt",
                            "my",
                            "ne",
                            "nl",
                            "nn",
                            "no",
                            "oc",
                            "pa",
                            "pl",
                            "ps",
                            "pt",
                            "ro",
                            "ru",
                            "sa",
                            "sd",
                            "si",
                            "sk",
                            "sl",
                            "sn",
                            "so",
                            "sq",
                            "sr",
                            "su",
                            "sv",
                            "sw",
                            "ta",
                            "te",
                            "tg",
                            "th",
                            "tk",
                            "tl",
                            "tr",
                            "tt",
                            "uk",
                            "ur",
                            "uz",
                            "vi",
                            "yi",
                            "yo",
                            "zh"
                          ])
                          .describe(
                            "Specify the language in which it will be pronounced when sound comparison occurs. Default to transcription language."
                          )
                      )
                      .default(
                        historyControllerGetListV1ResponseItemsItemRequestParamsLanguageConfigLanguagesDefaultOne
                      )
                      .describe(
                        "If one language is set, it will be used for the transcription. Otherwise, language will be auto-detected by the model."
                      ),
                    code_switching: zod
                      .boolean()
                      .optional()
                      .describe(
                        "If true, language will be auto-detected on each utterance. Otherwise, language will be auto-detected on first utterance and then used for the rest of the transcription. If one language is set, this option will be ignored."
                      )
                  })
                  .optional()
                  .describe("Specify the language configuration"),
                pre_processing: zod
                  .object({
                    audio_enhancer: zod
                      .boolean()
                      .optional()
                      .describe(
                        "If true, apply pre-processing to the audio stream to enhance the quality."
                      ),
                    speech_threshold: zod
                      .number()
                      .min(
                        historyControllerGetListV1ResponseItemsItemRequestParamsPreProcessingSpeechThresholdMin
                      )
                      .max(
                        historyControllerGetListV1ResponseItemsItemRequestParamsPreProcessingSpeechThresholdMax
                      )
                      .default(
                        historyControllerGetListV1ResponseItemsItemRequestParamsPreProcessingSpeechThresholdDefault
                      )
                      .describe(
                        "Sensitivity configuration for Speech Threshold. A value close to 1 will apply stricter thresholds, making it less likely to detect background sounds as speech."
                      )
                  })
                  .optional()
                  .describe("Specify the pre-processing configuration"),
                realtime_processing: zod
                  .object({
                    custom_vocabulary: zod
                      .boolean()
                      .optional()
                      .describe("If true, enable custom vocabulary for the transcription."),
                    custom_vocabulary_config: zod
                      .object({
                        vocabulary: zod
                          .array(
                            zod
                              .object({
                                value: zod
                                  .string()
                                  .describe("The text used to replace in the transcription."),
                                intensity: zod
                                  .number()
                                  .min(
                                    historyControllerGetListV1ResponseItemsItemRequestParamsRealtimeProcessingCustomVocabularyConfigVocabularyItemIntensityMin
                                  )
                                  .max(
                                    historyControllerGetListV1ResponseItemsItemRequestParamsRealtimeProcessingCustomVocabularyConfigVocabularyItemIntensityMax
                                  )
                                  .optional()
                                  .describe("The global intensity of the feature."),
                                pronunciations: zod
                                  .array(zod.string())
                                  .optional()
                                  .describe("The pronunciations used in the transcription."),
                                language: zod
                                  .enum([
                                    "af",
                                    "am",
                                    "ar",
                                    "as",
                                    "az",
                                    "ba",
                                    "be",
                                    "bg",
                                    "bn",
                                    "bo",
                                    "br",
                                    "bs",
                                    "ca",
                                    "cs",
                                    "cy",
                                    "da",
                                    "de",
                                    "el",
                                    "en",
                                    "es",
                                    "et",
                                    "eu",
                                    "fa",
                                    "fi",
                                    "fo",
                                    "fr",
                                    "gl",
                                    "gu",
                                    "ha",
                                    "haw",
                                    "he",
                                    "hi",
                                    "hr",
                                    "ht",
                                    "hu",
                                    "hy",
                                    "id",
                                    "is",
                                    "it",
                                    "ja",
                                    "jw",
                                    "ka",
                                    "kk",
                                    "km",
                                    "kn",
                                    "ko",
                                    "la",
                                    "lb",
                                    "ln",
                                    "lo",
                                    "lt",
                                    "lv",
                                    "mg",
                                    "mi",
                                    "mk",
                                    "ml",
                                    "mn",
                                    "mr",
                                    "ms",
                                    "mt",
                                    "my",
                                    "ne",
                                    "nl",
                                    "nn",
                                    "no",
                                    "oc",
                                    "pa",
                                    "pl",
                                    "ps",
                                    "pt",
                                    "ro",
                                    "ru",
                                    "sa",
                                    "sd",
                                    "si",
                                    "sk",
                                    "sl",
                                    "sn",
                                    "so",
                                    "sq",
                                    "sr",
                                    "su",
                                    "sv",
                                    "sw",
                                    "ta",
                                    "te",
                                    "tg",
                                    "th",
                                    "tk",
                                    "tl",
                                    "tr",
                                    "tt",
                                    "uk",
                                    "ur",
                                    "uz",
                                    "vi",
                                    "yi",
                                    "yo",
                                    "zh"
                                  ])
                                  .describe(
                                    "Specify the language in which it will be pronounced when sound comparison occurs. Default to transcription language."
                                  )
                                  .optional()
                                  .describe(
                                    "Specify the language in which it will be pronounced when sound comparison occurs. Default to transcription language."
                                  )
                              })
                              .or(zod.string())
                          )
                          .describe(
                            "Specific vocabulary list to feed the transcription model with. Each item can be a string or an object with the following properties: value, intensity, pronunciations, language."
                          ),
                        default_intensity: zod
                          .number()
                          .min(
                            historyControllerGetListV1ResponseItemsItemRequestParamsRealtimeProcessingCustomVocabularyConfigDefaultIntensityMin
                          )
                          .max(
                            historyControllerGetListV1ResponseItemsItemRequestParamsRealtimeProcessingCustomVocabularyConfigDefaultIntensityMax
                          )
                          .optional()
                          .describe("Default intensity for the custom vocabulary")
                      })
                      .optional()
                      .describe(
                        "Custom vocabulary configuration, if `custom_vocabulary` is enabled"
                      ),
                    custom_spelling: zod
                      .boolean()
                      .optional()
                      .describe("If true, enable custom spelling for the transcription."),
                    custom_spelling_config: zod
                      .object({
                        spelling_dictionary: zod
                          .record(zod.string(), zod.array(zod.string()))
                          .describe("The list of spelling applied on the audio transcription")
                      })
                      .optional()
                      .describe("Custom spelling configuration, if `custom_spelling` is enabled"),
                    translation: zod
                      .boolean()
                      .optional()
                      .describe("If true, enable translation for the transcription"),
                    translation_config: zod
                      .object({
                        target_languages: zod
                          .array(
                            zod
                              .enum([
                                "af",
                                "am",
                                "ar",
                                "as",
                                "az",
                                "ba",
                                "be",
                                "bg",
                                "bn",
                                "bo",
                                "br",
                                "bs",
                                "ca",
                                "cs",
                                "cy",
                                "da",
                                "de",
                                "el",
                                "en",
                                "es",
                                "et",
                                "eu",
                                "fa",
                                "fi",
                                "fo",
                                "fr",
                                "gl",
                                "gu",
                                "ha",
                                "haw",
                                "he",
                                "hi",
                                "hr",
                                "ht",
                                "hu",
                                "hy",
                                "id",
                                "is",
                                "it",
                                "ja",
                                "jw",
                                "ka",
                                "kk",
                                "km",
                                "kn",
                                "ko",
                                "la",
                                "lb",
                                "ln",
                                "lo",
                                "lt",
                                "lv",
                                "mg",
                                "mi",
                                "mk",
                                "ml",
                                "mn",
                                "mr",
                                "ms",
                                "mt",
                                "my",
                                "ne",
                                "nl",
                                "nn",
                                "no",
                                "oc",
                                "pa",
                                "pl",
                                "ps",
                                "pt",
                                "ro",
                                "ru",
                                "sa",
                                "sd",
                                "si",
                                "sk",
                                "sl",
                                "sn",
                                "so",
                                "sq",
                                "sr",
                                "su",
                                "sv",
                                "sw",
                                "ta",
                                "te",
                                "tg",
                                "th",
                                "tk",
                                "tl",
                                "tr",
                                "tt",
                                "uk",
                                "ur",
                                "uz",
                                "vi",
                                "wo",
                                "yi",
                                "yo",
                                "zh"
                              ])
                              .describe(
                                "Target language in `iso639-1` format you want the transcription translated to"
                              )
                          )
                          .min(1)
                          .describe(
                            "Target language in `iso639-1` format you want the transcription translated to"
                          ),
                        model: zod
                          .enum(["base", "enhanced"])
                          .describe("Model you want the translation model to use to translate")
                          .default(
                            historyControllerGetListV1ResponseItemsItemRequestParamsRealtimeProcessingTranslationConfigModelDefault
                          )
                          .describe("Model you want the translation model to use to translate"),
                        match_original_utterances: zod
                          .boolean()
                          .default(
                            historyControllerGetListV1ResponseItemsItemRequestParamsRealtimeProcessingTranslationConfigMatchOriginalUtterancesDefault
                          )
                          .describe("Align translated utterances with the original ones"),
                        lipsync: zod
                          .boolean()
                          .default(
                            historyControllerGetListV1ResponseItemsItemRequestParamsRealtimeProcessingTranslationConfigLipsyncDefault
                          )
                          .describe("Whether to apply lipsync to the translated transcription. "),
                        context_adaptation: zod
                          .boolean()
                          .default(
                            historyControllerGetListV1ResponseItemsItemRequestParamsRealtimeProcessingTranslationConfigContextAdaptationDefault
                          )
                          .describe(
                            "Enables or disables context-aware translation features that allow the model to adapt translations based on provided context."
                          ),
                        context: zod
                          .string()
                          .optional()
                          .describe("Context information to improve translation accuracy"),
                        informal: zod
                          .boolean()
                          .optional()
                          .describe(
                            "Forces the translation to use informal language forms when available in the target language."
                          )
                      })
                      .optional()
                      .describe("Translation configuration, if `translation` is enabled"),
                    named_entity_recognition: zod
                      .boolean()
                      .optional()
                      .describe("If true, enable named entity recognition for the transcription."),
                    sentiment_analysis: zod
                      .boolean()
                      .optional()
                      .describe("If true, enable sentiment analysis for the transcription.")
                  })
                  .optional()
                  .describe("Specify the realtime processing configuration"),
                post_processing: zod
                  .object({
                    summarization: zod
                      .boolean()
                      .optional()
                      .describe("If true, generates summarization for the whole transcription."),
                    summarization_config: zod
                      .object({
                        type: zod
                          .enum(["general", "bullet_points", "concise"])
                          .describe("The type of summarization to apply")
                          .default(
                            historyControllerGetListV1ResponseItemsItemRequestParamsPostProcessingSummarizationConfigTypeDefault
                          )
                          .describe("The type of summarization to apply")
                      })
                      .optional()
                      .describe("Summarization configuration, if `summarization` is enabled"),
                    chapterization: zod
                      .boolean()
                      .optional()
                      .describe("If true, generates chapters for the whole transcription.")
                  })
                  .optional()
                  .describe("Specify the post-processing configuration"),
                messages_config: zod
                  .object({
                    receive_partial_transcripts: zod
                      .boolean()
                      .optional()
                      .describe("If true, partial transcript will be sent to websocket."),
                    receive_final_transcripts: zod
                      .boolean()
                      .default(
                        historyControllerGetListV1ResponseItemsItemRequestParamsMessagesConfigReceiveFinalTranscriptsDefault
                      )
                      .describe("If true, final transcript will be sent to websocket."),
                    receive_speech_events: zod
                      .boolean()
                      .default(
                        historyControllerGetListV1ResponseItemsItemRequestParamsMessagesConfigReceiveSpeechEventsDefault
                      )
                      .describe("If true, begin and end speech events will be sent to websocket."),
                    receive_pre_processing_events: zod
                      .boolean()
                      .default(
                        historyControllerGetListV1ResponseItemsItemRequestParamsMessagesConfigReceivePreProcessingEventsDefault
                      )
                      .describe("If true, pre-processing events will be sent to websocket."),
                    receive_realtime_processing_events: zod
                      .boolean()
                      .default(
                        historyControllerGetListV1ResponseItemsItemRequestParamsMessagesConfigReceiveRealtimeProcessingEventsDefault
                      )
                      .describe("If true, realtime processing events will be sent to websocket."),
                    receive_post_processing_events: zod
                      .boolean()
                      .default(
                        historyControllerGetListV1ResponseItemsItemRequestParamsMessagesConfigReceivePostProcessingEventsDefault
                      )
                      .describe("If true, post-processing events will be sent to websocket."),
                    receive_acknowledgments: zod
                      .boolean()
                      .default(
                        historyControllerGetListV1ResponseItemsItemRequestParamsMessagesConfigReceiveAcknowledgmentsDefault
                      )
                      .describe("If true, acknowledgments will be sent to websocket."),
                    receive_errors: zod
                      .boolean()
                      .default(
                        historyControllerGetListV1ResponseItemsItemRequestParamsMessagesConfigReceiveErrorsDefault
                      )
                      .describe("If true, errors will be sent to websocket."),
                    receive_lifecycle_events: zod
                      .boolean()
                      .optional()
                      .describe("If true, lifecycle events will be sent to websocket.")
                  })
                  .optional()
                  .describe("Specify the websocket messages configuration"),
                callback: zod
                  .boolean()
                  .optional()
                  .describe("If true, messages will be sent to configured url."),
                callback_config: zod
                  .object({
                    url: zod
                      .string()
                      .url()
                      .optional()
                      .describe(
                        "URL on which we will do a `POST` request with configured messages"
                      ),
                    receive_partial_transcripts: zod
                      .boolean()
                      .optional()
                      .describe(
                        "If true, partial transcript will be sent to the defined callback."
                      ),
                    receive_final_transcripts: zod
                      .boolean()
                      .default(
                        historyControllerGetListV1ResponseItemsItemRequestParamsCallbackConfigReceiveFinalTranscriptsDefault
                      )
                      .describe("If true, final transcript will be sent to the defined callback."),
                    receive_speech_events: zod
                      .boolean()
                      .optional()
                      .describe(
                        "If true, begin and end speech events will be sent to the defined callback."
                      ),
                    receive_pre_processing_events: zod
                      .boolean()
                      .default(
                        historyControllerGetListV1ResponseItemsItemRequestParamsCallbackConfigReceivePreProcessingEventsDefault
                      )
                      .describe(
                        "If true, pre-processing events will be sent to the defined callback."
                      ),
                    receive_realtime_processing_events: zod
                      .boolean()
                      .default(
                        historyControllerGetListV1ResponseItemsItemRequestParamsCallbackConfigReceiveRealtimeProcessingEventsDefault
                      )
                      .describe(
                        "If true, realtime processing events will be sent to the defined callback."
                      ),
                    receive_post_processing_events: zod
                      .boolean()
                      .default(
                        historyControllerGetListV1ResponseItemsItemRequestParamsCallbackConfigReceivePostProcessingEventsDefault
                      )
                      .describe(
                        "If true, post-processing events will be sent to the defined callback."
                      ),
                    receive_acknowledgments: zod
                      .boolean()
                      .optional()
                      .describe("If true, acknowledgments will be sent to the defined callback."),
                    receive_errors: zod
                      .boolean()
                      .optional()
                      .describe("If true, errors will be sent to the defined callback."),
                    receive_lifecycle_events: zod
                      .boolean()
                      .default(
                        historyControllerGetListV1ResponseItemsItemRequestParamsCallbackConfigReceiveLifecycleEventsDefault
                      )
                      .describe("If true, lifecycle events will be sent to the defined callback.")
                  })
                  .optional()
                  .describe("Specify the callback configuration")
              })
              .nullish()
              .describe(
                'Parameters used for this live transcription. Can be null if status is \"error\"'
              ),
            result: zod
              .object({
                metadata: zod
                  .object({
                    audio_duration: zod.number().describe("Duration of the transcribed audio file"),
                    number_of_distinct_channels: zod
                      .number()
                      .min(1)
                      .describe("Number of distinct channels in the transcribed audio file"),
                    billing_time: zod
                      .number()
                      .describe(
                        "Billed duration in seconds (audio_duration * number_of_distinct_channels)"
                      ),
                    transcription_time: zod
                      .number()
                      .describe("Duration of the transcription in seconds")
                  })
                  .describe("Metadata for the given transcription & audio file"),
                transcription: zod
                  .object({
                    full_transcript: zod
                      .string()
                      .describe("All transcription on text format without any other information"),
                    languages: zod
                      .array(
                        zod
                          .enum([
                            "af",
                            "am",
                            "ar",
                            "as",
                            "az",
                            "ba",
                            "be",
                            "bg",
                            "bn",
                            "bo",
                            "br",
                            "bs",
                            "ca",
                            "cs",
                            "cy",
                            "da",
                            "de",
                            "el",
                            "en",
                            "es",
                            "et",
                            "eu",
                            "fa",
                            "fi",
                            "fo",
                            "fr",
                            "gl",
                            "gu",
                            "ha",
                            "haw",
                            "he",
                            "hi",
                            "hr",
                            "ht",
                            "hu",
                            "hy",
                            "id",
                            "is",
                            "it",
                            "ja",
                            "jw",
                            "ka",
                            "kk",
                            "km",
                            "kn",
                            "ko",
                            "la",
                            "lb",
                            "ln",
                            "lo",
                            "lt",
                            "lv",
                            "mg",
                            "mi",
                            "mk",
                            "ml",
                            "mn",
                            "mr",
                            "ms",
                            "mt",
                            "my",
                            "ne",
                            "nl",
                            "nn",
                            "no",
                            "oc",
                            "pa",
                            "pl",
                            "ps",
                            "pt",
                            "ro",
                            "ru",
                            "sa",
                            "sd",
                            "si",
                            "sk",
                            "sl",
                            "sn",
                            "so",
                            "sq",
                            "sr",
                            "su",
                            "sv",
                            "sw",
                            "ta",
                            "te",
                            "tg",
                            "th",
                            "tk",
                            "tl",
                            "tr",
                            "tt",
                            "uk",
                            "ur",
                            "uz",
                            "vi",
                            "yi",
                            "yo",
                            "zh"
                          ])
                          .describe(
                            "Specify the language in which it will be pronounced when sound comparison occurs. Default to transcription language."
                          )
                      )
                      .describe(
                        "All the detected languages in the audio sorted from the most detected to the less detected"
                      ),
                    sentences: zod
                      .array(
                        zod.object({
                          success: zod
                            .boolean()
                            .describe(
                              "The audio intelligence model succeeded to get a valid output"
                            ),
                          is_empty: zod
                            .boolean()
                            .describe("The audio intelligence model returned an empty value"),
                          exec_time: zod
                            .number()
                            .describe("Time audio intelligence model took to complete the task"),
                          error: zod
                            .object({
                              status_code: zod.number().describe("Status code of the addon error"),
                              exception: zod.string().describe("Reason of the addon error"),
                              message: zod.string().describe("Detailed message of the addon error")
                            })
                            .nullable()
                            .describe(
                              "`null` if `success` is `true`. Contains the error details of the failed model"
                            ),
                          results: zod
                            .array(zod.string())
                            .nullable()
                            .describe(
                              "If `sentences` has been enabled, transcription as sentences."
                            )
                        })
                      )
                      .optional()
                      .describe("If `sentences` has been enabled, sentences results"),
                    subtitles: zod
                      .array(
                        zod.object({
                          format: zod
                            .enum(["srt", "vtt"])
                            .describe(
                              "Subtitles formats you want your transcription to be formatted to"
                            )
                            .describe("Format of the current subtitle"),
                          subtitles: zod
                            .string()
                            .describe("Transcription on the asked subtitle format")
                        })
                      )
                      .optional()
                      .describe("If `subtitles` has been enabled, subtitles results"),
                    utterances: zod
                      .array(
                        zod.object({
                          start: zod
                            .number()
                            .describe("Start timestamp in seconds of this utterance"),
                          end: zod.number().describe("End timestamp in seconds of this utterance"),
                          confidence: zod
                            .number()
                            .describe(
                              "Confidence on the transcribed utterance (1 = 100% confident)"
                            ),
                          channel: zod
                            .number()
                            .min(
                              historyControllerGetListV1ResponseItemsItemResultTranscriptionUtterancesItemChannelMinOne
                            )
                            .describe(
                              "Audio channel of where this utterance has been transcribed from"
                            ),
                          speaker: zod
                            .number()
                            .min(
                              historyControllerGetListV1ResponseItemsItemResultTranscriptionUtterancesItemSpeakerMinOne
                            )
                            .optional()
                            .describe("If `diarization` enabled, speaker identification number"),
                          words: zod
                            .array(
                              zod.object({
                                word: zod.string().describe("Spoken word"),
                                start: zod
                                  .number()
                                  .describe("Start timestamps in seconds of the spoken word"),
                                end: zod
                                  .number()
                                  .describe("End timestamps in seconds of the spoken word"),
                                confidence: zod
                                  .number()
                                  .describe(
                                    "Confidence on the transcribed word (1 = 100% confident)"
                                  )
                              })
                            )
                            .describe("List of words of the utterance, split by timestamp"),
                          text: zod.string().describe("Transcription for this utterance"),
                          language: zod
                            .enum([
                              "af",
                              "am",
                              "ar",
                              "as",
                              "az",
                              "ba",
                              "be",
                              "bg",
                              "bn",
                              "bo",
                              "br",
                              "bs",
                              "ca",
                              "cs",
                              "cy",
                              "da",
                              "de",
                              "el",
                              "en",
                              "es",
                              "et",
                              "eu",
                              "fa",
                              "fi",
                              "fo",
                              "fr",
                              "gl",
                              "gu",
                              "ha",
                              "haw",
                              "he",
                              "hi",
                              "hr",
                              "ht",
                              "hu",
                              "hy",
                              "id",
                              "is",
                              "it",
                              "ja",
                              "jw",
                              "ka",
                              "kk",
                              "km",
                              "kn",
                              "ko",
                              "la",
                              "lb",
                              "ln",
                              "lo",
                              "lt",
                              "lv",
                              "mg",
                              "mi",
                              "mk",
                              "ml",
                              "mn",
                              "mr",
                              "ms",
                              "mt",
                              "my",
                              "ne",
                              "nl",
                              "nn",
                              "no",
                              "oc",
                              "pa",
                              "pl",
                              "ps",
                              "pt",
                              "ro",
                              "ru",
                              "sa",
                              "sd",
                              "si",
                              "sk",
                              "sl",
                              "sn",
                              "so",
                              "sq",
                              "sr",
                              "su",
                              "sv",
                              "sw",
                              "ta",
                              "te",
                              "tg",
                              "th",
                              "tk",
                              "tl",
                              "tr",
                              "tt",
                              "uk",
                              "ur",
                              "uz",
                              "vi",
                              "yi",
                              "yo",
                              "zh"
                            ])
                            .describe(
                              "Specify the language in which it will be pronounced when sound comparison occurs. Default to transcription language."
                            )
                            .describe("Spoken language in this utterance")
                        })
                      )
                      .describe("Transcribed speech utterances present in the audio")
                  })
                  .optional()
                  .describe("Transcription of the audio speech"),
                translation: zod
                  .object({
                    success: zod
                      .boolean()
                      .describe("The audio intelligence model succeeded to get a valid output"),
                    is_empty: zod
                      .boolean()
                      .describe("The audio intelligence model returned an empty value"),
                    exec_time: zod
                      .number()
                      .describe("Time audio intelligence model took to complete the task"),
                    error: zod
                      .object({
                        status_code: zod.number().describe("Status code of the addon error"),
                        exception: zod.string().describe("Reason of the addon error"),
                        message: zod.string().describe("Detailed message of the addon error")
                      })
                      .nullable()
                      .describe(
                        "`null` if `success` is `true`. Contains the error details of the failed model"
                      ),
                    results: zod
                      .array(
                        zod.object({
                          error: zod
                            .object({
                              status_code: zod.number().describe("Status code of the addon error"),
                              exception: zod.string().describe("Reason of the addon error"),
                              message: zod.string().describe("Detailed message of the addon error")
                            })
                            .nullable()
                            .describe("Contains the error details of the failed addon"),
                          full_transcript: zod
                            .string()
                            .describe(
                              "All transcription on text format without any other information"
                            ),
                          languages: zod
                            .array(
                              zod
                                .enum([
                                  "af",
                                  "am",
                                  "ar",
                                  "as",
                                  "az",
                                  "ba",
                                  "be",
                                  "bg",
                                  "bn",
                                  "bo",
                                  "br",
                                  "bs",
                                  "ca",
                                  "cs",
                                  "cy",
                                  "da",
                                  "de",
                                  "el",
                                  "en",
                                  "es",
                                  "et",
                                  "eu",
                                  "fa",
                                  "fi",
                                  "fo",
                                  "fr",
                                  "gl",
                                  "gu",
                                  "ha",
                                  "haw",
                                  "he",
                                  "hi",
                                  "hr",
                                  "ht",
                                  "hu",
                                  "hy",
                                  "id",
                                  "is",
                                  "it",
                                  "ja",
                                  "jw",
                                  "ka",
                                  "kk",
                                  "km",
                                  "kn",
                                  "ko",
                                  "la",
                                  "lb",
                                  "ln",
                                  "lo",
                                  "lt",
                                  "lv",
                                  "mg",
                                  "mi",
                                  "mk",
                                  "ml",
                                  "mn",
                                  "mr",
                                  "ms",
                                  "mt",
                                  "my",
                                  "ne",
                                  "nl",
                                  "nn",
                                  "no",
                                  "oc",
                                  "pa",
                                  "pl",
                                  "ps",
                                  "pt",
                                  "ro",
                                  "ru",
                                  "sa",
                                  "sd",
                                  "si",
                                  "sk",
                                  "sl",
                                  "sn",
                                  "so",
                                  "sq",
                                  "sr",
                                  "su",
                                  "sv",
                                  "sw",
                                  "ta",
                                  "te",
                                  "tg",
                                  "th",
                                  "tk",
                                  "tl",
                                  "tr",
                                  "tt",
                                  "uk",
                                  "ur",
                                  "uz",
                                  "vi",
                                  "wo",
                                  "yi",
                                  "yo",
                                  "zh"
                                ])
                                .describe(
                                  "Target language in `iso639-1` format you want the transcription translated to"
                                )
                            )
                            .describe(
                              "All the detected languages in the audio sorted from the most detected to the less detected"
                            ),
                          sentences: zod
                            .array(
                              zod.object({
                                success: zod
                                  .boolean()
                                  .describe(
                                    "The audio intelligence model succeeded to get a valid output"
                                  ),
                                is_empty: zod
                                  .boolean()
                                  .describe("The audio intelligence model returned an empty value"),
                                exec_time: zod
                                  .number()
                                  .describe(
                                    "Time audio intelligence model took to complete the task"
                                  ),
                                error: zod
                                  .object({
                                    status_code: zod
                                      .number()
                                      .describe("Status code of the addon error"),
                                    exception: zod.string().describe("Reason of the addon error"),
                                    message: zod
                                      .string()
                                      .describe("Detailed message of the addon error")
                                  })
                                  .nullable()
                                  .describe(
                                    "`null` if `success` is `true`. Contains the error details of the failed model"
                                  ),
                                results: zod
                                  .array(zod.string())
                                  .nullable()
                                  .describe(
                                    "If `sentences` has been enabled, transcription as sentences."
                                  )
                              })
                            )
                            .optional()
                            .describe(
                              "If `sentences` has been enabled, sentences results for this translation"
                            ),
                          subtitles: zod
                            .array(
                              zod.object({
                                format: zod
                                  .enum(["srt", "vtt"])
                                  .describe(
                                    "Subtitles formats you want your transcription to be formatted to"
                                  )
                                  .describe("Format of the current subtitle"),
                                subtitles: zod
                                  .string()
                                  .describe("Transcription on the asked subtitle format")
                              })
                            )
                            .optional()
                            .describe(
                              "If `subtitles` has been enabled, subtitles results for this translation"
                            ),
                          utterances: zod
                            .array(
                              zod.object({
                                start: zod
                                  .number()
                                  .describe("Start timestamp in seconds of this utterance"),
                                end: zod
                                  .number()
                                  .describe("End timestamp in seconds of this utterance"),
                                confidence: zod
                                  .number()
                                  .describe(
                                    "Confidence on the transcribed utterance (1 = 100% confident)"
                                  ),
                                channel: zod
                                  .number()
                                  .min(
                                    historyControllerGetListV1ResponseItemsItemResultTranslationResultsItemUtterancesItemChannelMinOne
                                  )
                                  .describe(
                                    "Audio channel of where this utterance has been transcribed from"
                                  ),
                                speaker: zod
                                  .number()
                                  .min(
                                    historyControllerGetListV1ResponseItemsItemResultTranslationResultsItemUtterancesItemSpeakerMinOne
                                  )
                                  .optional()
                                  .describe(
                                    "If `diarization` enabled, speaker identification number"
                                  ),
                                words: zod
                                  .array(
                                    zod.object({
                                      word: zod.string().describe("Spoken word"),
                                      start: zod
                                        .number()
                                        .describe("Start timestamps in seconds of the spoken word"),
                                      end: zod
                                        .number()
                                        .describe("End timestamps in seconds of the spoken word"),
                                      confidence: zod
                                        .number()
                                        .describe(
                                          "Confidence on the transcribed word (1 = 100% confident)"
                                        )
                                    })
                                  )
                                  .describe("List of words of the utterance, split by timestamp"),
                                text: zod.string().describe("Transcription for this utterance"),
                                language: zod
                                  .enum([
                                    "af",
                                    "am",
                                    "ar",
                                    "as",
                                    "az",
                                    "ba",
                                    "be",
                                    "bg",
                                    "bn",
                                    "bo",
                                    "br",
                                    "bs",
                                    "ca",
                                    "cs",
                                    "cy",
                                    "da",
                                    "de",
                                    "el",
                                    "en",
                                    "es",
                                    "et",
                                    "eu",
                                    "fa",
                                    "fi",
                                    "fo",
                                    "fr",
                                    "gl",
                                    "gu",
                                    "ha",
                                    "haw",
                                    "he",
                                    "hi",
                                    "hr",
                                    "ht",
                                    "hu",
                                    "hy",
                                    "id",
                                    "is",
                                    "it",
                                    "ja",
                                    "jw",
                                    "ka",
                                    "kk",
                                    "km",
                                    "kn",
                                    "ko",
                                    "la",
                                    "lb",
                                    "ln",
                                    "lo",
                                    "lt",
                                    "lv",
                                    "mg",
                                    "mi",
                                    "mk",
                                    "ml",
                                    "mn",
                                    "mr",
                                    "ms",
                                    "mt",
                                    "my",
                                    "ne",
                                    "nl",
                                    "nn",
                                    "no",
                                    "oc",
                                    "pa",
                                    "pl",
                                    "ps",
                                    "pt",
                                    "ro",
                                    "ru",
                                    "sa",
                                    "sd",
                                    "si",
                                    "sk",
                                    "sl",
                                    "sn",
                                    "so",
                                    "sq",
                                    "sr",
                                    "su",
                                    "sv",
                                    "sw",
                                    "ta",
                                    "te",
                                    "tg",
                                    "th",
                                    "tk",
                                    "tl",
                                    "tr",
                                    "tt",
                                    "uk",
                                    "ur",
                                    "uz",
                                    "vi",
                                    "yi",
                                    "yo",
                                    "zh"
                                  ])
                                  .describe(
                                    "Specify the language in which it will be pronounced when sound comparison occurs. Default to transcription language."
                                  )
                                  .describe("Spoken language in this utterance")
                              })
                            )
                            .describe("Transcribed speech utterances present in the audio")
                        })
                      )
                      .nullable()
                      .describe(
                        "List of translated transcriptions, one for each `target_languages`"
                      )
                  })
                  .optional()
                  .describe(
                    "If `translation` has been enabled, translation of the audio speech transcription"
                  ),
                summarization: zod
                  .object({
                    success: zod
                      .boolean()
                      .describe("The audio intelligence model succeeded to get a valid output"),
                    is_empty: zod
                      .boolean()
                      .describe("The audio intelligence model returned an empty value"),
                    exec_time: zod
                      .number()
                      .describe("Time audio intelligence model took to complete the task"),
                    error: zod
                      .object({
                        status_code: zod.number().describe("Status code of the addon error"),
                        exception: zod.string().describe("Reason of the addon error"),
                        message: zod.string().describe("Detailed message of the addon error")
                      })
                      .nullable()
                      .describe(
                        "`null` if `success` is `true`. Contains the error details of the failed model"
                      ),
                    results: zod
                      .string()
                      .nullable()
                      .describe("If `summarization` has been enabled, summary of the transcription")
                  })
                  .optional()
                  .describe(
                    "If `summarization` has been enabled, summarization of the audio speech transcription"
                  ),
                named_entity_recognition: zod
                  .object({
                    success: zod
                      .boolean()
                      .describe("The audio intelligence model succeeded to get a valid output"),
                    is_empty: zod
                      .boolean()
                      .describe("The audio intelligence model returned an empty value"),
                    exec_time: zod
                      .number()
                      .describe("Time audio intelligence model took to complete the task"),
                    error: zod
                      .object({
                        status_code: zod.number().describe("Status code of the addon error"),
                        exception: zod.string().describe("Reason of the addon error"),
                        message: zod.string().describe("Detailed message of the addon error")
                      })
                      .nullable()
                      .describe(
                        "`null` if `success` is `true`. Contains the error details of the failed model"
                      ),
                    entity: zod
                      .string()
                      .describe(
                        "If `named_entity_recognition` has been enabled, the detected entities."
                      )
                  })
                  .optional()
                  .describe(
                    "If `named_entity_recognition` has been enabled, the detected entities"
                  ),
                sentiment_analysis: zod
                  .object({
                    success: zod
                      .boolean()
                      .describe("The audio intelligence model succeeded to get a valid output"),
                    is_empty: zod
                      .boolean()
                      .describe("The audio intelligence model returned an empty value"),
                    exec_time: zod
                      .number()
                      .describe("Time audio intelligence model took to complete the task"),
                    error: zod
                      .object({
                        status_code: zod.number().describe("Status code of the addon error"),
                        exception: zod.string().describe("Reason of the addon error"),
                        message: zod.string().describe("Detailed message of the addon error")
                      })
                      .nullable()
                      .describe(
                        "`null` if `success` is `true`. Contains the error details of the failed model"
                      ),
                    results: zod
                      .string()
                      .describe(
                        "If `sentiment_analysis` has been enabled, Gladia will analyze the sentiments and emotions of the audio"
                      )
                  })
                  .optional()
                  .describe(
                    "If `sentiment_analysis` has been enabled, sentiment analysis of the audio speech transcription"
                  ),
                chapterization: zod
                  .object({
                    success: zod
                      .boolean()
                      .describe("The audio intelligence model succeeded to get a valid output"),
                    is_empty: zod
                      .boolean()
                      .describe("The audio intelligence model returned an empty value"),
                    exec_time: zod
                      .number()
                      .describe("Time audio intelligence model took to complete the task"),
                    error: zod
                      .object({
                        status_code: zod.number().describe("Status code of the addon error"),
                        exception: zod.string().describe("Reason of the addon error"),
                        message: zod.string().describe("Detailed message of the addon error")
                      })
                      .nullable()
                      .describe(
                        "`null` if `success` is `true`. Contains the error details of the failed model"
                      ),
                    results: zod
                      .record(zod.string(), zod.any())
                      .describe(
                        "If `chapterization` has been enabled, will generate chapters name for different parts of the given audio."
                      )
                  })
                  .optional()
                  .describe(
                    "If `chapterization` has been enabled, will generate chapters name for different parts of the given audio."
                  ),
                messages: zod
                  .array(zod.string())
                  .optional()
                  .describe("Real-Time messages sent by the server during the live transcription")
              })
              .nullish()
              .describe('Live transcription\'s result when status is \"done\"')
          })
        )
    )
    .describe("List of jobs")
})

/**
 * @summary Initiate a new live job
 */
export const streamingControllerInitStreamingSessionV2QueryParams = zod.object({
  region: zod
    .enum(["us-west", "eu-west"])
    .optional()
    .describe("The region used to process the audio.")
})

export const streamingControllerInitStreamingSessionV2BodyEncodingDefault = "wav/pcm"
export const streamingControllerInitStreamingSessionV2BodyBitDepthDefault = 16
export const streamingControllerInitStreamingSessionV2BodySampleRateDefault = 16000
export const streamingControllerInitStreamingSessionV2BodyChannelsDefault = 1
export const streamingControllerInitStreamingSessionV2BodyChannelsMax = 8
export const streamingControllerInitStreamingSessionV2BodyModelDefault = "solaria-1"
export const streamingControllerInitStreamingSessionV2BodyEndpointingDefault = 0.05
export const streamingControllerInitStreamingSessionV2BodyEndpointingMin = 0.01

export const streamingControllerInitStreamingSessionV2BodyEndpointingMax = 10
export const streamingControllerInitStreamingSessionV2BodyMaximumDurationWithoutEndpointingDefault = 5
export const streamingControllerInitStreamingSessionV2BodyMaximumDurationWithoutEndpointingMin = 5

export const streamingControllerInitStreamingSessionV2BodyMaximumDurationWithoutEndpointingMax = 60
export const streamingControllerInitStreamingSessionV2BodyLanguageConfigLanguagesDefault = []
export const streamingControllerInitStreamingSessionV2BodyLanguageConfigCodeSwitchingDefault = false
export const streamingControllerInitStreamingSessionV2BodyPreProcessingAudioEnhancerDefault = false
export const streamingControllerInitStreamingSessionV2BodyPreProcessingSpeechThresholdDefault = 0.6
export const streamingControllerInitStreamingSessionV2BodyPreProcessingSpeechThresholdMin = 0

export const streamingControllerInitStreamingSessionV2BodyPreProcessingSpeechThresholdMax = 1
export const streamingControllerInitStreamingSessionV2BodyRealtimeProcessingCustomVocabularyDefault = false
export const streamingControllerInitStreamingSessionV2BodyRealtimeProcessingCustomVocabularyConfigVocabularyItemIntensityMin = 0

export const streamingControllerInitStreamingSessionV2BodyRealtimeProcessingCustomVocabularyConfigVocabularyItemIntensityMax = 1
export const streamingControllerInitStreamingSessionV2BodyRealtimeProcessingCustomVocabularyConfigDefaultIntensityMin = 0

export const streamingControllerInitStreamingSessionV2BodyRealtimeProcessingCustomVocabularyConfigDefaultIntensityMax = 1
export const streamingControllerInitStreamingSessionV2BodyRealtimeProcessingCustomSpellingDefault = false
export const streamingControllerInitStreamingSessionV2BodyRealtimeProcessingTranslationDefault = false
export const streamingControllerInitStreamingSessionV2BodyRealtimeProcessingTranslationConfigModelDefault =
  "base"
export const streamingControllerInitStreamingSessionV2BodyRealtimeProcessingTranslationConfigMatchOriginalUtterancesDefault = true
export const streamingControllerInitStreamingSessionV2BodyRealtimeProcessingTranslationConfigLipsyncDefault = true
export const streamingControllerInitStreamingSessionV2BodyRealtimeProcessingTranslationConfigContextAdaptationDefault = true
export const streamingControllerInitStreamingSessionV2BodyRealtimeProcessingTranslationConfigInformalDefault = false
export const streamingControllerInitStreamingSessionV2BodyRealtimeProcessingNamedEntityRecognitionDefault = false
export const streamingControllerInitStreamingSessionV2BodyRealtimeProcessingSentimentAnalysisDefault = false
export const streamingControllerInitStreamingSessionV2BodyPostProcessingSummarizationDefault = false
export const streamingControllerInitStreamingSessionV2BodyPostProcessingSummarizationConfigTypeDefault =
  "general"
export const streamingControllerInitStreamingSessionV2BodyPostProcessingChapterizationDefault = false
export const streamingControllerInitStreamingSessionV2BodyMessagesConfigReceivePartialTranscriptsDefault = false
export const streamingControllerInitStreamingSessionV2BodyMessagesConfigReceiveFinalTranscriptsDefault = true
export const streamingControllerInitStreamingSessionV2BodyMessagesConfigReceiveSpeechEventsDefault = true
export const streamingControllerInitStreamingSessionV2BodyMessagesConfigReceivePreProcessingEventsDefault = true
export const streamingControllerInitStreamingSessionV2BodyMessagesConfigReceiveRealtimeProcessingEventsDefault = true
export const streamingControllerInitStreamingSessionV2BodyMessagesConfigReceivePostProcessingEventsDefault = true
export const streamingControllerInitStreamingSessionV2BodyMessagesConfigReceiveAcknowledgmentsDefault = true
export const streamingControllerInitStreamingSessionV2BodyMessagesConfigReceiveErrorsDefault = true
export const streamingControllerInitStreamingSessionV2BodyMessagesConfigReceiveLifecycleEventsDefault = false
export const streamingControllerInitStreamingSessionV2BodyCallbackDefault = false
export const streamingControllerInitStreamingSessionV2BodyCallbackConfigReceivePartialTranscriptsDefault = false
export const streamingControllerInitStreamingSessionV2BodyCallbackConfigReceiveFinalTranscriptsDefault = true
export const streamingControllerInitStreamingSessionV2BodyCallbackConfigReceiveSpeechEventsDefault = false
export const streamingControllerInitStreamingSessionV2BodyCallbackConfigReceivePreProcessingEventsDefault = true
export const streamingControllerInitStreamingSessionV2BodyCallbackConfigReceiveRealtimeProcessingEventsDefault = true
export const streamingControllerInitStreamingSessionV2BodyCallbackConfigReceivePostProcessingEventsDefault = true
export const streamingControllerInitStreamingSessionV2BodyCallbackConfigReceiveAcknowledgmentsDefault = false
export const streamingControllerInitStreamingSessionV2BodyCallbackConfigReceiveErrorsDefault = false
export const streamingControllerInitStreamingSessionV2BodyCallbackConfigReceiveLifecycleEventsDefault = true

export const streamingControllerInitStreamingSessionV2Body = zod.object({
  encoding: zod
    .enum(["wav/pcm", "wav/alaw", "wav/ulaw"])
    .describe(
      "The encoding format of the audio stream. Supported formats: \n- PCM: 8, 16, 24, and 32 bits \n- A-law: 8 bits \n- Œº-law: 8 bits \n\nNote: No need to add WAV headers to raw audio as the API supports both formats."
    )
    .default(streamingControllerInitStreamingSessionV2BodyEncodingDefault)
    .describe(
      "The encoding format of the audio stream. Supported formats: \n- PCM: 8, 16, 24, and 32 bits \n- A-law: 8 bits \n- Œº-law: 8 bits \n\nNote: No need to add WAV headers to raw audio as the API supports both formats."
    ),
  bit_depth: zod
    .literal(8)
    .or(zod.literal(16))
    .or(zod.literal(24))
    .or(zod.literal(32))
    .describe("The bit depth of the audio stream")
    .default(streamingControllerInitStreamingSessionV2BodyBitDepthDefault)
    .describe("The bit depth of the audio stream"),
  sample_rate: zod
    .literal(8000)
    .or(zod.literal(16000))
    .or(zod.literal(32000))
    .or(zod.literal(44100))
    .or(zod.literal(48000))
    .describe("The sample rate of the audio stream")
    .default(streamingControllerInitStreamingSessionV2BodySampleRateDefault)
    .describe("The sample rate of the audio stream"),
  channels: zod
    .number()
    .min(1)
    .max(streamingControllerInitStreamingSessionV2BodyChannelsMax)
    .default(streamingControllerInitStreamingSessionV2BodyChannelsDefault)
    .describe("The number of channels of the audio stream"),
  custom_metadata: zod
    .record(zod.string(), zod.any())
    .optional()
    .describe("Custom metadata you can attach to this live transcription"),
  model: zod
    .enum(["solaria-1"])
    .describe('The model used to process the audio. \"solaria-1\" is used by default.')
    .default(streamingControllerInitStreamingSessionV2BodyModelDefault)
    .describe('The model used to process the audio. \"solaria-1\" is used by default.'),
  endpointing: zod
    .number()
    .min(streamingControllerInitStreamingSessionV2BodyEndpointingMin)
    .max(streamingControllerInitStreamingSessionV2BodyEndpointingMax)
    .default(streamingControllerInitStreamingSessionV2BodyEndpointingDefault)
    .describe(
      "The endpointing duration in seconds. Endpointing is the duration of silence which will cause an utterance to be considered as finished"
    ),
  maximum_duration_without_endpointing: zod
    .number()
    .min(streamingControllerInitStreamingSessionV2BodyMaximumDurationWithoutEndpointingMin)
    .max(streamingControllerInitStreamingSessionV2BodyMaximumDurationWithoutEndpointingMax)
    .default(streamingControllerInitStreamingSessionV2BodyMaximumDurationWithoutEndpointingDefault)
    .describe(
      "The maximum duration in seconds without endpointing. If endpointing is not detected after this duration, current utterance will be considered as finished"
    ),
  language_config: zod
    .object({
      languages: zod
        .array(
          zod
            .enum([
              "af",
              "am",
              "ar",
              "as",
              "az",
              "ba",
              "be",
              "bg",
              "bn",
              "bo",
              "br",
              "bs",
              "ca",
              "cs",
              "cy",
              "da",
              "de",
              "el",
              "en",
              "es",
              "et",
              "eu",
              "fa",
              "fi",
              "fo",
              "fr",
              "gl",
              "gu",
              "ha",
              "haw",
              "he",
              "hi",
              "hr",
              "ht",
              "hu",
              "hy",
              "id",
              "is",
              "it",
              "ja",
              "jw",
              "ka",
              "kk",
              "km",
              "kn",
              "ko",
              "la",
              "lb",
              "ln",
              "lo",
              "lt",
              "lv",
              "mg",
              "mi",
              "mk",
              "ml",
              "mn",
              "mr",
              "ms",
              "mt",
              "my",
              "ne",
              "nl",
              "nn",
              "no",
              "oc",
              "pa",
              "pl",
              "ps",
              "pt",
              "ro",
              "ru",
              "sa",
              "sd",
              "si",
              "sk",
              "sl",
              "sn",
              "so",
              "sq",
              "sr",
              "su",
              "sv",
              "sw",
              "ta",
              "te",
              "tg",
              "th",
              "tk",
              "tl",
              "tr",
              "tt",
              "uk",
              "ur",
              "uz",
              "vi",
              "yi",
              "yo",
              "zh"
            ])
            .describe(
              "Specify the language in which it will be pronounced when sound comparison occurs. Default to transcription language."
            )
        )
        .default(streamingControllerInitStreamingSessionV2BodyLanguageConfigLanguagesDefault)
        .describe(
          "If one language is set, it will be used for the transcription. Otherwise, language will be auto-detected by the model."
        ),
      code_switching: zod
        .boolean()
        .optional()
        .describe(
          "If true, language will be auto-detected on each utterance. Otherwise, language will be auto-detected on first utterance and then used for the rest of the transcription. If one language is set, this option will be ignored."
        )
    })
    .optional()
    .describe("Specify the language configuration"),
  pre_processing: zod
    .object({
      audio_enhancer: zod
        .boolean()
        .optional()
        .describe("If true, apply pre-processing to the audio stream to enhance the quality."),
      speech_threshold: zod
        .number()
        .min(streamingControllerInitStreamingSessionV2BodyPreProcessingSpeechThresholdMin)
        .max(streamingControllerInitStreamingSessionV2BodyPreProcessingSpeechThresholdMax)
        .default(streamingControllerInitStreamingSessionV2BodyPreProcessingSpeechThresholdDefault)
        .describe(
          "Sensitivity configuration for Speech Threshold. A value close to 1 will apply stricter thresholds, making it less likely to detect background sounds as speech."
        )
    })
    .optional()
    .describe("Specify the pre-processing configuration"),
  realtime_processing: zod
    .object({
      custom_vocabulary: zod
        .boolean()
        .optional()
        .describe("If true, enable custom vocabulary for the transcription."),
      custom_vocabulary_config: zod
        .object({
          vocabulary: zod
            .array(
              zod
                .object({
                  value: zod.string().describe("The text used to replace in the transcription."),
                  intensity: zod
                    .number()
                    .min(
                      streamingControllerInitStreamingSessionV2BodyRealtimeProcessingCustomVocabularyConfigVocabularyItemIntensityMin
                    )
                    .max(
                      streamingControllerInitStreamingSessionV2BodyRealtimeProcessingCustomVocabularyConfigVocabularyItemIntensityMax
                    )
                    .optional()
                    .describe("The global intensity of the feature."),
                  pronunciations: zod
                    .array(zod.string())
                    .optional()
                    .describe("The pronunciations used in the transcription."),
                  language: zod
                    .enum([
                      "af",
                      "am",
                      "ar",
                      "as",
                      "az",
                      "ba",
                      "be",
                      "bg",
                      "bn",
                      "bo",
                      "br",
                      "bs",
                      "ca",
                      "cs",
                      "cy",
                      "da",
                      "de",
                      "el",
                      "en",
                      "es",
                      "et",
                      "eu",
                      "fa",
                      "fi",
                      "fo",
                      "fr",
                      "gl",
                      "gu",
                      "ha",
                      "haw",
                      "he",
                      "hi",
                      "hr",
                      "ht",
                      "hu",
                      "hy",
                      "id",
                      "is",
                      "it",
                      "ja",
                      "jw",
                      "ka",
                      "kk",
                      "km",
                      "kn",
                      "ko",
                      "la",
                      "lb",
                      "ln",
                      "lo",
                      "lt",
                      "lv",
                      "mg",
                      "mi",
                      "mk",
                      "ml",
                      "mn",
                      "mr",
                      "ms",
                      "mt",
                      "my",
                      "ne",
                      "nl",
                      "nn",
                      "no",
                      "oc",
                      "pa",
                      "pl",
                      "ps",
                      "pt",
                      "ro",
                      "ru",
                      "sa",
                      "sd",
                      "si",
                      "sk",
                      "sl",
                      "sn",
                      "so",
                      "sq",
                      "sr",
                      "su",
                      "sv",
                      "sw",
                      "ta",
                      "te",
                      "tg",
                      "th",
                      "tk",
                      "tl",
                      "tr",
                      "tt",
                      "uk",
                      "ur",
                      "uz",
                      "vi",
                      "yi",
                      "yo",
                      "zh"
                    ])
                    .describe(
                      "Specify the language in which it will be pronounced when sound comparison occurs. Default to transcription language."
                    )
                    .optional()
                    .describe(
                      "Specify the language in which it will be pronounced when sound comparison occurs. Default to transcription language."
                    )
                })
                .or(zod.string())
            )
            .describe(
              "Specific vocabulary list to feed the transcription model with. Each item can be a string or an object with the following properties: value, intensity, pronunciations, language."
            ),
          default_intensity: zod
            .number()
            .min(
              streamingControllerInitStreamingSessionV2BodyRealtimeProcessingCustomVocabularyConfigDefaultIntensityMin
            )
            .max(
              streamingControllerInitStreamingSessionV2BodyRealtimeProcessingCustomVocabularyConfigDefaultIntensityMax
            )
            .optional()
            .describe("Default intensity for the custom vocabulary")
        })
        .optional()
        .describe("Custom vocabulary configuration, if `custom_vocabulary` is enabled"),
      custom_spelling: zod
        .boolean()
        .optional()
        .describe("If true, enable custom spelling for the transcription."),
      custom_spelling_config: zod
        .object({
          spelling_dictionary: zod
            .record(zod.string(), zod.array(zod.string()))
            .describe("The list of spelling applied on the audio transcription")
        })
        .optional()
        .describe("Custom spelling configuration, if `custom_spelling` is enabled"),
      translation: zod
        .boolean()
        .optional()
        .describe("If true, enable translation for the transcription"),
      translation_config: zod
        .object({
          target_languages: zod
            .array(
              zod
                .enum([
                  "af",
                  "am",
                  "ar",
                  "as",
                  "az",
                  "ba",
                  "be",
                  "bg",
                  "bn",
                  "bo",
                  "br",
                  "bs",
                  "ca",
                  "cs",
                  "cy",
                  "da",
                  "de",
                  "el",
                  "en",
                  "es",
                  "et",
                  "eu",
                  "fa",
                  "fi",
                  "fo",
                  "fr",
                  "gl",
                  "gu",
                  "ha",
                  "haw",
                  "he",
                  "hi",
                  "hr",
                  "ht",
                  "hu",
                  "hy",
                  "id",
                  "is",
                  "it",
                  "ja",
                  "jw",
                  "ka",
                  "kk",
                  "km",
                  "kn",
                  "ko",
                  "la",
                  "lb",
                  "ln",
                  "lo",
                  "lt",
                  "lv",
                  "mg",
                  "mi",
                  "mk",
                  "ml",
                  "mn",
                  "mr",
                  "ms",
                  "mt",
                  "my",
                  "ne",
                  "nl",
                  "nn",
                  "no",
                  "oc",
                  "pa",
                  "pl",
                  "ps",
                  "pt",
                  "ro",
                  "ru",
                  "sa",
                  "sd",
                  "si",
                  "sk",
                  "sl",
                  "sn",
                  "so",
                  "sq",
                  "sr",
                  "su",
                  "sv",
                  "sw",
                  "ta",
                  "te",
                  "tg",
                  "th",
                  "tk",
                  "tl",
                  "tr",
                  "tt",
                  "uk",
                  "ur",
                  "uz",
                  "vi",
                  "wo",
                  "yi",
                  "yo",
                  "zh"
                ])
                .describe(
                  "Target language in `iso639-1` format you want the transcription translated to"
                )
            )
            .min(1)
            .describe(
              "Target language in `iso639-1` format you want the transcription translated to"
            ),
          model: zod
            .enum(["base", "enhanced"])
            .describe("Model you want the translation model to use to translate")
            .default(
              streamingControllerInitStreamingSessionV2BodyRealtimeProcessingTranslationConfigModelDefault
            )
            .describe("Model you want the translation model to use to translate"),
          match_original_utterances: zod
            .boolean()
            .default(
              streamingControllerInitStreamingSessionV2BodyRealtimeProcessingTranslationConfigMatchOriginalUtterancesDefault
            )
            .describe("Align translated utterances with the original ones"),
          lipsync: zod
            .boolean()
            .default(
              streamingControllerInitStreamingSessionV2BodyRealtimeProcessingTranslationConfigLipsyncDefault
            )
            .describe("Whether to apply lipsync to the translated transcription. "),
          context_adaptation: zod
            .boolean()
            .default(
              streamingControllerInitStreamingSessionV2BodyRealtimeProcessingTranslationConfigContextAdaptationDefault
            )
            .describe(
              "Enables or disables context-aware translation features that allow the model to adapt translations based on provided context."
            ),
          context: zod
            .string()
            .optional()
            .describe("Context information to improve translation accuracy"),
          informal: zod
            .boolean()
            .optional()
            .describe(
              "Forces the translation to use informal language forms when available in the target language."
            )
        })
        .optional()
        .describe("Translation configuration, if `translation` is enabled"),
      named_entity_recognition: zod
        .boolean()
        .optional()
        .describe("If true, enable named entity recognition for the transcription."),
      sentiment_analysis: zod
        .boolean()
        .optional()
        .describe("If true, enable sentiment analysis for the transcription.")
    })
    .optional()
    .describe("Specify the realtime processing configuration"),
  post_processing: zod
    .object({
      summarization: zod
        .boolean()
        .optional()
        .describe("If true, generates summarization for the whole transcription."),
      summarization_config: zod
        .object({
          type: zod
            .enum(["general", "bullet_points", "concise"])
            .describe("The type of summarization to apply")
            .default(
              streamingControllerInitStreamingSessionV2BodyPostProcessingSummarizationConfigTypeDefault
            )
            .describe("The type of summarization to apply")
        })
        .optional()
        .describe("Summarization configuration, if `summarization` is enabled"),
      chapterization: zod
        .boolean()
        .optional()
        .describe("If true, generates chapters for the whole transcription.")
    })
    .optional()
    .describe("Specify the post-processing configuration"),
  messages_config: zod
    .object({
      receive_partial_transcripts: zod
        .boolean()
        .optional()
        .describe("If true, partial transcript will be sent to websocket."),
      receive_final_transcripts: zod
        .boolean()
        .default(
          streamingControllerInitStreamingSessionV2BodyMessagesConfigReceiveFinalTranscriptsDefault
        )
        .describe("If true, final transcript will be sent to websocket."),
      receive_speech_events: zod
        .boolean()
        .default(
          streamingControllerInitStreamingSessionV2BodyMessagesConfigReceiveSpeechEventsDefault
        )
        .describe("If true, begin and end speech events will be sent to websocket."),
      receive_pre_processing_events: zod
        .boolean()
        .default(
          streamingControllerInitStreamingSessionV2BodyMessagesConfigReceivePreProcessingEventsDefault
        )
        .describe("If true, pre-processing events will be sent to websocket."),
      receive_realtime_processing_events: zod
        .boolean()
        .default(
          streamingControllerInitStreamingSessionV2BodyMessagesConfigReceiveRealtimeProcessingEventsDefault
        )
        .describe("If true, realtime processing events will be sent to websocket."),
      receive_post_processing_events: zod
        .boolean()
        .default(
          streamingControllerInitStreamingSessionV2BodyMessagesConfigReceivePostProcessingEventsDefault
        )
        .describe("If true, post-processing events will be sent to websocket."),
      receive_acknowledgments: zod
        .boolean()
        .default(
          streamingControllerInitStreamingSessionV2BodyMessagesConfigReceiveAcknowledgmentsDefault
        )
        .describe("If true, acknowledgments will be sent to websocket."),
      receive_errors: zod
        .boolean()
        .default(streamingControllerInitStreamingSessionV2BodyMessagesConfigReceiveErrorsDefault)
        .describe("If true, errors will be sent to websocket."),
      receive_lifecycle_events: zod
        .boolean()
        .optional()
        .describe("If true, lifecycle events will be sent to websocket.")
    })
    .optional()
    .describe("Specify the websocket messages configuration"),
  callback: zod.boolean().optional().describe("If true, messages will be sent to configured url."),
  callback_config: zod
    .object({
      url: zod
        .string()
        .url()
        .optional()
        .describe("URL on which we will do a `POST` request with configured messages"),
      receive_partial_transcripts: zod
        .boolean()
        .optional()
        .describe("If true, partial transcript will be sent to the defined callback."),
      receive_final_transcripts: zod
        .boolean()
        .default(
          streamingControllerInitStreamingSessionV2BodyCallbackConfigReceiveFinalTranscriptsDefault
        )
        .describe("If true, final transcript will be sent to the defined callback."),
      receive_speech_events: zod
        .boolean()
        .optional()
        .describe("If true, begin and end speech events will be sent to the defined callback."),
      receive_pre_processing_events: zod
        .boolean()
        .default(
          streamingControllerInitStreamingSessionV2BodyCallbackConfigReceivePreProcessingEventsDefault
        )
        .describe("If true, pre-processing events will be sent to the defined callback."),
      receive_realtime_processing_events: zod
        .boolean()
        .default(
          streamingControllerInitStreamingSessionV2BodyCallbackConfigReceiveRealtimeProcessingEventsDefault
        )
        .describe("If true, realtime processing events will be sent to the defined callback."),
      receive_post_processing_events: zod
        .boolean()
        .default(
          streamingControllerInitStreamingSessionV2BodyCallbackConfigReceivePostProcessingEventsDefault
        )
        .describe("If true, post-processing events will be sent to the defined callback."),
      receive_acknowledgments: zod
        .boolean()
        .optional()
        .describe("If true, acknowledgments will be sent to the defined callback."),
      receive_errors: zod
        .boolean()
        .optional()
        .describe("If true, errors will be sent to the defined callback."),
      receive_lifecycle_events: zod
        .boolean()
        .default(
          streamingControllerInitStreamingSessionV2BodyCallbackConfigReceiveLifecycleEventsDefault
        )
        .describe("If true, lifecycle events will be sent to the defined callback.")
    })
    .optional()
    .describe("Specify the callback configuration")
})

/**
 * @summary Get live jobs based on query parameters
 */
export const streamingControllerGetStreamingJobsV2QueryOffsetDefault = 0
export const streamingControllerGetStreamingJobsV2QueryOffsetMin = 0
export const streamingControllerGetStreamingJobsV2QueryLimitDefault = 20

export const streamingControllerGetStreamingJobsV2QueryParams = zod.object({
  offset: zod
    .number()
    .min(streamingControllerGetStreamingJobsV2QueryOffsetMin)
    .optional()
    .describe("The starting point for pagination. A value of 0 starts from the first item."),
  limit: zod
    .number()
    .min(1)
    .default(streamingControllerGetStreamingJobsV2QueryLimitDefault)
    .describe(
      "The maximum number of items to return. Useful for pagination and controlling data payload size."
    ),
  date: zod
    .string()
    .datetime({})
    .optional()
    .describe("Filter items relevant to a specific date in ISO format (YYYY-MM-DD)."),
  before_date: zod
    .string()
    .datetime({})
    .optional()
    .describe("Include items that occurred before the specified date in ISO format."),
  after_date: zod
    .string()
    .datetime({})
    .optional()
    .describe(
      "Filter for items after the specified date. Use with `before_date` for a range. Date in ISO format."
    ),
  status: zod
    .array(zod.enum(["queued", "processing", "done", "error"]))
    .optional()
    .describe(
      "Filter the list based on item status. Accepts multiple values from the predefined list."
    ),
  custom_metadata: zod.record(zod.string(), zod.any()).optional()
})

export const streamingControllerGetStreamingJobsV2ResponseItemsItemErrorCodeMin = 400

export const streamingControllerGetStreamingJobsV2ResponseItemsItemErrorCodeMax = 599
export const streamingControllerGetStreamingJobsV2ResponseItemsItemKindDefault = "live"
export const streamingControllerGetStreamingJobsV2ResponseItemsItemRequestParamsEncodingDefault =
  "wav/pcm"
export const streamingControllerGetStreamingJobsV2ResponseItemsItemRequestParamsBitDepthDefault = 16
export const streamingControllerGetStreamingJobsV2ResponseItemsItemRequestParamsSampleRateDefault = 16000
export const streamingControllerGetStreamingJobsV2ResponseItemsItemRequestParamsChannelsDefault = 1
export const streamingControllerGetStreamingJobsV2ResponseItemsItemRequestParamsChannelsMax = 8
export const streamingControllerGetStreamingJobsV2ResponseItemsItemRequestParamsModelDefault =
  "solaria-1"
export const streamingControllerGetStreamingJobsV2ResponseItemsItemRequestParamsEndpointingDefault = 0.05
export const streamingControllerGetStreamingJobsV2ResponseItemsItemRequestParamsEndpointingMin = 0.01

export const streamingControllerGetStreamingJobsV2ResponseItemsItemRequestParamsEndpointingMax = 10
export const streamingControllerGetStreamingJobsV2ResponseItemsItemRequestParamsMaximumDurationWithoutEndpointingDefault = 5
export const streamingControllerGetStreamingJobsV2ResponseItemsItemRequestParamsMaximumDurationWithoutEndpointingMin = 5

export const streamingControllerGetStreamingJobsV2ResponseItemsItemRequestParamsMaximumDurationWithoutEndpointingMax = 60
export const streamingControllerGetStreamingJobsV2ResponseItemsItemRequestParamsLanguageConfigLanguagesDefault =
  []
export const streamingControllerGetStreamingJobsV2ResponseItemsItemRequestParamsLanguageConfigCodeSwitchingDefault = false
export const streamingControllerGetStreamingJobsV2ResponseItemsItemRequestParamsPreProcessingAudioEnhancerDefault = false
export const streamingControllerGetStreamingJobsV2ResponseItemsItemRequestParamsPreProcessingSpeechThresholdDefault = 0.6
export const streamingControllerGetStreamingJobsV2ResponseItemsItemRequestParamsPreProcessingSpeechThresholdMin = 0

export const streamingControllerGetStreamingJobsV2ResponseItemsItemRequestParamsPreProcessingSpeechThresholdMax = 1
export const streamingControllerGetStreamingJobsV2ResponseItemsItemRequestParamsRealtimeProcessingCustomVocabularyDefault = false
export const streamingControllerGetStreamingJobsV2ResponseItemsItemRequestParamsRealtimeProcessingCustomVocabularyConfigVocabularyItemIntensityMin = 0

export const streamingControllerGetStreamingJobsV2ResponseItemsItemRequestParamsRealtimeProcessingCustomVocabularyConfigVocabularyItemIntensityMax = 1
export const streamingControllerGetStreamingJobsV2ResponseItemsItemRequestParamsRealtimeProcessingCustomVocabularyConfigDefaultIntensityMin = 0

export const streamingControllerGetStreamingJobsV2ResponseItemsItemRequestParamsRealtimeProcessingCustomVocabularyConfigDefaultIntensityMax = 1
export const streamingControllerGetStreamingJobsV2ResponseItemsItemRequestParamsRealtimeProcessingCustomSpellingDefault = false
export const streamingControllerGetStreamingJobsV2ResponseItemsItemRequestParamsRealtimeProcessingTranslationDefault = false
export const streamingControllerGetStreamingJobsV2ResponseItemsItemRequestParamsRealtimeProcessingTranslationConfigModelDefault =
  "base"
export const streamingControllerGetStreamingJobsV2ResponseItemsItemRequestParamsRealtimeProcessingTranslationConfigMatchOriginalUtterancesDefault = true
export const streamingControllerGetStreamingJobsV2ResponseItemsItemRequestParamsRealtimeProcessingTranslationConfigLipsyncDefault = true
export const streamingControllerGetStreamingJobsV2ResponseItemsItemRequestParamsRealtimeProcessingTranslationConfigContextAdaptationDefault = true
export const streamingControllerGetStreamingJobsV2ResponseItemsItemRequestParamsRealtimeProcessingTranslationConfigInformalDefault = false
export const streamingControllerGetStreamingJobsV2ResponseItemsItemRequestParamsRealtimeProcessingNamedEntityRecognitionDefault = false
export const streamingControllerGetStreamingJobsV2ResponseItemsItemRequestParamsRealtimeProcessingSentimentAnalysisDefault = false
export const streamingControllerGetStreamingJobsV2ResponseItemsItemRequestParamsPostProcessingSummarizationDefault = false
export const streamingControllerGetStreamingJobsV2ResponseItemsItemRequestParamsPostProcessingSummarizationConfigTypeDefault =
  "general"
export const streamingControllerGetStreamingJobsV2ResponseItemsItemRequestParamsPostProcessingChapterizationDefault = false
export const streamingControllerGetStreamingJobsV2ResponseItemsItemRequestParamsMessagesConfigReceivePartialTranscriptsDefault = false
export const streamingControllerGetStreamingJobsV2ResponseItemsItemRequestParamsMessagesConfigReceiveFinalTranscriptsDefault = true
export const streamingControllerGetStreamingJobsV2ResponseItemsItemRequestParamsMessagesConfigReceiveSpeechEventsDefault = true
export const streamingControllerGetStreamingJobsV2ResponseItemsItemRequestParamsMessagesConfigReceivePreProcessingEventsDefault = true
export const streamingControllerGetStreamingJobsV2ResponseItemsItemRequestParamsMessagesConfigReceiveRealtimeProcessingEventsDefault = true
export const streamingControllerGetStreamingJobsV2ResponseItemsItemRequestParamsMessagesConfigReceivePostProcessingEventsDefault = true
export const streamingControllerGetStreamingJobsV2ResponseItemsItemRequestParamsMessagesConfigReceiveAcknowledgmentsDefault = true
export const streamingControllerGetStreamingJobsV2ResponseItemsItemRequestParamsMessagesConfigReceiveErrorsDefault = true
export const streamingControllerGetStreamingJobsV2ResponseItemsItemRequestParamsMessagesConfigReceiveLifecycleEventsDefault = false
export const streamingControllerGetStreamingJobsV2ResponseItemsItemRequestParamsCallbackDefault = false
export const streamingControllerGetStreamingJobsV2ResponseItemsItemRequestParamsCallbackConfigReceivePartialTranscriptsDefault = false
export const streamingControllerGetStreamingJobsV2ResponseItemsItemRequestParamsCallbackConfigReceiveFinalTranscriptsDefault = true
export const streamingControllerGetStreamingJobsV2ResponseItemsItemRequestParamsCallbackConfigReceiveSpeechEventsDefault = false
export const streamingControllerGetStreamingJobsV2ResponseItemsItemRequestParamsCallbackConfigReceivePreProcessingEventsDefault = true
export const streamingControllerGetStreamingJobsV2ResponseItemsItemRequestParamsCallbackConfigReceiveRealtimeProcessingEventsDefault = true
export const streamingControllerGetStreamingJobsV2ResponseItemsItemRequestParamsCallbackConfigReceivePostProcessingEventsDefault = true
export const streamingControllerGetStreamingJobsV2ResponseItemsItemRequestParamsCallbackConfigReceiveAcknowledgmentsDefault = false
export const streamingControllerGetStreamingJobsV2ResponseItemsItemRequestParamsCallbackConfigReceiveErrorsDefault = false
export const streamingControllerGetStreamingJobsV2ResponseItemsItemRequestParamsCallbackConfigReceiveLifecycleEventsDefault = true
export const streamingControllerGetStreamingJobsV2ResponseItemsItemResultTranscriptionUtterancesItemChannelMin = 0
export const streamingControllerGetStreamingJobsV2ResponseItemsItemResultTranscriptionUtterancesItemSpeakerMin = 0
export const streamingControllerGetStreamingJobsV2ResponseItemsItemResultTranslationResultsItemUtterancesItemChannelMin = 0
export const streamingControllerGetStreamingJobsV2ResponseItemsItemResultTranslationResultsItemUtterancesItemSpeakerMin = 0

export const streamingControllerGetStreamingJobsV2Response = zod.object({
  first: zod.string().url().describe("URL to fetch the first page"),
  current: zod.string().url().describe("URL to fetch the current page"),
  next: zod.string().url().nullable().describe("URL to fetch the next page"),
  items: zod
    .array(
      zod.object({
        id: zod.string().uuid().describe("Id of the job"),
        request_id: zod.string().describe("Debug id"),
        version: zod.number().describe("API version"),
        status: zod
          .enum(["queued", "processing", "done", "error"])
          .describe(
            '\"queued\": the job has been queued. \"processing\": the job is being processed. \"done\": the job has been processed and the result is available. \"error\": an error occurred during the job\'s processing.'
          ),
        created_at: zod.string().datetime({}).describe("Creation date"),
        completed_at: zod
          .string()
          .datetime({})
          .nullish()
          .describe('Completion date when status is \"done\" or \"error\"'),
        custom_metadata: zod
          .record(zod.string(), zod.any())
          .optional()
          .describe("Custom metadata given in the initial request"),
        error_code: zod
          .number()
          .min(streamingControllerGetStreamingJobsV2ResponseItemsItemErrorCodeMin)
          .max(streamingControllerGetStreamingJobsV2ResponseItemsItemErrorCodeMax)
          .nullish()
          .describe('HTTP status code of the error if status is \"error\"'),
        post_session_metadata: zod
          .object({})
          .describe("For debugging purposes, send data that could help to identify issues"),
        kind: zod.enum(["live"]),
        file: zod
          .object({
            id: zod.string().describe("The file id"),
            filename: zod.string().nullable().describe("The name of the uploaded file"),
            source: zod
              .string()
              .nullable()
              .describe("The link used to download the file if audio_url was used"),
            audio_duration: zod.number().nullable().describe("Duration of the audio file"),
            number_of_channels: zod
              .number()
              .min(1)
              .nullable()
              .describe("Number of channels in the audio file")
          })
          .nullish()
          .describe('The file data you uploaded. Can be null if status is \"error\"'),
        request_params: zod
          .object({
            encoding: zod
              .enum(["wav/pcm", "wav/alaw", "wav/ulaw"])
              .describe(
                "The encoding format of the audio stream. Supported formats: \n- PCM: 8, 16, 24, and 32 bits \n- A-law: 8 bits \n- Œº-law: 8 bits \n\nNote: No need to add WAV headers to raw audio as the API supports both formats."
              )
              .default(
                streamingControllerGetStreamingJobsV2ResponseItemsItemRequestParamsEncodingDefault
              )
              .describe(
                "The encoding format of the audio stream. Supported formats: \n- PCM: 8, 16, 24, and 32 bits \n- A-law: 8 bits \n- Œº-law: 8 bits \n\nNote: No need to add WAV headers to raw audio as the API supports both formats."
              ),
            bit_depth: zod
              .literal(8)
              .or(zod.literal(16))
              .or(zod.literal(24))
              .or(zod.literal(32))
              .describe("The bit depth of the audio stream")
              .default(
                streamingControllerGetStreamingJobsV2ResponseItemsItemRequestParamsBitDepthDefault
              )
              .describe("The bit depth of the audio stream"),
            sample_rate: zod
              .literal(8000)
              .or(zod.literal(16000))
              .or(zod.literal(32000))
              .or(zod.literal(44100))
              .or(zod.literal(48000))
              .describe("The sample rate of the audio stream")
              .default(
                streamingControllerGetStreamingJobsV2ResponseItemsItemRequestParamsSampleRateDefault
              )
              .describe("The sample rate of the audio stream"),
            channels: zod
              .number()
              .min(1)
              .max(streamingControllerGetStreamingJobsV2ResponseItemsItemRequestParamsChannelsMax)
              .default(
                streamingControllerGetStreamingJobsV2ResponseItemsItemRequestParamsChannelsDefault
              )
              .describe("The number of channels of the audio stream"),
            model: zod
              .enum(["solaria-1"])
              .describe('The model used to process the audio. \"solaria-1\" is used by default.')
              .default(
                streamingControllerGetStreamingJobsV2ResponseItemsItemRequestParamsModelDefault
              )
              .describe('The model used to process the audio. \"solaria-1\" is used by default.'),
            endpointing: zod
              .number()
              .min(
                streamingControllerGetStreamingJobsV2ResponseItemsItemRequestParamsEndpointingMin
              )
              .max(
                streamingControllerGetStreamingJobsV2ResponseItemsItemRequestParamsEndpointingMax
              )
              .default(
                streamingControllerGetStreamingJobsV2ResponseItemsItemRequestParamsEndpointingDefault
              )
              .describe(
                "The endpointing duration in seconds. Endpointing is the duration of silence which will cause an utterance to be considered as finished"
              ),
            maximum_duration_without_endpointing: zod
              .number()
              .min(
                streamingControllerGetStreamingJobsV2ResponseItemsItemRequestParamsMaximumDurationWithoutEndpointingMin
              )
              .max(
                streamingControllerGetStreamingJobsV2ResponseItemsItemRequestParamsMaximumDurationWithoutEndpointingMax
              )
              .default(
                streamingControllerGetStreamingJobsV2ResponseItemsItemRequestParamsMaximumDurationWithoutEndpointingDefault
              )
              .describe(
                "The maximum duration in seconds without endpointing. If endpointing is not detected after this duration, current utterance will be considered as finished"
              ),
            language_config: zod
              .object({
                languages: zod
                  .array(
                    zod
                      .enum([
                        "af",
                        "am",
                        "ar",
                        "as",
                        "az",
                        "ba",
                        "be",
                        "bg",
                        "bn",
                        "bo",
                        "br",
                        "bs",
                        "ca",
                        "cs",
                        "cy",
                        "da",
                        "de",
                        "el",
                        "en",
                        "es",
                        "et",
                        "eu",
                        "fa",
                        "fi",
                        "fo",
                        "fr",
                        "gl",
                        "gu",
                        "ha",
                        "haw",
                        "he",
                        "hi",
                        "hr",
                        "ht",
                        "hu",
                        "hy",
                        "id",
                        "is",
                        "it",
                        "ja",
                        "jw",
                        "ka",
                        "kk",
                        "km",
                        "kn",
                        "ko",
                        "la",
                        "lb",
                        "ln",
                        "lo",
                        "lt",
                        "lv",
                        "mg",
                        "mi",
                        "mk",
                        "ml",
                        "mn",
                        "mr",
                        "ms",
                        "mt",
                        "my",
                        "ne",
                        "nl",
                        "nn",
                        "no",
                        "oc",
                        "pa",
                        "pl",
                        "ps",
                        "pt",
                        "ro",
                        "ru",
                        "sa",
                        "sd",
                        "si",
                        "sk",
                        "sl",
                        "sn",
                        "so",
                        "sq",
                        "sr",
                        "su",
                        "sv",
                        "sw",
                        "ta",
                        "te",
                        "tg",
                        "th",
                        "tk",
                        "tl",
                        "tr",
                        "tt",
                        "uk",
                        "ur",
                        "uz",
                        "vi",
                        "yi",
                        "yo",
                        "zh"
                      ])
                      .describe(
                        "Specify the language in which it will be pronounced when sound comparison occurs. Default to transcription language."
                      )
                  )
                  .default(
                    streamingControllerGetStreamingJobsV2ResponseItemsItemRequestParamsLanguageConfigLanguagesDefault
                  )
                  .describe(
                    "If one language is set, it will be used for the transcription. Otherwise, language will be auto-detected by the model."
                  ),
                code_switching: zod
                  .boolean()
                  .optional()
                  .describe(
                    "If true, language will be auto-detected on each utterance. Otherwise, language will be auto-detected on first utterance and then used for the rest of the transcription. If one language is set, this option will be ignored."
                  )
              })
              .optional()
              .describe("Specify the language configuration"),
            pre_processing: zod
              .object({
                audio_enhancer: zod
                  .boolean()
                  .optional()
                  .describe(
                    "If true, apply pre-processing to the audio stream to enhance the quality."
                  ),
                speech_threshold: zod
                  .number()
                  .min(
                    streamingControllerGetStreamingJobsV2ResponseItemsItemRequestParamsPreProcessingSpeechThresholdMin
                  )
                  .max(
                    streamingControllerGetStreamingJobsV2ResponseItemsItemRequestParamsPreProcessingSpeechThresholdMax
                  )
                  .default(
                    streamingControllerGetStreamingJobsV2ResponseItemsItemRequestParamsPreProcessingSpeechThresholdDefault
                  )
                  .describe(
                    "Sensitivity configuration for Speech Threshold. A value close to 1 will apply stricter thresholds, making it less likely to detect background sounds as speech."
                  )
              })
              .optional()
              .describe("Specify the pre-processing configuration"),
            realtime_processing: zod
              .object({
                custom_vocabulary: zod
                  .boolean()
                  .optional()
                  .describe("If true, enable custom vocabulary for the transcription."),
                custom_vocabulary_config: zod
                  .object({
                    vocabulary: zod
                      .array(
                        zod
                          .object({
                            value: zod
                              .string()
                              .describe("The text used to replace in the transcription."),
                            intensity: zod
                              .number()
                              .min(
                                streamingControllerGetStreamingJobsV2ResponseItemsItemRequestParamsRealtimeProcessingCustomVocabularyConfigVocabularyItemIntensityMin
                              )
                              .max(
                                streamingControllerGetStreamingJobsV2ResponseItemsItemRequestParamsRealtimeProcessingCustomVocabularyConfigVocabularyItemIntensityMax
                              )
                              .optional()
                              .describe("The global intensity of the feature."),
                            pronunciations: zod
                              .array(zod.string())
                              .optional()
                              .describe("The pronunciations used in the transcription."),
                            language: zod
                              .enum([
                                "af",
                                "am",
                                "ar",
                                "as",
                                "az",
                                "ba",
                                "be",
                                "bg",
                                "bn",
                                "bo",
                                "br",
                                "bs",
                                "ca",
                                "cs",
                                "cy",
                                "da",
                                "de",
                                "el",
                                "en",
                                "es",
                                "et",
                                "eu",
                                "fa",
                                "fi",
                                "fo",
                                "fr",
                                "gl",
                                "gu",
                                "ha",
                                "haw",
                                "he",
                                "hi",
                                "hr",
                                "ht",
                                "hu",
                                "hy",
                                "id",
                                "is",
                                "it",
                                "ja",
                                "jw",
                                "ka",
                                "kk",
                                "km",
                                "kn",
                                "ko",
                                "la",
                                "lb",
                                "ln",
                                "lo",
                                "lt",
                                "lv",
                                "mg",
                                "mi",
                                "mk",
                                "ml",
                                "mn",
                                "mr",
                                "ms",
                                "mt",
                                "my",
                                "ne",
                                "nl",
                                "nn",
                                "no",
                                "oc",
                                "pa",
                                "pl",
                                "ps",
                                "pt",
                                "ro",
                                "ru",
                                "sa",
                                "sd",
                                "si",
                                "sk",
                                "sl",
                                "sn",
                                "so",
                                "sq",
                                "sr",
                                "su",
                                "sv",
                                "sw",
                                "ta",
                                "te",
                                "tg",
                                "th",
                                "tk",
                                "tl",
                                "tr",
                                "tt",
                                "uk",
                                "ur",
                                "uz",
                                "vi",
                                "yi",
                                "yo",
                                "zh"
                              ])
                              .describe(
                                "Specify the language in which it will be pronounced when sound comparison occurs. Default to transcription language."
                              )
                              .optional()
                              .describe(
                                "Specify the language in which it will be pronounced when sound comparison occurs. Default to transcription language."
                              )
                          })
                          .or(zod.string())
                      )
                      .describe(
                        "Specific vocabulary list to feed the transcription model with. Each item can be a string or an object with the following properties: value, intensity, pronunciations, language."
                      ),
                    default_intensity: zod
                      .number()
                      .min(
                        streamingControllerGetStreamingJobsV2ResponseItemsItemRequestParamsRealtimeProcessingCustomVocabularyConfigDefaultIntensityMin
                      )
                      .max(
                        streamingControllerGetStreamingJobsV2ResponseItemsItemRequestParamsRealtimeProcessingCustomVocabularyConfigDefaultIntensityMax
                      )
                      .optional()
                      .describe("Default intensity for the custom vocabulary")
                  })
                  .optional()
                  .describe("Custom vocabulary configuration, if `custom_vocabulary` is enabled"),
                custom_spelling: zod
                  .boolean()
                  .optional()
                  .describe("If true, enable custom spelling for the transcription."),
                custom_spelling_config: zod
                  .object({
                    spelling_dictionary: zod
                      .record(zod.string(), zod.array(zod.string()))
                      .describe("The list of spelling applied on the audio transcription")
                  })
                  .optional()
                  .describe("Custom spelling configuration, if `custom_spelling` is enabled"),
                translation: zod
                  .boolean()
                  .optional()
                  .describe("If true, enable translation for the transcription"),
                translation_config: zod
                  .object({
                    target_languages: zod
                      .array(
                        zod
                          .enum([
                            "af",
                            "am",
                            "ar",
                            "as",
                            "az",
                            "ba",
                            "be",
                            "bg",
                            "bn",
                            "bo",
                            "br",
                            "bs",
                            "ca",
                            "cs",
                            "cy",
                            "da",
                            "de",
                            "el",
                            "en",
                            "es",
                            "et",
                            "eu",
                            "fa",
                            "fi",
                            "fo",
                            "fr",
                            "gl",
                            "gu",
                            "ha",
                            "haw",
                            "he",
                            "hi",
                            "hr",
                            "ht",
                            "hu",
                            "hy",
                            "id",
                            "is",
                            "it",
                            "ja",
                            "jw",
                            "ka",
                            "kk",
                            "km",
                            "kn",
                            "ko",
                            "la",
                            "lb",
                            "ln",
                            "lo",
                            "lt",
                            "lv",
                            "mg",
                            "mi",
                            "mk",
                            "ml",
                            "mn",
                            "mr",
                            "ms",
                            "mt",
                            "my",
                            "ne",
                            "nl",
                            "nn",
                            "no",
                            "oc",
                            "pa",
                            "pl",
                            "ps",
                            "pt",
                            "ro",
                            "ru",
                            "sa",
                            "sd",
                            "si",
                            "sk",
                            "sl",
                            "sn",
                            "so",
                            "sq",
                            "sr",
                            "su",
                            "sv",
                            "sw",
                            "ta",
                            "te",
                            "tg",
                            "th",
                            "tk",
                            "tl",
                            "tr",
                            "tt",
                            "uk",
                            "ur",
                            "uz",
                            "vi",
                            "wo",
                            "yi",
                            "yo",
                            "zh"
                          ])
                          .describe(
                            "Target language in `iso639-1` format you want the transcription translated to"
                          )
                      )
                      .min(1)
                      .describe(
                        "Target language in `iso639-1` format you want the transcription translated to"
                      ),
                    model: zod
                      .enum(["base", "enhanced"])
                      .describe("Model you want the translation model to use to translate")
                      .default(
                        streamingControllerGetStreamingJobsV2ResponseItemsItemRequestParamsRealtimeProcessingTranslationConfigModelDefault
                      )
                      .describe("Model you want the translation model to use to translate"),
                    match_original_utterances: zod
                      .boolean()
                      .default(
                        streamingControllerGetStreamingJobsV2ResponseItemsItemRequestParamsRealtimeProcessingTranslationConfigMatchOriginalUtterancesDefault
                      )
                      .describe("Align translated utterances with the original ones"),
                    lipsync: zod
                      .boolean()
                      .default(
                        streamingControllerGetStreamingJobsV2ResponseItemsItemRequestParamsRealtimeProcessingTranslationConfigLipsyncDefault
                      )
                      .describe("Whether to apply lipsync to the translated transcription. "),
                    context_adaptation: zod
                      .boolean()
                      .default(
                        streamingControllerGetStreamingJobsV2ResponseItemsItemRequestParamsRealtimeProcessingTranslationConfigContextAdaptationDefault
                      )
                      .describe(
                        "Enables or disables context-aware translation features that allow the model to adapt translations based on provided context."
                      ),
                    context: zod
                      .string()
                      .optional()
                      .describe("Context information to improve translation accuracy"),
                    informal: zod
                      .boolean()
                      .optional()
                      .describe(
                        "Forces the translation to use informal language forms when available in the target language."
                      )
                  })
                  .optional()
                  .describe("Translation configuration, if `translation` is enabled"),
                named_entity_recognition: zod
                  .boolean()
                  .optional()
                  .describe("If true, enable named entity recognition for the transcription."),
                sentiment_analysis: zod
                  .boolean()
                  .optional()
                  .describe("If true, enable sentiment analysis for the transcription.")
              })
              .optional()
              .describe("Specify the realtime processing configuration"),
            post_processing: zod
              .object({
                summarization: zod
                  .boolean()
                  .optional()
                  .describe("If true, generates summarization for the whole transcription."),
                summarization_config: zod
                  .object({
                    type: zod
                      .enum(["general", "bullet_points", "concise"])
                      .describe("The type of summarization to apply")
                      .default(
                        streamingControllerGetStreamingJobsV2ResponseItemsItemRequestParamsPostProcessingSummarizationConfigTypeDefault
                      )
                      .describe("The type of summarization to apply")
                  })
                  .optional()
                  .describe("Summarization configuration, if `summarization` is enabled"),
                chapterization: zod
                  .boolean()
                  .optional()
                  .describe("If true, generates chapters for the whole transcription.")
              })
              .optional()
              .describe("Specify the post-processing configuration"),
            messages_config: zod
              .object({
                receive_partial_transcripts: zod
                  .boolean()
                  .optional()
                  .describe("If true, partial transcript will be sent to websocket."),
                receive_final_transcripts: zod
                  .boolean()
                  .default(
                    streamingControllerGetStreamingJobsV2ResponseItemsItemRequestParamsMessagesConfigReceiveFinalTranscriptsDefault
                  )
                  .describe("If true, final transcript will be sent to websocket."),
                receive_speech_events: zod
                  .boolean()
                  .default(
                    streamingControllerGetStreamingJobsV2ResponseItemsItemRequestParamsMessagesConfigReceiveSpeechEventsDefault
                  )
                  .describe("If true, begin and end speech events will be sent to websocket."),
                receive_pre_processing_events: zod
                  .boolean()
                  .default(
                    streamingControllerGetStreamingJobsV2ResponseItemsItemRequestParamsMessagesConfigReceivePreProcessingEventsDefault
                  )
                  .describe("If true, pre-processing events will be sent to websocket."),
                receive_realtime_processing_events: zod
                  .boolean()
                  .default(
                    streamingControllerGetStreamingJobsV2ResponseItemsItemRequestParamsMessagesConfigReceiveRealtimeProcessingEventsDefault
                  )
                  .describe("If true, realtime processing events will be sent to websocket."),
                receive_post_processing_events: zod
                  .boolean()
                  .default(
                    streamingControllerGetStreamingJobsV2ResponseItemsItemRequestParamsMessagesConfigReceivePostProcessingEventsDefault
                  )
                  .describe("If true, post-processing events will be sent to websocket."),
                receive_acknowledgments: zod
                  .boolean()
                  .default(
                    streamingControllerGetStreamingJobsV2ResponseItemsItemRequestParamsMessagesConfigReceiveAcknowledgmentsDefault
                  )
                  .describe("If true, acknowledgments will be sent to websocket."),
                receive_errors: zod
                  .boolean()
                  .default(
                    streamingControllerGetStreamingJobsV2ResponseItemsItemRequestParamsMessagesConfigReceiveErrorsDefault
                  )
                  .describe("If true, errors will be sent to websocket."),
                receive_lifecycle_events: zod
                  .boolean()
                  .optional()
                  .describe("If true, lifecycle events will be sent to websocket.")
              })
              .optional()
              .describe("Specify the websocket messages configuration"),
            callback: zod
              .boolean()
              .optional()
              .describe("If true, messages will be sent to configured url."),
            callback_config: zod
              .object({
                url: zod
                  .string()
                  .url()
                  .optional()
                  .describe("URL on which we will do a `POST` request with configured messages"),
                receive_partial_transcripts: zod
                  .boolean()
                  .optional()
                  .describe("If true, partial transcript will be sent to the defined callback."),
                receive_final_transcripts: zod
                  .boolean()
                  .default(
                    streamingControllerGetStreamingJobsV2ResponseItemsItemRequestParamsCallbackConfigReceiveFinalTranscriptsDefault
                  )
                  .describe("If true, final transcript will be sent to the defined callback."),
                receive_speech_events: zod
                  .boolean()
                  .optional()
                  .describe(
                    "If true, begin and end speech events will be sent to the defined callback."
                  ),
                receive_pre_processing_events: zod
                  .boolean()
                  .default(
                    streamingControllerGetStreamingJobsV2ResponseItemsItemRequestParamsCallbackConfigReceivePreProcessingEventsDefault
                  )
                  .describe("If true, pre-processing events will be sent to the defined callback."),
                receive_realtime_processing_events: zod
                  .boolean()
                  .default(
                    streamingControllerGetStreamingJobsV2ResponseItemsItemRequestParamsCallbackConfigReceiveRealtimeProcessingEventsDefault
                  )
                  .describe(
                    "If true, realtime processing events will be sent to the defined callback."
                  ),
                receive_post_processing_events: zod
                  .boolean()
                  .default(
                    streamingControllerGetStreamingJobsV2ResponseItemsItemRequestParamsCallbackConfigReceivePostProcessingEventsDefault
                  )
                  .describe(
                    "If true, post-processing events will be sent to the defined callback."
                  ),
                receive_acknowledgments: zod
                  .boolean()
                  .optional()
                  .describe("If true, acknowledgments will be sent to the defined callback."),
                receive_errors: zod
                  .boolean()
                  .optional()
                  .describe("If true, errors will be sent to the defined callback."),
                receive_lifecycle_events: zod
                  .boolean()
                  .default(
                    streamingControllerGetStreamingJobsV2ResponseItemsItemRequestParamsCallbackConfigReceiveLifecycleEventsDefault
                  )
                  .describe("If true, lifecycle events will be sent to the defined callback.")
              })
              .optional()
              .describe("Specify the callback configuration")
          })
          .nullish()
          .describe(
            'Parameters used for this live transcription. Can be null if status is \"error\"'
          ),
        result: zod
          .object({
            metadata: zod
              .object({
                audio_duration: zod.number().describe("Duration of the transcribed audio file"),
                number_of_distinct_channels: zod
                  .number()
                  .min(1)
                  .describe("Number of distinct channels in the transcribed audio file"),
                billing_time: zod
                  .number()
                  .describe(
                    "Billed duration in seconds (audio_duration * number_of_distinct_channels)"
                  ),
                transcription_time: zod
                  .number()
                  .describe("Duration of the transcription in seconds")
              })
              .describe("Metadata for the given transcription & audio file"),
            transcription: zod
              .object({
                full_transcript: zod
                  .string()
                  .describe("All transcription on text format without any other information"),
                languages: zod
                  .array(
                    zod
                      .enum([
                        "af",
                        "am",
                        "ar",
                        "as",
                        "az",
                        "ba",
                        "be",
                        "bg",
                        "bn",
                        "bo",
                        "br",
                        "bs",
                        "ca",
                        "cs",
                        "cy",
                        "da",
                        "de",
                        "el",
                        "en",
                        "es",
                        "et",
                        "eu",
                        "fa",
                        "fi",
                        "fo",
                        "fr",
                        "gl",
                        "gu",
                        "ha",
                        "haw",
                        "he",
                        "hi",
                        "hr",
                        "ht",
                        "hu",
                        "hy",
                        "id",
                        "is",
                        "it",
                        "ja",
                        "jw",
                        "ka",
                        "kk",
                        "km",
                        "kn",
                        "ko",
                        "la",
                        "lb",
                        "ln",
                        "lo",
                        "lt",
                        "lv",
                        "mg",
                        "mi",
                        "mk",
                        "ml",
                        "mn",
                        "mr",
                        "ms",
                        "mt",
                        "my",
                        "ne",
                        "nl",
                        "nn",
                        "no",
                        "oc",
                        "pa",
                        "pl",
                        "ps",
                        "pt",
                        "ro",
                        "ru",
                        "sa",
                        "sd",
                        "si",
                        "sk",
                        "sl",
                        "sn",
                        "so",
                        "sq",
                        "sr",
                        "su",
                        "sv",
                        "sw",
                        "ta",
                        "te",
                        "tg",
                        "th",
                        "tk",
                        "tl",
                        "tr",
                        "tt",
                        "uk",
                        "ur",
                        "uz",
                        "vi",
                        "yi",
                        "yo",
                        "zh"
                      ])
                      .describe(
                        "Specify the language in which it will be pronounced when sound comparison occurs. Default to transcription language."
                      )
                  )
                  .describe(
                    "All the detected languages in the audio sorted from the most detected to the less detected"
                  ),
                sentences: zod
                  .array(
                    zod.object({
                      success: zod
                        .boolean()
                        .describe("The audio intelligence model succeeded to get a valid output"),
                      is_empty: zod
                        .boolean()
                        .describe("The audio intelligence model returned an empty value"),
                      exec_time: zod
                        .number()
                        .describe("Time audio intelligence model took to complete the task"),
                      error: zod
                        .object({
                          status_code: zod.number().describe("Status code of the addon error"),
                          exception: zod.string().describe("Reason of the addon error"),
                          message: zod.string().describe("Detailed message of the addon error")
                        })
                        .nullable()
                        .describe(
                          "`null` if `success` is `true`. Contains the error details of the failed model"
                        ),
                      results: zod
                        .array(zod.string())
                        .nullable()
                        .describe("If `sentences` has been enabled, transcription as sentences.")
                    })
                  )
                  .optional()
                  .describe("If `sentences` has been enabled, sentences results"),
                subtitles: zod
                  .array(
                    zod.object({
                      format: zod
                        .enum(["srt", "vtt"])
                        .describe(
                          "Subtitles formats you want your transcription to be formatted to"
                        )
                        .describe("Format of the current subtitle"),
                      subtitles: zod.string().describe("Transcription on the asked subtitle format")
                    })
                  )
                  .optional()
                  .describe("If `subtitles` has been enabled, subtitles results"),
                utterances: zod
                  .array(
                    zod.object({
                      start: zod.number().describe("Start timestamp in seconds of this utterance"),
                      end: zod.number().describe("End timestamp in seconds of this utterance"),
                      confidence: zod
                        .number()
                        .describe("Confidence on the transcribed utterance (1 = 100% confident)"),
                      channel: zod
                        .number()
                        .min(
                          streamingControllerGetStreamingJobsV2ResponseItemsItemResultTranscriptionUtterancesItemChannelMin
                        )
                        .describe(
                          "Audio channel of where this utterance has been transcribed from"
                        ),
                      speaker: zod
                        .number()
                        .min(
                          streamingControllerGetStreamingJobsV2ResponseItemsItemResultTranscriptionUtterancesItemSpeakerMin
                        )
                        .optional()
                        .describe("If `diarization` enabled, speaker identification number"),
                      words: zod
                        .array(
                          zod.object({
                            word: zod.string().describe("Spoken word"),
                            start: zod
                              .number()
                              .describe("Start timestamps in seconds of the spoken word"),
                            end: zod
                              .number()
                              .describe("End timestamps in seconds of the spoken word"),
                            confidence: zod
                              .number()
                              .describe("Confidence on the transcribed word (1 = 100% confident)")
                          })
                        )
                        .describe("List of words of the utterance, split by timestamp"),
                      text: zod.string().describe("Transcription for this utterance"),
                      language: zod
                        .enum([
                          "af",
                          "am",
                          "ar",
                          "as",
                          "az",
                          "ba",
                          "be",
                          "bg",
                          "bn",
                          "bo",
                          "br",
                          "bs",
                          "ca",
                          "cs",
                          "cy",
                          "da",
                          "de",
                          "el",
                          "en",
                          "es",
                          "et",
                          "eu",
                          "fa",
                          "fi",
                          "fo",
                          "fr",
                          "gl",
                          "gu",
                          "ha",
                          "haw",
                          "he",
                          "hi",
                          "hr",
                          "ht",
                          "hu",
                          "hy",
                          "id",
                          "is",
                          "it",
                          "ja",
                          "jw",
                          "ka",
                          "kk",
                          "km",
                          "kn",
                          "ko",
                          "la",
                          "lb",
                          "ln",
                          "lo",
                          "lt",
                          "lv",
                          "mg",
                          "mi",
                          "mk",
                          "ml",
                          "mn",
                          "mr",
                          "ms",
                          "mt",
                          "my",
                          "ne",
                          "nl",
                          "nn",
                          "no",
                          "oc",
                          "pa",
                          "pl",
                          "ps",
                          "pt",
                          "ro",
                          "ru",
                          "sa",
                          "sd",
                          "si",
                          "sk",
                          "sl",
                          "sn",
                          "so",
                          "sq",
                          "sr",
                          "su",
                          "sv",
                          "sw",
                          "ta",
                          "te",
                          "tg",
                          "th",
                          "tk",
                          "tl",
                          "tr",
                          "tt",
                          "uk",
                          "ur",
                          "uz",
                          "vi",
                          "yi",
                          "yo",
                          "zh"
                        ])
                        .describe(
                          "Specify the language in which it will be pronounced when sound comparison occurs. Default to transcription language."
                        )
                        .describe("Spoken language in this utterance")
                    })
                  )
                  .describe("Transcribed speech utterances present in the audio")
              })
              .optional()
              .describe("Transcription of the audio speech"),
            translation: zod
              .object({
                success: zod
                  .boolean()
                  .describe("The audio intelligence model succeeded to get a valid output"),
                is_empty: zod
                  .boolean()
                  .describe("The audio intelligence model returned an empty value"),
                exec_time: zod
                  .number()
                  .describe("Time audio intelligence model took to complete the task"),
                error: zod
                  .object({
                    status_code: zod.number().describe("Status code of the addon error"),
                    exception: zod.string().describe("Reason of the addon error"),
                    message: zod.string().describe("Detailed message of the addon error")
                  })
                  .nullable()
                  .describe(
                    "`null` if `success` is `true`. Contains the error details of the failed model"
                  ),
                results: zod
                  .array(
                    zod.object({
                      error: zod
                        .object({
                          status_code: zod.number().describe("Status code of the addon error"),
                          exception: zod.string().describe("Reason of the addon error"),
                          message: zod.string().describe("Detailed message of the addon error")
                        })
                        .nullable()
                        .describe("Contains the error details of the failed addon"),
                      full_transcript: zod
                        .string()
                        .describe("All transcription on text format without any other information"),
                      languages: zod
                        .array(
                          zod
                            .enum([
                              "af",
                              "am",
                              "ar",
                              "as",
                              "az",
                              "ba",
                              "be",
                              "bg",
                              "bn",
                              "bo",
                              "br",
                              "bs",
                              "ca",
                              "cs",
                              "cy",
                              "da",
                              "de",
                              "el",
                              "en",
                              "es",
                              "et",
                              "eu",
                              "fa",
                              "fi",
                              "fo",
                              "fr",
                              "gl",
                              "gu",
                              "ha",
                              "haw",
                              "he",
                              "hi",
                              "hr",
                              "ht",
                              "hu",
                              "hy",
                              "id",
                              "is",
                              "it",
                              "ja",
                              "jw",
                              "ka",
                              "kk",
                              "km",
                              "kn",
                              "ko",
                              "la",
                              "lb",
                              "ln",
                              "lo",
                              "lt",
                              "lv",
                              "mg",
                              "mi",
                              "mk",
                              "ml",
                              "mn",
                              "mr",
                              "ms",
                              "mt",
                              "my",
                              "ne",
                              "nl",
                              "nn",
                              "no",
                              "oc",
                              "pa",
                              "pl",
                              "ps",
                              "pt",
                              "ro",
                              "ru",
                              "sa",
                              "sd",
                              "si",
                              "sk",
                              "sl",
                              "sn",
                              "so",
                              "sq",
                              "sr",
                              "su",
                              "sv",
                              "sw",
                              "ta",
                              "te",
                              "tg",
                              "th",
                              "tk",
                              "tl",
                              "tr",
                              "tt",
                              "uk",
                              "ur",
                              "uz",
                              "vi",
                              "wo",
                              "yi",
                              "yo",
                              "zh"
                            ])
                            .describe(
                              "Target language in `iso639-1` format you want the transcription translated to"
                            )
                        )
                        .describe(
                          "All the detected languages in the audio sorted from the most detected to the less detected"
                        ),
                      sentences: zod
                        .array(
                          zod.object({
                            success: zod
                              .boolean()
                              .describe(
                                "The audio intelligence model succeeded to get a valid output"
                              ),
                            is_empty: zod
                              .boolean()
                              .describe("The audio intelligence model returned an empty value"),
                            exec_time: zod
                              .number()
                              .describe("Time audio intelligence model took to complete the task"),
                            error: zod
                              .object({
                                status_code: zod
                                  .number()
                                  .describe("Status code of the addon error"),
                                exception: zod.string().describe("Reason of the addon error"),
                                message: zod
                                  .string()
                                  .describe("Detailed message of the addon error")
                              })
                              .nullable()
                              .describe(
                                "`null` if `success` is `true`. Contains the error details of the failed model"
                              ),
                            results: zod
                              .array(zod.string())
                              .nullable()
                              .describe(
                                "If `sentences` has been enabled, transcription as sentences."
                              )
                          })
                        )
                        .optional()
                        .describe(
                          "If `sentences` has been enabled, sentences results for this translation"
                        ),
                      subtitles: zod
                        .array(
                          zod.object({
                            format: zod
                              .enum(["srt", "vtt"])
                              .describe(
                                "Subtitles formats you want your transcription to be formatted to"
                              )
                              .describe("Format of the current subtitle"),
                            subtitles: zod
                              .string()
                              .describe("Transcription on the asked subtitle format")
                          })
                        )
                        .optional()
                        .describe(
                          "If `subtitles` has been enabled, subtitles results for this translation"
                        ),
                      utterances: zod
                        .array(
                          zod.object({
                            start: zod
                              .number()
                              .describe("Start timestamp in seconds of this utterance"),
                            end: zod
                              .number()
                              .describe("End timestamp in seconds of this utterance"),
                            confidence: zod
                              .number()
                              .describe(
                                "Confidence on the transcribed utterance (1 = 100% confident)"
                              ),
                            channel: zod
                              .number()
                              .min(
                                streamingControllerGetStreamingJobsV2ResponseItemsItemResultTranslationResultsItemUtterancesItemChannelMin
                              )
                              .describe(
                                "Audio channel of where this utterance has been transcribed from"
                              ),
                            speaker: zod
                              .number()
                              .min(
                                streamingControllerGetStreamingJobsV2ResponseItemsItemResultTranslationResultsItemUtterancesItemSpeakerMin
                              )
                              .optional()
                              .describe("If `diarization` enabled, speaker identification number"),
                            words: zod
                              .array(
                                zod.object({
                                  word: zod.string().describe("Spoken word"),
                                  start: zod
                                    .number()
                                    .describe("Start timestamps in seconds of the spoken word"),
                                  end: zod
                                    .number()
                                    .describe("End timestamps in seconds of the spoken word"),
                                  confidence: zod
                                    .number()
                                    .describe(
                                      "Confidence on the transcribed word (1 = 100% confident)"
                                    )
                                })
                              )
                              .describe("List of words of the utterance, split by timestamp"),
                            text: zod.string().describe("Transcription for this utterance"),
                            language: zod
                              .enum([
                                "af",
                                "am",
                                "ar",
                                "as",
                                "az",
                                "ba",
                                "be",
                                "bg",
                                "bn",
                                "bo",
                                "br",
                                "bs",
                                "ca",
                                "cs",
                                "cy",
                                "da",
                                "de",
                                "el",
                                "en",
                                "es",
                                "et",
                                "eu",
                                "fa",
                                "fi",
                                "fo",
                                "fr",
                                "gl",
                                "gu",
                                "ha",
                                "haw",
                                "he",
                                "hi",
                                "hr",
                                "ht",
                                "hu",
                                "hy",
                                "id",
                                "is",
                                "it",
                                "ja",
                                "jw",
                                "ka",
                                "kk",
                                "km",
                                "kn",
                                "ko",
                                "la",
                                "lb",
                                "ln",
                                "lo",
                                "lt",
                                "lv",
                                "mg",
                                "mi",
                                "mk",
                                "ml",
                                "mn",
                                "mr",
                                "ms",
                                "mt",
                                "my",
                                "ne",
                                "nl",
                                "nn",
                                "no",
                                "oc",
                                "pa",
                                "pl",
                                "ps",
                                "pt",
                                "ro",
                                "ru",
                                "sa",
                                "sd",
                                "si",
                                "sk",
                                "sl",
                                "sn",
                                "so",
                                "sq",
                                "sr",
                                "su",
                                "sv",
                                "sw",
                                "ta",
                                "te",
                                "tg",
                                "th",
                                "tk",
                                "tl",
                                "tr",
                                "tt",
                                "uk",
                                "ur",
                                "uz",
                                "vi",
                                "yi",
                                "yo",
                                "zh"
                              ])
                              .describe(
                                "Specify the language in which it will be pronounced when sound comparison occurs. Default to transcription language."
                              )
                              .describe("Spoken language in this utterance")
                          })
                        )
                        .describe("Transcribed speech utterances present in the audio")
                    })
                  )
                  .nullable()
                  .describe("List of translated transcriptions, one for each `target_languages`")
              })
              .optional()
              .describe(
                "If `translation` has been enabled, translation of the audio speech transcription"
              ),
            summarization: zod
              .object({
                success: zod
                  .boolean()
                  .describe("The audio intelligence model succeeded to get a valid output"),
                is_empty: zod
                  .boolean()
                  .describe("The audio intelligence model returned an empty value"),
                exec_time: zod
                  .number()
                  .describe("Time audio intelligence model took to complete the task"),
                error: zod
                  .object({
                    status_code: zod.number().describe("Status code of the addon error"),
                    exception: zod.string().describe("Reason of the addon error"),
                    message: zod.string().describe("Detailed message of the addon error")
                  })
                  .nullable()
                  .describe(
                    "`null` if `success` is `true`. Contains the error details of the failed model"
                  ),
                results: zod
                  .string()
                  .nullable()
                  .describe("If `summarization` has been enabled, summary of the transcription")
              })
              .optional()
              .describe(
                "If `summarization` has been enabled, summarization of the audio speech transcription"
              ),
            named_entity_recognition: zod
              .object({
                success: zod
                  .boolean()
                  .describe("The audio intelligence model succeeded to get a valid output"),
                is_empty: zod
                  .boolean()
                  .describe("The audio intelligence model returned an empty value"),
                exec_time: zod
                  .number()
                  .describe("Time audio intelligence model took to complete the task"),
                error: zod
                  .object({
                    status_code: zod.number().describe("Status code of the addon error"),
                    exception: zod.string().describe("Reason of the addon error"),
                    message: zod.string().describe("Detailed message of the addon error")
                  })
                  .nullable()
                  .describe(
                    "`null` if `success` is `true`. Contains the error details of the failed model"
                  ),
                entity: zod
                  .string()
                  .describe(
                    "If `named_entity_recognition` has been enabled, the detected entities."
                  )
              })
              .optional()
              .describe("If `named_entity_recognition` has been enabled, the detected entities"),
            sentiment_analysis: zod
              .object({
                success: zod
                  .boolean()
                  .describe("The audio intelligence model succeeded to get a valid output"),
                is_empty: zod
                  .boolean()
                  .describe("The audio intelligence model returned an empty value"),
                exec_time: zod
                  .number()
                  .describe("Time audio intelligence model took to complete the task"),
                error: zod
                  .object({
                    status_code: zod.number().describe("Status code of the addon error"),
                    exception: zod.string().describe("Reason of the addon error"),
                    message: zod.string().describe("Detailed message of the addon error")
                  })
                  .nullable()
                  .describe(
                    "`null` if `success` is `true`. Contains the error details of the failed model"
                  ),
                results: zod
                  .string()
                  .describe(
                    "If `sentiment_analysis` has been enabled, Gladia will analyze the sentiments and emotions of the audio"
                  )
              })
              .optional()
              .describe(
                "If `sentiment_analysis` has been enabled, sentiment analysis of the audio speech transcription"
              ),
            chapterization: zod
              .object({
                success: zod
                  .boolean()
                  .describe("The audio intelligence model succeeded to get a valid output"),
                is_empty: zod
                  .boolean()
                  .describe("The audio intelligence model returned an empty value"),
                exec_time: zod
                  .number()
                  .describe("Time audio intelligence model took to complete the task"),
                error: zod
                  .object({
                    status_code: zod.number().describe("Status code of the addon error"),
                    exception: zod.string().describe("Reason of the addon error"),
                    message: zod.string().describe("Detailed message of the addon error")
                  })
                  .nullable()
                  .describe(
                    "`null` if `success` is `true`. Contains the error details of the failed model"
                  ),
                results: zod
                  .record(zod.string(), zod.any())
                  .describe(
                    "If `chapterization` has been enabled, will generate chapters name for different parts of the given audio."
                  )
              })
              .optional()
              .describe(
                "If `chapterization` has been enabled, will generate chapters name for different parts of the given audio."
              ),
            messages: zod
              .array(zod.string())
              .optional()
              .describe("Real-Time messages sent by the server during the live transcription")
          })
          .nullish()
          .describe('Live transcription\'s result when status is \"done\"')
      })
    )
    .describe("List of live transcriptions")
})

/**
 * @summary Get the live job's metadata
 */
export const streamingControllerGetStreamingJobV2Params = zod.object({
  id: zod.string().describe("Id of the live job")
})

export const streamingControllerGetStreamingJobV2ResponseErrorCodeMin = 400

export const streamingControllerGetStreamingJobV2ResponseErrorCodeMax = 599
export const streamingControllerGetStreamingJobV2ResponseKindDefault = "live"
export const streamingControllerGetStreamingJobV2ResponseRequestParamsEncodingDefault = "wav/pcm"
export const streamingControllerGetStreamingJobV2ResponseRequestParamsBitDepthDefault = 16
export const streamingControllerGetStreamingJobV2ResponseRequestParamsSampleRateDefault = 16000
export const streamingControllerGetStreamingJobV2ResponseRequestParamsChannelsDefault = 1
export const streamingControllerGetStreamingJobV2ResponseRequestParamsChannelsMax = 8
export const streamingControllerGetStreamingJobV2ResponseRequestParamsModelDefault = "solaria-1"
export const streamingControllerGetStreamingJobV2ResponseRequestParamsEndpointingDefault = 0.05
export const streamingControllerGetStreamingJobV2ResponseRequestParamsEndpointingMin = 0.01

export const streamingControllerGetStreamingJobV2ResponseRequestParamsEndpointingMax = 10
export const streamingControllerGetStreamingJobV2ResponseRequestParamsMaximumDurationWithoutEndpointingDefault = 5
export const streamingControllerGetStreamingJobV2ResponseRequestParamsMaximumDurationWithoutEndpointingMin = 5

export const streamingControllerGetStreamingJobV2ResponseRequestParamsMaximumDurationWithoutEndpointingMax = 60
export const streamingControllerGetStreamingJobV2ResponseRequestParamsLanguageConfigLanguagesDefault =
  []
export const streamingControllerGetStreamingJobV2ResponseRequestParamsLanguageConfigCodeSwitchingDefault = false
export const streamingControllerGetStreamingJobV2ResponseRequestParamsPreProcessingAudioEnhancerDefault = false
export const streamingControllerGetStreamingJobV2ResponseRequestParamsPreProcessingSpeechThresholdDefault = 0.6
export const streamingControllerGetStreamingJobV2ResponseRequestParamsPreProcessingSpeechThresholdMin = 0

export const streamingControllerGetStreamingJobV2ResponseRequestParamsPreProcessingSpeechThresholdMax = 1
export const streamingControllerGetStreamingJobV2ResponseRequestParamsRealtimeProcessingCustomVocabularyDefault = false
export const streamingControllerGetStreamingJobV2ResponseRequestParamsRealtimeProcessingCustomVocabularyConfigVocabularyItemIntensityMin = 0

export const streamingControllerGetStreamingJobV2ResponseRequestParamsRealtimeProcessingCustomVocabularyConfigVocabularyItemIntensityMax = 1
export const streamingControllerGetStreamingJobV2ResponseRequestParamsRealtimeProcessingCustomVocabularyConfigDefaultIntensityMin = 0

export const streamingControllerGetStreamingJobV2ResponseRequestParamsRealtimeProcessingCustomVocabularyConfigDefaultIntensityMax = 1
export const streamingControllerGetStreamingJobV2ResponseRequestParamsRealtimeProcessingCustomSpellingDefault = false
export const streamingControllerGetStreamingJobV2ResponseRequestParamsRealtimeProcessingTranslationDefault = false
export const streamingControllerGetStreamingJobV2ResponseRequestParamsRealtimeProcessingTranslationConfigModelDefault =
  "base"
export const streamingControllerGetStreamingJobV2ResponseRequestParamsRealtimeProcessingTranslationConfigMatchOriginalUtterancesDefault = true
export const streamingControllerGetStreamingJobV2ResponseRequestParamsRealtimeProcessingTranslationConfigLipsyncDefault = true
export const streamingControllerGetStreamingJobV2ResponseRequestParamsRealtimeProcessingTranslationConfigContextAdaptationDefault = true
export const streamingControllerGetStreamingJobV2ResponseRequestParamsRealtimeProcessingTranslationConfigInformalDefault = false
export const streamingControllerGetStreamingJobV2ResponseRequestParamsRealtimeProcessingNamedEntityRecognitionDefault = false
export const streamingControllerGetStreamingJobV2ResponseRequestParamsRealtimeProcessingSentimentAnalysisDefault = false
export const streamingControllerGetStreamingJobV2ResponseRequestParamsPostProcessingSummarizationDefault = false
export const streamingControllerGetStreamingJobV2ResponseRequestParamsPostProcessingSummarizationConfigTypeDefault =
  "general"
export const streamingControllerGetStreamingJobV2ResponseRequestParamsPostProcessingChapterizationDefault = false
export const streamingControllerGetStreamingJobV2ResponseRequestParamsMessagesConfigReceivePartialTranscriptsDefault = false
export const streamingControllerGetStreamingJobV2ResponseRequestParamsMessagesConfigReceiveFinalTranscriptsDefault = true
export const streamingControllerGetStreamingJobV2ResponseRequestParamsMessagesConfigReceiveSpeechEventsDefault = true
export const streamingControllerGetStreamingJobV2ResponseRequestParamsMessagesConfigReceivePreProcessingEventsDefault = true
export const streamingControllerGetStreamingJobV2ResponseRequestParamsMessagesConfigReceiveRealtimeProcessingEventsDefault = true
export const streamingControllerGetStreamingJobV2ResponseRequestParamsMessagesConfigReceivePostProcessingEventsDefault = true
export const streamingControllerGetStreamingJobV2ResponseRequestParamsMessagesConfigReceiveAcknowledgmentsDefault = true
export const streamingControllerGetStreamingJobV2ResponseRequestParamsMessagesConfigReceiveErrorsDefault = true
export const streamingControllerGetStreamingJobV2ResponseRequestParamsMessagesConfigReceiveLifecycleEventsDefault = false
export const streamingControllerGetStreamingJobV2ResponseRequestParamsCallbackDefault = false
export const streamingControllerGetStreamingJobV2ResponseRequestParamsCallbackConfigReceivePartialTranscriptsDefault = false
export const streamingControllerGetStreamingJobV2ResponseRequestParamsCallbackConfigReceiveFinalTranscriptsDefault = true
export const streamingControllerGetStreamingJobV2ResponseRequestParamsCallbackConfigReceiveSpeechEventsDefault = false
export const streamingControllerGetStreamingJobV2ResponseRequestParamsCallbackConfigReceivePreProcessingEventsDefault = true
export const streamingControllerGetStreamingJobV2ResponseRequestParamsCallbackConfigReceiveRealtimeProcessingEventsDefault = true
export const streamingControllerGetStreamingJobV2ResponseRequestParamsCallbackConfigReceivePostProcessingEventsDefault = true
export const streamingControllerGetStreamingJobV2ResponseRequestParamsCallbackConfigReceiveAcknowledgmentsDefault = false
export const streamingControllerGetStreamingJobV2ResponseRequestParamsCallbackConfigReceiveErrorsDefault = false
export const streamingControllerGetStreamingJobV2ResponseRequestParamsCallbackConfigReceiveLifecycleEventsDefault = true
export const streamingControllerGetStreamingJobV2ResponseResultTranscriptionUtterancesItemChannelMin = 0
export const streamingControllerGetStreamingJobV2ResponseResultTranscriptionUtterancesItemSpeakerMin = 0
export const streamingControllerGetStreamingJobV2ResponseResultTranslationResultsItemUtterancesItemChannelMin = 0
export const streamingControllerGetStreamingJobV2ResponseResultTranslationResultsItemUtterancesItemSpeakerMin = 0

export const streamingControllerGetStreamingJobV2Response = zod.object({
  id: zod.string().uuid().describe("Id of the job"),
  request_id: zod.string().describe("Debug id"),
  version: zod.number().describe("API version"),
  status: zod
    .enum(["queued", "processing", "done", "error"])
    .describe(
      '\"queued\": the job has been queued. \"processing\": the job is being processed. \"done\": the job has been processed and the result is available. \"error\": an error occurred during the job\'s processing.'
    ),
  created_at: zod.string().datetime({}).describe("Creation date"),
  completed_at: zod
    .string()
    .datetime({})
    .nullish()
    .describe('Completion date when status is \"done\" or \"error\"'),
  custom_metadata: zod
    .record(zod.string(), zod.any())
    .optional()
    .describe("Custom metadata given in the initial request"),
  error_code: zod
    .number()
    .min(streamingControllerGetStreamingJobV2ResponseErrorCodeMin)
    .max(streamingControllerGetStreamingJobV2ResponseErrorCodeMax)
    .nullish()
    .describe('HTTP status code of the error if status is \"error\"'),
  post_session_metadata: zod
    .object({})
    .describe("For debugging purposes, send data that could help to identify issues"),
  kind: zod.enum(["live"]),
  file: zod
    .object({
      id: zod.string().describe("The file id"),
      filename: zod.string().nullable().describe("The name of the uploaded file"),
      source: zod
        .string()
        .nullable()
        .describe("The link used to download the file if audio_url was used"),
      audio_duration: zod.number().nullable().describe("Duration of the audio file"),
      number_of_channels: zod
        .number()
        .min(1)
        .nullable()
        .describe("Number of channels in the audio file")
    })
    .nullish()
    .describe('The file data you uploaded. Can be null if status is \"error\"'),
  request_params: zod
    .object({
      encoding: zod
        .enum(["wav/pcm", "wav/alaw", "wav/ulaw"])
        .describe(
          "The encoding format of the audio stream. Supported formats: \n- PCM: 8, 16, 24, and 32 bits \n- A-law: 8 bits \n- Œº-law: 8 bits \n\nNote: No need to add WAV headers to raw audio as the API supports both formats."
        )
        .default(streamingControllerGetStreamingJobV2ResponseRequestParamsEncodingDefault)
        .describe(
          "The encoding format of the audio stream. Supported formats: \n- PCM: 8, 16, 24, and 32 bits \n- A-law: 8 bits \n- Œº-law: 8 bits \n\nNote: No need to add WAV headers to raw audio as the API supports both formats."
        ),
      bit_depth: zod
        .literal(8)
        .or(zod.literal(16))
        .or(zod.literal(24))
        .or(zod.literal(32))
        .describe("The bit depth of the audio stream")
        .default(streamingControllerGetStreamingJobV2ResponseRequestParamsBitDepthDefault)
        .describe("The bit depth of the audio stream"),
      sample_rate: zod
        .literal(8000)
        .or(zod.literal(16000))
        .or(zod.literal(32000))
        .or(zod.literal(44100))
        .or(zod.literal(48000))
        .describe("The sample rate of the audio stream")
        .default(streamingControllerGetStreamingJobV2ResponseRequestParamsSampleRateDefault)
        .describe("The sample rate of the audio stream"),
      channels: zod
        .number()
        .min(1)
        .max(streamingControllerGetStreamingJobV2ResponseRequestParamsChannelsMax)
        .default(streamingControllerGetStreamingJobV2ResponseRequestParamsChannelsDefault)
        .describe("The number of channels of the audio stream"),
      model: zod
        .enum(["solaria-1"])
        .describe('The model used to process the audio. \"solaria-1\" is used by default.')
        .default(streamingControllerGetStreamingJobV2ResponseRequestParamsModelDefault)
        .describe('The model used to process the audio. \"solaria-1\" is used by default.'),
      endpointing: zod
        .number()
        .min(streamingControllerGetStreamingJobV2ResponseRequestParamsEndpointingMin)
        .max(streamingControllerGetStreamingJobV2ResponseRequestParamsEndpointingMax)
        .default(streamingControllerGetStreamingJobV2ResponseRequestParamsEndpointingDefault)
        .describe(
          "The endpointing duration in seconds. Endpointing is the duration of silence which will cause an utterance to be considered as finished"
        ),
      maximum_duration_without_endpointing: zod
        .number()
        .min(
          streamingControllerGetStreamingJobV2ResponseRequestParamsMaximumDurationWithoutEndpointingMin
        )
        .max(
          streamingControllerGetStreamingJobV2ResponseRequestParamsMaximumDurationWithoutEndpointingMax
        )
        .default(
          streamingControllerGetStreamingJobV2ResponseRequestParamsMaximumDurationWithoutEndpointingDefault
        )
        .describe(
          "The maximum duration in seconds without endpointing. If endpointing is not detected after this duration, current utterance will be considered as finished"
        ),
      language_config: zod
        .object({
          languages: zod
            .array(
              zod
                .enum([
                  "af",
                  "am",
                  "ar",
                  "as",
                  "az",
                  "ba",
                  "be",
                  "bg",
                  "bn",
                  "bo",
                  "br",
                  "bs",
                  "ca",
                  "cs",
                  "cy",
                  "da",
                  "de",
                  "el",
                  "en",
                  "es",
                  "et",
                  "eu",
                  "fa",
                  "fi",
                  "fo",
                  "fr",
                  "gl",
                  "gu",
                  "ha",
                  "haw",
                  "he",
                  "hi",
                  "hr",
                  "ht",
                  "hu",
                  "hy",
                  "id",
                  "is",
                  "it",
                  "ja",
                  "jw",
                  "ka",
                  "kk",
                  "km",
                  "kn",
                  "ko",
                  "la",
                  "lb",
                  "ln",
                  "lo",
                  "lt",
                  "lv",
                  "mg",
                  "mi",
                  "mk",
                  "ml",
                  "mn",
                  "mr",
                  "ms",
                  "mt",
                  "my",
                  "ne",
                  "nl",
                  "nn",
                  "no",
                  "oc",
                  "pa",
                  "pl",
                  "ps",
                  "pt",
                  "ro",
                  "ru",
                  "sa",
                  "sd",
                  "si",
                  "sk",
                  "sl",
                  "sn",
                  "so",
                  "sq",
                  "sr",
                  "su",
                  "sv",
                  "sw",
                  "ta",
                  "te",
                  "tg",
                  "th",
                  "tk",
                  "tl",
                  "tr",
                  "tt",
                  "uk",
                  "ur",
                  "uz",
                  "vi",
                  "yi",
                  "yo",
                  "zh"
                ])
                .describe(
                  "Specify the language in which it will be pronounced when sound comparison occurs. Default to transcription language."
                )
            )
            .default(
              streamingControllerGetStreamingJobV2ResponseRequestParamsLanguageConfigLanguagesDefault
            )
            .describe(
              "If one language is set, it will be used for the transcription. Otherwise, language will be auto-detected by the model."
            ),
          code_switching: zod
            .boolean()
            .optional()
            .describe(
              "If true, language will be auto-detected on each utterance. Otherwise, language will be auto-detected on first utterance and then used for the rest of the transcription. If one language is set, this option will be ignored."
            )
        })
        .optional()
        .describe("Specify the language configuration"),
      pre_processing: zod
        .object({
          audio_enhancer: zod
            .boolean()
            .optional()
            .describe("If true, apply pre-processing to the audio stream to enhance the quality."),
          speech_threshold: zod
            .number()
            .min(
              streamingControllerGetStreamingJobV2ResponseRequestParamsPreProcessingSpeechThresholdMin
            )
            .max(
              streamingControllerGetStreamingJobV2ResponseRequestParamsPreProcessingSpeechThresholdMax
            )
            .default(
              streamingControllerGetStreamingJobV2ResponseRequestParamsPreProcessingSpeechThresholdDefault
            )
            .describe(
              "Sensitivity configuration for Speech Threshold. A value close to 1 will apply stricter thresholds, making it less likely to detect background sounds as speech."
            )
        })
        .optional()
        .describe("Specify the pre-processing configuration"),
      realtime_processing: zod
        .object({
          custom_vocabulary: zod
            .boolean()
            .optional()
            .describe("If true, enable custom vocabulary for the transcription."),
          custom_vocabulary_config: zod
            .object({
              vocabulary: zod
                .array(
                  zod
                    .object({
                      value: zod
                        .string()
                        .describe("The text used to replace in the transcription."),
                      intensity: zod
                        .number()
                        .min(
                          streamingControllerGetStreamingJobV2ResponseRequestParamsRealtimeProcessingCustomVocabularyConfigVocabularyItemIntensityMin
                        )
                        .max(
                          streamingControllerGetStreamingJobV2ResponseRequestParamsRealtimeProcessingCustomVocabularyConfigVocabularyItemIntensityMax
                        )
                        .optional()
                        .describe("The global intensity of the feature."),
                      pronunciations: zod
                        .array(zod.string())
                        .optional()
                        .describe("The pronunciations used in the transcription."),
                      language: zod
                        .enum([
                          "af",
                          "am",
                          "ar",
                          "as",
                          "az",
                          "ba",
                          "be",
                          "bg",
                          "bn",
                          "bo",
                          "br",
                          "bs",
                          "ca",
                          "cs",
                          "cy",
                          "da",
                          "de",
                          "el",
                          "en",
                          "es",
                          "et",
                          "eu",
                          "fa",
                          "fi",
                          "fo",
                          "fr",
                          "gl",
                          "gu",
                          "ha",
                          "haw",
                          "he",
                          "hi",
                          "hr",
                          "ht",
                          "hu",
                          "hy",
                          "id",
                          "is",
                          "it",
                          "ja",
                          "jw",
                          "ka",
                          "kk",
                          "km",
                          "kn",
                          "ko",
                          "la",
                          "lb",
                          "ln",
                          "lo",
                          "lt",
                          "lv",
                          "mg",
                          "mi",
                          "mk",
                          "ml",
                          "mn",
                          "mr",
                          "ms",
                          "mt",
                          "my",
                          "ne",
                          "nl",
                          "nn",
                          "no",
                          "oc",
                          "pa",
                          "pl",
                          "ps",
                          "pt",
                          "ro",
                          "ru",
                          "sa",
                          "sd",
                          "si",
                          "sk",
                          "sl",
                          "sn",
                          "so",
                          "sq",
                          "sr",
                          "su",
                          "sv",
                          "sw",
                          "ta",
                          "te",
                          "tg",
                          "th",
                          "tk",
                          "tl",
                          "tr",
                          "tt",
                          "uk",
                          "ur",
                          "uz",
                          "vi",
                          "yi",
                          "yo",
                          "zh"
                        ])
                        .describe(
                          "Specify the language in which it will be pronounced when sound comparison occurs. Default to transcription language."
                        )
                        .optional()
                        .describe(
                          "Specify the language in which it will be pronounced when sound comparison occurs. Default to transcription language."
                        )
                    })
                    .or(zod.string())
                )
                .describe(
                  "Specific vocabulary list to feed the transcription model with. Each item can be a string or an object with the following properties: value, intensity, pronunciations, language."
                ),
              default_intensity: zod
                .number()
                .min(
                  streamingControllerGetStreamingJobV2ResponseRequestParamsRealtimeProcessingCustomVocabularyConfigDefaultIntensityMin
                )
                .max(
                  streamingControllerGetStreamingJobV2ResponseRequestParamsRealtimeProcessingCustomVocabularyConfigDefaultIntensityMax
                )
                .optional()
                .describe("Default intensity for the custom vocabulary")
            })
            .optional()
            .describe("Custom vocabulary configuration, if `custom_vocabulary` is enabled"),
          custom_spelling: zod
            .boolean()
            .optional()
            .describe("If true, enable custom spelling for the transcription."),
          custom_spelling_config: zod
            .object({
              spelling_dictionary: zod
                .record(zod.string(), zod.array(zod.string()))
                .describe("The list of spelling applied on the audio transcription")
            })
            .optional()
            .describe("Custom spelling configuration, if `custom_spelling` is enabled"),
          translation: zod
            .boolean()
            .optional()
            .describe("If true, enable translation for the transcription"),
          translation_config: zod
            .object({
              target_languages: zod
                .array(
                  zod
                    .enum([
                      "af",
                      "am",
                      "ar",
                      "as",
                      "az",
                      "ba",
                      "be",
                      "bg",
                      "bn",
                      "bo",
                      "br",
                      "bs",
                      "ca",
                      "cs",
                      "cy",
                      "da",
                      "de",
                      "el",
                      "en",
                      "es",
                      "et",
                      "eu",
                      "fa",
                      "fi",
                      "fo",
                      "fr",
                      "gl",
                      "gu",
                      "ha",
                      "haw",
                      "he",
                      "hi",
                      "hr",
                      "ht",
                      "hu",
                      "hy",
                      "id",
                      "is",
                      "it",
                      "ja",
                      "jw",
                      "ka",
                      "kk",
                      "km",
                      "kn",
                      "ko",
                      "la",
                      "lb",
                      "ln",
                      "lo",
                      "lt",
                      "lv",
                      "mg",
                      "mi",
                      "mk",
                      "ml",
                      "mn",
                      "mr",
                      "ms",
                      "mt",
                      "my",
                      "ne",
                      "nl",
                      "nn",
                      "no",
                      "oc",
                      "pa",
                      "pl",
                      "ps",
                      "pt",
                      "ro",
                      "ru",
                      "sa",
                      "sd",
                      "si",
                      "sk",
                      "sl",
                      "sn",
                      "so",
                      "sq",
                      "sr",
                      "su",
                      "sv",
                      "sw",
                      "ta",
                      "te",
                      "tg",
                      "th",
                      "tk",
                      "tl",
                      "tr",
                      "tt",
                      "uk",
                      "ur",
                      "uz",
                      "vi",
                      "wo",
                      "yi",
                      "yo",
                      "zh"
                    ])
                    .describe(
                      "Target language in `iso639-1` format you want the transcription translated to"
                    )
                )
                .min(1)
                .describe(
                  "Target language in `iso639-1` format you want the transcription translated to"
                ),
              model: zod
                .enum(["base", "enhanced"])
                .describe("Model you want the translation model to use to translate")
                .default(
                  streamingControllerGetStreamingJobV2ResponseRequestParamsRealtimeProcessingTranslationConfigModelDefault
                )
                .describe("Model you want the translation model to use to translate"),
              match_original_utterances: zod
                .boolean()
                .default(
                  streamingControllerGetStreamingJobV2ResponseRequestParamsRealtimeProcessingTranslationConfigMatchOriginalUtterancesDefault
                )
                .describe("Align translated utterances with the original ones"),
              lipsync: zod
                .boolean()
                .default(
                  streamingControllerGetStreamingJobV2ResponseRequestParamsRealtimeProcessingTranslationConfigLipsyncDefault
                )
                .describe("Whether to apply lipsync to the translated transcription. "),
              context_adaptation: zod
                .boolean()
                .default(
                  streamingControllerGetStreamingJobV2ResponseRequestParamsRealtimeProcessingTranslationConfigContextAdaptationDefault
                )
                .describe(
                  "Enables or disables context-aware translation features that allow the model to adapt translations based on provided context."
                ),
              context: zod
                .string()
                .optional()
                .describe("Context information to improve translation accuracy"),
              informal: zod
                .boolean()
                .optional()
                .describe(
                  "Forces the translation to use informal language forms when available in the target language."
                )
            })
            .optional()
            .describe("Translation configuration, if `translation` is enabled"),
          named_entity_recognition: zod
            .boolean()
            .optional()
            .describe("If true, enable named entity recognition for the transcription."),
          sentiment_analysis: zod
            .boolean()
            .optional()
            .describe("If true, enable sentiment analysis for the transcription.")
        })
        .optional()
        .describe("Specify the realtime processing configuration"),
      post_processing: zod
        .object({
          summarization: zod
            .boolean()
            .optional()
            .describe("If true, generates summarization for the whole transcription."),
          summarization_config: zod
            .object({
              type: zod
                .enum(["general", "bullet_points", "concise"])
                .describe("The type of summarization to apply")
                .default(
                  streamingControllerGetStreamingJobV2ResponseRequestParamsPostProcessingSummarizationConfigTypeDefault
                )
                .describe("The type of summarization to apply")
            })
            .optional()
            .describe("Summarization configuration, if `summarization` is enabled"),
          chapterization: zod
            .boolean()
            .optional()
            .describe("If true, generates chapters for the whole transcription.")
        })
        .optional()
        .describe("Specify the post-processing configuration"),
      messages_config: zod
        .object({
          receive_partial_transcripts: zod
            .boolean()
            .optional()
            .describe("If true, partial transcript will be sent to websocket."),
          receive_final_transcripts: zod
            .boolean()
            .default(
              streamingControllerGetStreamingJobV2ResponseRequestParamsMessagesConfigReceiveFinalTranscriptsDefault
            )
            .describe("If true, final transcript will be sent to websocket."),
          receive_speech_events: zod
            .boolean()
            .default(
              streamingControllerGetStreamingJobV2ResponseRequestParamsMessagesConfigReceiveSpeechEventsDefault
            )
            .describe("If true, begin and end speech events will be sent to websocket."),
          receive_pre_processing_events: zod
            .boolean()
            .default(
              streamingControllerGetStreamingJobV2ResponseRequestParamsMessagesConfigReceivePreProcessingEventsDefault
            )
            .describe("If true, pre-processing events will be sent to websocket."),
          receive_realtime_processing_events: zod
            .boolean()
            .default(
              streamingControllerGetStreamingJobV2ResponseRequestParamsMessagesConfigReceiveRealtimeProcessingEventsDefault
            )
            .describe("If true, realtime processing events will be sent to websocket."),
          receive_post_processing_events: zod
            .boolean()
            .default(
              streamingControllerGetStreamingJobV2ResponseRequestParamsMessagesConfigReceivePostProcessingEventsDefault
            )
            .describe("If true, post-processing events will be sent to websocket."),
          receive_acknowledgments: zod
            .boolean()
            .default(
              streamingControllerGetStreamingJobV2ResponseRequestParamsMessagesConfigReceiveAcknowledgmentsDefault
            )
            .describe("If true, acknowledgments will be sent to websocket."),
          receive_errors: zod
            .boolean()
            .default(
              streamingControllerGetStreamingJobV2ResponseRequestParamsMessagesConfigReceiveErrorsDefault
            )
            .describe("If true, errors will be sent to websocket."),
          receive_lifecycle_events: zod
            .boolean()
            .optional()
            .describe("If true, lifecycle events will be sent to websocket.")
        })
        .optional()
        .describe("Specify the websocket messages configuration"),
      callback: zod
        .boolean()
        .optional()
        .describe("If true, messages will be sent to configured url."),
      callback_config: zod
        .object({
          url: zod
            .string()
            .url()
            .optional()
            .describe("URL on which we will do a `POST` request with configured messages"),
          receive_partial_transcripts: zod
            .boolean()
            .optional()
            .describe("If true, partial transcript will be sent to the defined callback."),
          receive_final_transcripts: zod
            .boolean()
            .default(
              streamingControllerGetStreamingJobV2ResponseRequestParamsCallbackConfigReceiveFinalTranscriptsDefault
            )
            .describe("If true, final transcript will be sent to the defined callback."),
          receive_speech_events: zod
            .boolean()
            .optional()
            .describe("If true, begin and end speech events will be sent to the defined callback."),
          receive_pre_processing_events: zod
            .boolean()
            .default(
              streamingControllerGetStreamingJobV2ResponseRequestParamsCallbackConfigReceivePreProcessingEventsDefault
            )
            .describe("If true, pre-processing events will be sent to the defined callback."),
          receive_realtime_processing_events: zod
            .boolean()
            .default(
              streamingControllerGetStreamingJobV2ResponseRequestParamsCallbackConfigReceiveRealtimeProcessingEventsDefault
            )
            .describe("If true, realtime processing events will be sent to the defined callback."),
          receive_post_processing_events: zod
            .boolean()
            .default(
              streamingControllerGetStreamingJobV2ResponseRequestParamsCallbackConfigReceivePostProcessingEventsDefault
            )
            .describe("If true, post-processing events will be sent to the defined callback."),
          receive_acknowledgments: zod
            .boolean()
            .optional()
            .describe("If true, acknowledgments will be sent to the defined callback."),
          receive_errors: zod
            .boolean()
            .optional()
            .describe("If true, errors will be sent to the defined callback."),
          receive_lifecycle_events: zod
            .boolean()
            .default(
              streamingControllerGetStreamingJobV2ResponseRequestParamsCallbackConfigReceiveLifecycleEventsDefault
            )
            .describe("If true, lifecycle events will be sent to the defined callback.")
        })
        .optional()
        .describe("Specify the callback configuration")
    })
    .nullish()
    .describe('Parameters used for this live transcription. Can be null if status is \"error\"'),
  result: zod
    .object({
      metadata: zod
        .object({
          audio_duration: zod.number().describe("Duration of the transcribed audio file"),
          number_of_distinct_channels: zod
            .number()
            .min(1)
            .describe("Number of distinct channels in the transcribed audio file"),
          billing_time: zod
            .number()
            .describe("Billed duration in seconds (audio_duration * number_of_distinct_channels)"),
          transcription_time: zod.number().describe("Duration of the transcription in seconds")
        })
        .describe("Metadata for the given transcription & audio file"),
      transcription: zod
        .object({
          full_transcript: zod
            .string()
            .describe("All transcription on text format without any other information"),
          languages: zod
            .array(
              zod
                .enum([
                  "af",
                  "am",
                  "ar",
                  "as",
                  "az",
                  "ba",
                  "be",
                  "bg",
                  "bn",
                  "bo",
                  "br",
                  "bs",
                  "ca",
                  "cs",
                  "cy",
                  "da",
                  "de",
                  "el",
                  "en",
                  "es",
                  "et",
                  "eu",
                  "fa",
                  "fi",
                  "fo",
                  "fr",
                  "gl",
                  "gu",
                  "ha",
                  "haw",
                  "he",
                  "hi",
                  "hr",
                  "ht",
                  "hu",
                  "hy",
                  "id",
                  "is",
                  "it",
                  "ja",
                  "jw",
                  "ka",
                  "kk",
                  "km",
                  "kn",
                  "ko",
                  "la",
                  "lb",
                  "ln",
                  "lo",
                  "lt",
                  "lv",
                  "mg",
                  "mi",
                  "mk",
                  "ml",
                  "mn",
                  "mr",
                  "ms",
                  "mt",
                  "my",
                  "ne",
                  "nl",
                  "nn",
                  "no",
                  "oc",
                  "pa",
                  "pl",
                  "ps",
                  "pt",
                  "ro",
                  "ru",
                  "sa",
                  "sd",
                  "si",
                  "sk",
                  "sl",
                  "sn",
                  "so",
                  "sq",
                  "sr",
                  "su",
                  "sv",
                  "sw",
                  "ta",
                  "te",
                  "tg",
                  "th",
                  "tk",
                  "tl",
                  "tr",
                  "tt",
                  "uk",
                  "ur",
                  "uz",
                  "vi",
                  "yi",
                  "yo",
                  "zh"
                ])
                .describe(
                  "Specify the language in which it will be pronounced when sound comparison occurs. Default to transcription language."
                )
            )
            .describe(
              "All the detected languages in the audio sorted from the most detected to the less detected"
            ),
          sentences: zod
            .array(
              zod.object({
                success: zod
                  .boolean()
                  .describe("The audio intelligence model succeeded to get a valid output"),
                is_empty: zod
                  .boolean()
                  .describe("The audio intelligence model returned an empty value"),
                exec_time: zod
                  .number()
                  .describe("Time audio intelligence model took to complete the task"),
                error: zod
                  .object({
                    status_code: zod.number().describe("Status code of the addon error"),
                    exception: zod.string().describe("Reason of the addon error"),
                    message: zod.string().describe("Detailed message of the addon error")
                  })
                  .nullable()
                  .describe(
                    "`null` if `success` is `true`. Contains the error details of the failed model"
                  ),
                results: zod
                  .array(zod.string())
                  .nullable()
                  .describe("If `sentences` has been enabled, transcription as sentences.")
              })
            )
            .optional()
            .describe("If `sentences` has been enabled, sentences results"),
          subtitles: zod
            .array(
              zod.object({
                format: zod
                  .enum(["srt", "vtt"])
                  .describe("Subtitles formats you want your transcription to be formatted to")
                  .describe("Format of the current subtitle"),
                subtitles: zod.string().describe("Transcription on the asked subtitle format")
              })
            )
            .optional()
            .describe("If `subtitles` has been enabled, subtitles results"),
          utterances: zod
            .array(
              zod.object({
                start: zod.number().describe("Start timestamp in seconds of this utterance"),
                end: zod.number().describe("End timestamp in seconds of this utterance"),
                confidence: zod
                  .number()
                  .describe("Confidence on the transcribed utterance (1 = 100% confident)"),
                channel: zod
                  .number()
                  .min(
                    streamingControllerGetStreamingJobV2ResponseResultTranscriptionUtterancesItemChannelMin
                  )
                  .describe("Audio channel of where this utterance has been transcribed from"),
                speaker: zod
                  .number()
                  .min(
                    streamingControllerGetStreamingJobV2ResponseResultTranscriptionUtterancesItemSpeakerMin
                  )
                  .optional()
                  .describe("If `diarization` enabled, speaker identification number"),
                words: zod
                  .array(
                    zod.object({
                      word: zod.string().describe("Spoken word"),
                      start: zod
                        .number()
                        .describe("Start timestamps in seconds of the spoken word"),
                      end: zod.number().describe("End timestamps in seconds of the spoken word"),
                      confidence: zod
                        .number()
                        .describe("Confidence on the transcribed word (1 = 100% confident)")
                    })
                  )
                  .describe("List of words of the utterance, split by timestamp"),
                text: zod.string().describe("Transcription for this utterance"),
                language: zod
                  .enum([
                    "af",
                    "am",
                    "ar",
                    "as",
                    "az",
                    "ba",
                    "be",
                    "bg",
                    "bn",
                    "bo",
                    "br",
                    "bs",
                    "ca",
                    "cs",
                    "cy",
                    "da",
                    "de",
                    "el",
                    "en",
                    "es",
                    "et",
                    "eu",
                    "fa",
                    "fi",
                    "fo",
                    "fr",
                    "gl",
                    "gu",
                    "ha",
                    "haw",
                    "he",
                    "hi",
                    "hr",
                    "ht",
                    "hu",
                    "hy",
                    "id",
                    "is",
                    "it",
                    "ja",
                    "jw",
                    "ka",
                    "kk",
                    "km",
                    "kn",
                    "ko",
                    "la",
                    "lb",
                    "ln",
                    "lo",
                    "lt",
                    "lv",
                    "mg",
                    "mi",
                    "mk",
                    "ml",
                    "mn",
                    "mr",
                    "ms",
                    "mt",
                    "my",
                    "ne",
                    "nl",
                    "nn",
                    "no",
                    "oc",
                    "pa",
                    "pl",
                    "ps",
                    "pt",
                    "ro",
                    "ru",
                    "sa",
                    "sd",
                    "si",
                    "sk",
                    "sl",
                    "sn",
                    "so",
                    "sq",
                    "sr",
                    "su",
                    "sv",
                    "sw",
                    "ta",
                    "te",
                    "tg",
                    "th",
                    "tk",
                    "tl",
                    "tr",
                    "tt",
                    "uk",
                    "ur",
                    "uz",
                    "vi",
                    "yi",
                    "yo",
                    "zh"
                  ])
                  .describe(
                    "Specify the language in which it will be pronounced when sound comparison occurs. Default to transcription language."
                  )
                  .describe("Spoken language in this utterance")
              })
            )
            .describe("Transcribed speech utterances present in the audio")
        })
        .optional()
        .describe("Transcription of the audio speech"),
      translation: zod
        .object({
          success: zod
            .boolean()
            .describe("The audio intelligence model succeeded to get a valid output"),
          is_empty: zod.boolean().describe("The audio intelligence model returned an empty value"),
          exec_time: zod
            .number()
            .describe("Time audio intelligence model took to complete the task"),
          error: zod
            .object({
              status_code: zod.number().describe("Status code of the addon error"),
              exception: zod.string().describe("Reason of the addon error"),
              message: zod.string().describe("Detailed message of the addon error")
            })
            .nullable()
            .describe(
              "`null` if `success` is `true`. Contains the error details of the failed model"
            ),
          results: zod
            .array(
              zod.object({
                error: zod
                  .object({
                    status_code: zod.number().describe("Status code of the addon error"),
                    exception: zod.string().describe("Reason of the addon error"),
                    message: zod.string().describe("Detailed message of the addon error")
                  })
                  .nullable()
                  .describe("Contains the error details of the failed addon"),
                full_transcript: zod
                  .string()
                  .describe("All transcription on text format without any other information"),
                languages: zod
                  .array(
                    zod
                      .enum([
                        "af",
                        "am",
                        "ar",
                        "as",
                        "az",
                        "ba",
                        "be",
                        "bg",
                        "bn",
                        "bo",
                        "br",
                        "bs",
                        "ca",
                        "cs",
                        "cy",
                        "da",
                        "de",
                        "el",
                        "en",
                        "es",
                        "et",
                        "eu",
                        "fa",
                        "fi",
                        "fo",
                        "fr",
                        "gl",
                        "gu",
                        "ha",
                        "haw",
                        "he",
                        "hi",
                        "hr",
                        "ht",
                        "hu",
                        "hy",
                        "id",
                        "is",
                        "it",
                        "ja",
                        "jw",
                        "ka",
                        "kk",
                        "km",
                        "kn",
                        "ko",
                        "la",
                        "lb",
                        "ln",
                        "lo",
                        "lt",
                        "lv",
                        "mg",
                        "mi",
                        "mk",
                        "ml",
                        "mn",
                        "mr",
                        "ms",
                        "mt",
                        "my",
                        "ne",
                        "nl",
                        "nn",
                        "no",
                        "oc",
                        "pa",
                        "pl",
                        "ps",
                        "pt",
                        "ro",
                        "ru",
                        "sa",
                        "sd",
                        "si",
                        "sk",
                        "sl",
                        "sn",
                        "so",
                        "sq",
                        "sr",
                        "su",
                        "sv",
                        "sw",
                        "ta",
                        "te",
                        "tg",
                        "th",
                        "tk",
                        "tl",
                        "tr",
                        "tt",
                        "uk",
                        "ur",
                        "uz",
                        "vi",
                        "wo",
                        "yi",
                        "yo",
                        "zh"
                      ])
                      .describe(
                        "Target language in `iso639-1` format you want the transcription translated to"
                      )
                  )
                  .describe(
                    "All the detected languages in the audio sorted from the most detected to the less detected"
                  ),
                sentences: zod
                  .array(
                    zod.object({
                      success: zod
                        .boolean()
                        .describe("The audio intelligence model succeeded to get a valid output"),
                      is_empty: zod
                        .boolean()
                        .describe("The audio intelligence model returned an empty value"),
                      exec_time: zod
                        .number()
                        .describe("Time audio intelligence model took to complete the task"),
                      error: zod
                        .object({
                          status_code: zod.number().describe("Status code of the addon error"),
                          exception: zod.string().describe("Reason of the addon error"),
                          message: zod.string().describe("Detailed message of the addon error")
                        })
                        .nullable()
                        .describe(
                          "`null` if `success` is `true`. Contains the error details of the failed model"
                        ),
                      results: zod
                        .array(zod.string())
                        .nullable()
                        .describe("If `sentences` has been enabled, transcription as sentences.")
                    })
                  )
                  .optional()
                  .describe(
                    "If `sentences` has been enabled, sentences results for this translation"
                  ),
                subtitles: zod
                  .array(
                    zod.object({
                      format: zod
                        .enum(["srt", "vtt"])
                        .describe(
                          "Subtitles formats you want your transcription to be formatted to"
                        )
                        .describe("Format of the current subtitle"),
                      subtitles: zod.string().describe("Transcription on the asked subtitle format")
                    })
                  )
                  .optional()
                  .describe(
                    "If `subtitles` has been enabled, subtitles results for this translation"
                  ),
                utterances: zod
                  .array(
                    zod.object({
                      start: zod.number().describe("Start timestamp in seconds of this utterance"),
                      end: zod.number().describe("End timestamp in seconds of this utterance"),
                      confidence: zod
                        .number()
                        .describe("Confidence on the transcribed utterance (1 = 100% confident)"),
                      channel: zod
                        .number()
                        .min(
                          streamingControllerGetStreamingJobV2ResponseResultTranslationResultsItemUtterancesItemChannelMin
                        )
                        .describe(
                          "Audio channel of where this utterance has been transcribed from"
                        ),
                      speaker: zod
                        .number()
                        .min(
                          streamingControllerGetStreamingJobV2ResponseResultTranslationResultsItemUtterancesItemSpeakerMin
                        )
                        .optional()
                        .describe("If `diarization` enabled, speaker identification number"),
                      words: zod
                        .array(
                          zod.object({
                            word: zod.string().describe("Spoken word"),
                            start: zod
                              .number()
                              .describe("Start timestamps in seconds of the spoken word"),
                            end: zod
                              .number()
                              .describe("End timestamps in seconds of the spoken word"),
                            confidence: zod
                              .number()
                              .describe("Confidence on the transcribed word (1 = 100% confident)")
                          })
                        )
                        .describe("List of words of the utterance, split by timestamp"),
                      text: zod.string().describe("Transcription for this utterance"),
                      language: zod
                        .enum([
                          "af",
                          "am",
                          "ar",
                          "as",
                          "az",
                          "ba",
                          "be",
                          "bg",
                          "bn",
                          "bo",
                          "br",
                          "bs",
                          "ca",
                          "cs",
                          "cy",
                          "da",
                          "de",
                          "el",
                          "en",
                          "es",
                          "et",
                          "eu",
                          "fa",
                          "fi",
                          "fo",
                          "fr",
                          "gl",
                          "gu",
                          "ha",
                          "haw",
                          "he",
                          "hi",
                          "hr",
                          "ht",
                          "hu",
                          "hy",
                          "id",
                          "is",
                          "it",
                          "ja",
                          "jw",
                          "ka",
                          "kk",
                          "km",
                          "kn",
                          "ko",
                          "la",
                          "lb",
                          "ln",
                          "lo",
                          "lt",
                          "lv",
                          "mg",
                          "mi",
                          "mk",
                          "ml",
                          "mn",
                          "mr",
                          "ms",
                          "mt",
                          "my",
                          "ne",
                          "nl",
                          "nn",
                          "no",
                          "oc",
                          "pa",
                          "pl",
                          "ps",
                          "pt",
                          "ro",
                          "ru",
                          "sa",
                          "sd",
                          "si",
                          "sk",
                          "sl",
                          "sn",
                          "so",
                          "sq",
                          "sr",
                          "su",
                          "sv",
                          "sw",
                          "ta",
                          "te",
                          "tg",
                          "th",
                          "tk",
                          "tl",
                          "tr",
                          "tt",
                          "uk",
                          "ur",
                          "uz",
                          "vi",
                          "yi",
                          "yo",
                          "zh"
                        ])
                        .describe(
                          "Specify the language in which it will be pronounced when sound comparison occurs. Default to transcription language."
                        )
                        .describe("Spoken language in this utterance")
                    })
                  )
                  .describe("Transcribed speech utterances present in the audio")
              })
            )
            .nullable()
            .describe("List of translated transcriptions, one for each `target_languages`")
        })
        .optional()
        .describe(
          "If `translation` has been enabled, translation of the audio speech transcription"
        ),
      summarization: zod
        .object({
          success: zod
            .boolean()
            .describe("The audio intelligence model succeeded to get a valid output"),
          is_empty: zod.boolean().describe("The audio intelligence model returned an empty value"),
          exec_time: zod
            .number()
            .describe("Time audio intelligence model took to complete the task"),
          error: zod
            .object({
              status_code: zod.number().describe("Status code of the addon error"),
              exception: zod.string().describe("Reason of the addon error"),
              message: zod.string().describe("Detailed message of the addon error")
            })
            .nullable()
            .describe(
              "`null` if `success` is `true`. Contains the error details of the failed model"
            ),
          results: zod
            .string()
            .nullable()
            .describe("If `summarization` has been enabled, summary of the transcription")
        })
        .optional()
        .describe(
          "If `summarization` has been enabled, summarization of the audio speech transcription"
        ),
      named_entity_recognition: zod
        .object({
          success: zod
            .boolean()
            .describe("The audio intelligence model succeeded to get a valid output"),
          is_empty: zod.boolean().describe("The audio intelligence model returned an empty value"),
          exec_time: zod
            .number()
            .describe("Time audio intelligence model took to complete the task"),
          error: zod
            .object({
              status_code: zod.number().describe("Status code of the addon error"),
              exception: zod.string().describe("Reason of the addon error"),
              message: zod.string().describe("Detailed message of the addon error")
            })
            .nullable()
            .describe(
              "`null` if `success` is `true`. Contains the error details of the failed model"
            ),
          entity: zod
            .string()
            .describe("If `named_entity_recognition` has been enabled, the detected entities.")
        })
        .optional()
        .describe("If `named_entity_recognition` has been enabled, the detected entities"),
      sentiment_analysis: zod
        .object({
          success: zod
            .boolean()
            .describe("The audio intelligence model succeeded to get a valid output"),
          is_empty: zod.boolean().describe("The audio intelligence model returned an empty value"),
          exec_time: zod
            .number()
            .describe("Time audio intelligence model took to complete the task"),
          error: zod
            .object({
              status_code: zod.number().describe("Status code of the addon error"),
              exception: zod.string().describe("Reason of the addon error"),
              message: zod.string().describe("Detailed message of the addon error")
            })
            .nullable()
            .describe(
              "`null` if `success` is `true`. Contains the error details of the failed model"
            ),
          results: zod
            .string()
            .describe(
              "If `sentiment_analysis` has been enabled, Gladia will analyze the sentiments and emotions of the audio"
            )
        })
        .optional()
        .describe(
          "If `sentiment_analysis` has been enabled, sentiment analysis of the audio speech transcription"
        ),
      chapterization: zod
        .object({
          success: zod
            .boolean()
            .describe("The audio intelligence model succeeded to get a valid output"),
          is_empty: zod.boolean().describe("The audio intelligence model returned an empty value"),
          exec_time: zod
            .number()
            .describe("Time audio intelligence model took to complete the task"),
          error: zod
            .object({
              status_code: zod.number().describe("Status code of the addon error"),
              exception: zod.string().describe("Reason of the addon error"),
              message: zod.string().describe("Detailed message of the addon error")
            })
            .nullable()
            .describe(
              "`null` if `success` is `true`. Contains the error details of the failed model"
            ),
          results: zod
            .record(zod.string(), zod.any())
            .describe(
              "If `chapterization` has been enabled, will generate chapters name for different parts of the given audio."
            )
        })
        .optional()
        .describe(
          "If `chapterization` has been enabled, will generate chapters name for different parts of the given audio."
        ),
      messages: zod
        .array(zod.string())
        .optional()
        .describe("Real-Time messages sent by the server during the live transcription")
    })
    .nullish()
    .describe('Live transcription\'s result when status is \"done\"')
})

/**
 * @summary Delete the live job
 */
export const streamingControllerDeleteStreamingJobV2Params = zod.object({
  id: zod.string().describe("Id of the live job")
})

/**
 * @summary For debugging purposes, send post session metadata in the request params of the job
 */
export const streamingControllerPatchRequestParamsV2Params = zod.object({
  id: zod.string().describe("Id of the live job")
})

export const streamingControllerPatchRequestParamsV2Body = zod.object({})

/**
 * @summary Download the audio file used for this live job
 */
export const streamingControllerGetAudioV2Params = zod.object({
  id: zod.string().describe("Id of the live job")
})
