/**
 * Generated by orval v7.9.0 üç∫
 * Do not edit manually.
 * OpenAI API
 * The OpenAI REST API. Please see https://platform.openai.com/docs/api-reference for more details.
 * OpenAPI spec version: 2.3.0
 */
import type { ResponseAllOfObject } from "./responseAllOfObject"
import type { ResponseAllOfStatus } from "./responseAllOfStatus"
import type { ResponseError } from "./responseError"
import type { ResponseAllOfIncompleteDetails } from "./responseAllOfIncompleteDetails"
import type { OutputItem } from "./outputItem"
import type { ResponseAllOfInstructions } from "./responseAllOfInstructions"
import type { ResponseAllOfOutputText } from "./responseAllOfOutputText"
import type { ResponseUsage } from "./responseUsage"
import type { ResponseAllOfConversation } from "./responseAllOfConversation"

export type ResponseAllOf = {
  /** Unique identifier for this Response.
   */
  id: string
  /** The object type of this resource - always set to `response`.
   */
  object: ResponseAllOfObject
  /** The status of the response generation. One of `completed`, `failed`,
`in_progress`, `cancelled`, `queued`, or `incomplete`.
 */
  status?: ResponseAllOfStatus
  /** Unix timestamp (in seconds) of when this Response was created.
   */
  created_at: number
  error: ResponseError
  incomplete_details: ResponseAllOfIncompleteDetails
  /** An array of content items generated by the model.

- The length and order of items in the `output` array is dependent
  on the model's response.
- Rather than accessing the first item in the `output` array and
  assuming it's an `assistant` message with the content generated by
  the model, you might consider using the `output_text` property where
  supported in SDKs.
 */
  output: OutputItem[]
  instructions: ResponseAllOfInstructions
  output_text?: ResponseAllOfOutputText
  usage?: ResponseUsage
  /** Whether to allow the model to run tool calls in parallel.
   */
  parallel_tool_calls: boolean
  conversation?: ResponseAllOfConversation
}
