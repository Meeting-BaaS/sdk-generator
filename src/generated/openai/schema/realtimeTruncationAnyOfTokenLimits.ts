/**
 * Generated by orval v7.9.0 üç∫
 * Do not edit manually.
 * OpenAI API
 * The OpenAI REST API. Please see https://platform.openai.com/docs/api-reference for more details.
 * OpenAPI spec version: 2.3.0
 */

/**
 * Optional custom token limits for this truncation strategy. If not provided, the model's default token limits will be used.
 */
export type RealtimeTruncationAnyOfTokenLimits = {
  /**
   * Maximum tokens allowed in the conversation after instructions (which including tool definitions). For example, setting this to 5,000 would mean that truncation would occur when the conversation exceeds 5,000 tokens after instructions. This cannot be higher than the model's context window size minus the maximum output tokens.
   * @minimum 0
   */
  post_instructions?: number
}
