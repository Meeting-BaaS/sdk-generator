/**
 * Generated by orval v7.9.0 üç∫
 * Do not edit manually.
 * OpenAI API
 * The OpenAI REST API. Please see https://platform.openai.com/docs/api-reference for more details.
 * OpenAPI spec version: 2.3.0
 */
import type { RealtimeResponseCreateParamsOutputModalitiesItem } from './realtimeResponseCreateParamsOutputModalitiesItem';
import type { RealtimeResponseCreateParamsAudio } from './realtimeResponseCreateParamsAudio';
import type { RealtimeResponseCreateParamsToolsItem } from './realtimeResponseCreateParamsToolsItem';
import type { RealtimeResponseCreateParamsToolChoice } from './realtimeResponseCreateParamsToolChoice';
import type { RealtimeResponseCreateParamsMaxOutputTokens } from './realtimeResponseCreateParamsMaxOutputTokens';
import type { RealtimeResponseCreateParamsConversation } from './realtimeResponseCreateParamsConversation';
import type { Metadata } from './metadata';
import type { Prompt } from './prompt';
import type { RealtimeConversationItem } from './realtimeConversationItem';

/**
 * Create a new Realtime response with these parameters
 */
export interface RealtimeResponseCreateParams {
  /** The set of modalities the model used to respond, currently the only possible values are
`[\"audio\"]`, `[\"text\"]`. Audio output always include a text transcript. Setting the
output to mode `text` will disable audio output from the model.
 */
  output_modalities?: RealtimeResponseCreateParamsOutputModalitiesItem[];
  /** The default system instructions (i.e. system message) prepended to model calls. This field allows the client to guide the model on desired responses. The model can be instructed on response content and format, (e.g. "be extremely succinct", "act friendly", "here are examples of good responses") and on audio behavior (e.g. "talk quickly", "inject emotion into your voice", "laugh frequently"). The instructions are not guaranteed to be followed by the model, but they provide guidance to the model on the desired behavior.
Note that the server sets default instructions which will be used if this field is not set and are visible in the `session.created` event at the start of the session.
 */
  instructions?: string;
  /** Configuration for audio input and output. */
  audio?: RealtimeResponseCreateParamsAudio;
  /** Tools available to the model. */
  tools?: RealtimeResponseCreateParamsToolsItem[];
  /** How the model chooses tools. Provide one of the string modes or force a specific
function/MCP tool.
 */
  tool_choice?: RealtimeResponseCreateParamsToolChoice;
  /** Maximum number of output tokens for a single assistant response,
inclusive of tool calls. Provide an integer between 1 and 4096 to
limit output tokens, or `inf` for the maximum available tokens for a
given model. Defaults to `inf`.
 */
  max_output_tokens?: RealtimeResponseCreateParamsMaxOutputTokens;
  /** Controls which conversation the response is added to. Currently supports
`auto` and `none`, with `auto` as the default value. The `auto` value
means that the contents of the response will be added to the default
conversation. Set this to `none` to create an out-of-band response which
will not add items to default conversation.
 */
  conversation?: RealtimeResponseCreateParamsConversation;
  metadata?: Metadata;
  prompt?: Prompt;
  /** Input items to include in the prompt for the model. Using this field
creates a new context for this Response instead of using the default
conversation. An empty array `[]` will clear the context for this Response.
Note that this can include references to items that previously appeared in the session
using their id.
 */
  input?: RealtimeConversationItem[];
}
