/**
 * Generated by orval v7.9.0 üç∫
 * Do not edit manually.
 * OpenAI API
 * The OpenAI REST API. Please see https://platform.openai.com/docs/api-reference for more details.
 * OpenAPI spec version: 2.3.0
 */
import type { RealtimeSessionCreateRequestGAType } from './realtimeSessionCreateRequestGAType';
import type { RealtimeSessionCreateRequestGAOutputModalitiesItem } from './realtimeSessionCreateRequestGAOutputModalitiesItem';
import type { RealtimeSessionCreateRequestGAModel } from './realtimeSessionCreateRequestGAModel';
import type { RealtimeSessionCreateRequestGAAudio } from './realtimeSessionCreateRequestGAAudio';
import type { RealtimeSessionCreateRequestGAIncludeItem } from './realtimeSessionCreateRequestGAIncludeItem';
import type { RealtimeSessionCreateRequestGATracing } from './realtimeSessionCreateRequestGATracing';
import type { RealtimeSessionCreateRequestGAToolsItem } from './realtimeSessionCreateRequestGAToolsItem';
import type { RealtimeSessionCreateRequestGAToolChoice } from './realtimeSessionCreateRequestGAToolChoice';
import type { RealtimeSessionCreateRequestGAMaxOutputTokens } from './realtimeSessionCreateRequestGAMaxOutputTokens';
import type { RealtimeTruncation } from './realtimeTruncation';
import type { Prompt } from './prompt';

/**
 * Realtime session object configuration.
 */
export interface RealtimeSessionCreateRequestGA {
  /** The type of session to create. Always `realtime` for the Realtime API.
 */
  type: RealtimeSessionCreateRequestGAType;
  /** The set of modalities the model can respond with. It defaults to `["audio"]`, indicating
that the model will respond with audio plus a transcript. `["text"]` can be used to make
the model respond with text only. It is not possible to request both `text` and `audio` at the same time.
 */
  output_modalities?: RealtimeSessionCreateRequestGAOutputModalitiesItem[];
  /** The Realtime model used for this session.
 */
  model?: RealtimeSessionCreateRequestGAModel;
  /** The default system instructions (i.e. system message) prepended to model calls. This field allows the client to guide the model on desired responses. The model can be instructed on response content and format, (e.g. "be extremely succinct", "act friendly", "here are examples of good responses") and on audio behavior (e.g. "talk quickly", "inject emotion into your voice", "laugh frequently"). The instructions are not guaranteed to be followed by the model, but they provide guidance to the model on the desired behavior.

Note that the server sets default instructions which will be used if this field is not set and are visible in the `session.created` event at the start of the session.
 */
  instructions?: string;
  /** Configuration for input and output audio.
 */
  audio?: RealtimeSessionCreateRequestGAAudio;
  /** Additional fields to include in server outputs.

`item.input_audio_transcription.logprobs`: Include logprobs for input audio transcription.
 */
  include?: RealtimeSessionCreateRequestGAIncludeItem[];
  /**
   * Realtime API can write session traces to the [Traces Dashboard](/logs?api=traces). Set to null to disable tracing. Once
tracing is enabled for a session, the configuration cannot be modified.

`auto` will create a trace for the session with default values for the
workflow name, group id, and metadata.

   * @nullable
   */
  tracing?: RealtimeSessionCreateRequestGATracing;
  /** Tools available to the model. */
  tools?: RealtimeSessionCreateRequestGAToolsItem[];
  /** How the model chooses tools. Provide one of the string modes or force a specific
function/MCP tool.
 */
  tool_choice?: RealtimeSessionCreateRequestGAToolChoice;
  /** Maximum number of output tokens for a single assistant response,
inclusive of tool calls. Provide an integer between 1 and 4096 to
limit output tokens, or `inf` for the maximum available tokens for a
given model. Defaults to `inf`.
 */
  max_output_tokens?: RealtimeSessionCreateRequestGAMaxOutputTokens;
  truncation?: RealtimeTruncation;
  prompt?: Prompt;
}
