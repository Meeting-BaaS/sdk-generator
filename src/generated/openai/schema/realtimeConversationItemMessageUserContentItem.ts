/**
 * Generated by orval v7.17.0 üç∫
 * Do not edit manually.
 * OpenAI API
 * The OpenAI REST API. Please see https://platform.openai.com/docs/api-reference for more details.
 * OpenAPI spec version: 2.3.0
 */
import type { RealtimeConversationItemMessageUserContentItemType } from "./realtimeConversationItemMessageUserContentItemType"
import type { RealtimeConversationItemMessageUserContentItemDetail } from "./realtimeConversationItemMessageUserContentItemDetail"

export type RealtimeConversationItemMessageUserContentItem = {
  /** The content type (`input_text`, `input_audio`, or `input_image`). */
  type?: RealtimeConversationItemMessageUserContentItemType
  /** The text content (for `input_text`). */
  text?: string
  /** Base64-encoded audio bytes (for `input_audio`), these will be parsed as the format specified in the session input audio type configuration. This defaults to PCM 16-bit 24kHz mono if not specified. */
  audio?: string
  /** Base64-encoded image bytes (for `input_image`) as a data URI. For example `data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAA...`. Supported formats are PNG and JPEG. */
  image_url?: string
  /** The detail level of the image (for `input_image`). `auto` will default to `high`. */
  detail?: RealtimeConversationItemMessageUserContentItemDetail
  /** Transcript of the audio (for `input_audio`). This is not sent to the model, but will be attached to the message item for reference. */
  transcript?: string
}
