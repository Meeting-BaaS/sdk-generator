/**
 * Generated by orval v7.9.0 üç∫
 * Do not edit manually.
 * Deepgram API Specification
 * APIs for speech-to-text transcription, text-to-speech synthesis, language understanding, and account management.

 * OpenAPI spec version: 1.0.0
 */
import type { SharedCallbackParameter } from './sharedCallbackParameter';
import type { SharedCallbackMethodParameter } from './sharedCallbackMethodParameter';
import type { SharedSentimentParameter } from './sharedSentimentParameter';
import type { SharedSummarizeParameter } from './sharedSummarizeParameter';
import type { SharedTagParameter } from './sharedTagParameter';
import type { SharedTopicsParameter } from './sharedTopicsParameter';
import type { SharedCustomTopicParameter } from './sharedCustomTopicParameter';
import type { SharedCustomTopicModeParameter } from './sharedCustomTopicModeParameter';
import type { SharedIntentsParameter } from './sharedIntentsParameter';
import type { SharedCustomIntentParameter } from './sharedCustomIntentParameter';
import type { SharedCustomIntentModeParameter } from './sharedCustomIntentModeParameter';
import type { ReadV1LanguageParameter } from './readV1LanguageParameter';

export type ReadV1TextAnalyzeParams = {
/**
 * URL to which we'll make the callback request
 */
callback?: SharedCallbackParameter;
/**
 * HTTP method by which the callback request will be made
 */
callback_method?: SharedCallbackMethodParameter;
/**
 * Recognizes the sentiment throughout a transcript or text
 */
sentiment?: SharedSentimentParameter;
/**
 * Summarize content. For Listen API, supports string version option. For Read API, accepts boolean only.
 */
summarize?: SharedSummarizeParameter;
/**
 * Label your requests for the purpose of identification during usage reporting
 */
tag?: SharedTagParameter;
/**
 * Detect topics throughout a transcript or text
 */
topics?: SharedTopicsParameter;
/**
 * Custom topics you want the model to detect within your input audio or text if present Submit up to `100`.
 */
custom_topic?: SharedCustomTopicParameter;
/**
 * Sets how the model will interpret strings submitted to the `custom_topic` param. When `strict`, the model will only return topics submitted using the `custom_topic` param. When `extended`, the model will return its own detected topics in addition to those submitted using the `custom_topic` param
 */
custom_topic_mode?: SharedCustomTopicModeParameter;
/**
 * Recognizes speaker intent throughout a transcript or text
 */
intents?: SharedIntentsParameter;
/**
 * Custom intents you want the model to detect within your input audio if present
 */
custom_intent?: SharedCustomIntentParameter;
/**
 * Sets how the model will interpret intents submitted to the `custom_intent` param. When `strict`, the model will only return intents submitted using the `custom_intent` param. When `extended`, the model will return its own detected intents in the `custom_intent` param.
 */
custom_intent_mode?: SharedCustomIntentModeParameter;
/**
 * The [BCP-47 language tag](https://tools.ietf.org/html/bcp47) that hints at the primary spoken language. Depending on the Model and API endpoint you choose only certain languages are available
 */
language?: ReadV1LanguageParameter;
};
