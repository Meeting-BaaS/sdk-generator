# Voice Router SDK - Implementation Plan

## ğŸ¯ Goal
Create a **multi-provider transcription SDK** that unifies multiple Speech-to-Text APIs (Gladia, DeepGram, AssemblyAI, etc.) behind a single, provider-agnostic interface.

## ğŸ“‹ Current Status

### âœ… Completed
- Created `voice-router` branch
- Analyzed existing architecture (reusable patterns identified)
- Updated `orval.config.ts` with initial provider configs
- Removed old Meeting BaaS v1/v2 code
- Generated types for Gladia and AssemblyAI
- Created base provider interface (`BaseAdapter`)
- **Implemented Gladia adapter** - Full transcription support with diarization, summarization, etc.
- **Implemented AssemblyAI adapter** - Full transcription support with advanced features
- Created VoiceRouter bridge class with provider selection strategies
- Generated comprehensive documentation for all providers
- Build system working with unified commands

### ğŸš§ In Progress
- Testing adapters with real API calls
- Adding usage examples

### âš ï¸ Blockers Found
1. **Orval + Node 18 compatibility**: `toSorted()` not available in Node 18
   - Solution: Use `mode: "single"` instead of `mode: "tags-split"`

2. **Deepgram OpenAPI spec**: No public OpenAPI spec found at standard URL
   - Need to find correct URL or use manual typing

3. **Provider OpenAPI quality**: Each provider has different schema quality/formats
   - May need custom transformers (like existing `scripts/preprocess.js`)

## ğŸ—ï¸ Architecture Design

### Provider Layer
Each transcription provider gets:
- Generated types from OpenAPI (`src/generated/{provider}/`)
- Provider adapter class (`src/adapters/{provider}-adapter.ts`)
- Normalized interface implementation

### Bridge Layer
- `VoiceRouter` class - main entry point
- Unified interface for common operations:
  - `transcribe(audio, options)` - Synchronous transcription
  - `transcribeStream(audioStream, options)` - Real-time transcription
  - `getTranscript(id)` - Retrieve completed transcription
  - `getSpeakers(id)` - Get speaker diarization
  - `getWordTimestamps(id)` - Get word-level timestamps

### Response Normalization
```typescript
interface UnifiedTranscriptResponse {
  success: boolean
  provider: 'gladia' | 'deepgram' | 'assemblyai' | ...
  data?: {
    id: string
    text: string
    confidence: number
    speakers?: Speaker[]
    words?: Word[]
    language?: string
    duration?: number
  }
  error?: {
    code: string
    message: string
    details?: unknown
  }
}
```

## ğŸ“¦ Target Providers

**âš ï¸ See [PROVIDER_INTEGRATION_PLAN.md](./PROVIDER_INTEGRATION_PLAN.md) for comprehensive provider integration roadmap**

### âœ… Completed (2/11 providers)
- [x] **Gladia** - https://api.gladia.io/openapi.json - âœ… Adapter implemented
- [x] **AssemblyAI** - https://github.com/AssemblyAI/assemblyai-api-spec - âœ… Adapter implemented

### ğŸš§ Phase 2: High Priority (3 providers)
- [ ] **Deepgram** - https://github.com/deepgram/deepgram-api-specs - ğŸ”´ TODO - **NEXT**
- [ ] **OpenAI Whisper** - https://app.stainless.com/api/spec/documented/openai/openapi.documented.yml - ğŸ”´ TODO
- [ ] **Azure Speech-to-Text** - https://github.com/Azure/azure-rest-api-specs - ğŸ”´ TODO

### ğŸ“‹ Phase 3: Medium Priority (2 providers)
- [ ] **Speechmatics** - https://docs.speechmatics.com/jobsapi - ğŸ”´ TODO
- [ ] **Google Cloud STT** - https://speech.googleapis.com/$discovery/rest?version=v2 - âš ï¸ Discovery Doc (needs conversion)

### ğŸ”» Phase 4: Low Priority (2 providers)
- [ ] **Rev.ai** - No public OpenAPI spec - Manual typing required
- [ ] **Amazon Transcribe** - AWS proprietary - Manual typing required

### â¸ï¸ Skipped (2 providers)
- IBM Watson STT (deprecated)
- Kaldi (self-hosted toolkit)

## ğŸ”§ Implementation Steps

### Phase 1: Foundation âœ… COMPLETED
1. âœ… Set up orval config for providers
2. âœ… Fix orval generation issues (workaround with mode: "single")
3. âœ… Generate types for Gladia
4. âœ… Create base provider interface
5. âœ… Build first adapter (Gladia)

### Phase 2: Multi-Provider âœ… COMPLETED
1. âœ… Add AssemblyAI adapter - **DONE Dec 8, 2025**
2. â³ Add Deepgram adapter (manual types needed - no OpenAPI spec)
3. âœ… Create VoiceRouter bridge class
4. âœ… Implement provider selection logic (explicit, default, round-robin)

### Phase 3: Polish (Current)
1. â³ Add comprehensive tests
2. âœ… Generate documentation
3. â³ Update README with new architecture
4. â³ Add usage examples

## ğŸš§ Known Issues & Solutions

### Issue 1: Orval toSorted() Error
**Problem**: Orval uses `toSorted()` which doesn't exist in Node 18

**Solutions**:
- Option A: Upgrade to Node 20+ (check `package.json` engines)
- Option B: Use `mode: "single"` instead of `mode: "tags-split"`
- Option C: Use custom transformer to polyfill

**Recommendation**: Use Option B for now

### Issue 2: Deepgram OpenAPI Spec
**Problem**: No public OpenAPI spec found

**Solutions**:
- Option A: Find correct URL (check Deepgram docs)
- Option B: Generate from their API docs manually
- Option C: Use community-maintained spec (if exists)
- Option D: Write manual TypeScript types

**Recommendation**: Start with Gladia + AssemblyAI (working specs), add Deepgram later

### Issue 3: Different Provider Capabilities
**Problem**: Each provider has different features (some have speaker diarization, some don't)

**Solution**: Use capability flags in provider interface:
```typescript
interface ProviderCapabilities {
  streaming: boolean
  diarization: boolean
  wordTimestamps: boolean
  languageDetection: boolean
  customVocabulary: boolean
}
```

## ğŸ“‚ File Structure

```
voice-router-sdk/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ generated/              # Auto-generated from OpenAPI
â”‚   â”‚   â”œâ”€â”€ gladia/
â”‚   â”‚   â”œâ”€â”€ assemblyai/
â”‚   â”‚   â””â”€â”€ deepgram/
â”‚   â”œâ”€â”€ adapters/               # Provider adapters
â”‚   â”‚   â”œâ”€â”€ base-adapter.ts
â”‚   â”‚   â”œâ”€â”€ gladia-adapter.ts
â”‚   â”‚   â”œâ”€â”€ assemblyai-adapter.ts
â”‚   â”‚   â””â”€â”€ deepgram-adapter.ts
â”‚   â”œâ”€â”€ router/                 # Bridge layer
â”‚   â”‚   â”œâ”€â”€ voice-router.ts
â”‚   â”‚   â”œâ”€â”€ types.ts
â”‚   â”‚   â””â”€â”€ normalizer.ts
â”‚   â””â”€â”€ index.ts                # Main export
â”œâ”€â”€ scripts/
â”‚   â””â”€â”€ preprocess.js           # OpenAPI fixer (reused)
â”œâ”€â”€ docs/
â”‚   â””â”€â”€ generated/
â”‚       â”œâ”€â”€ gladia/
â”‚       â”œâ”€â”€ assemblyai/
â”‚       â””â”€â”€ router/
â”œâ”€â”€ orval.config.ts             # Provider configs
â”œâ”€â”€ package.json                # Scripts per provider
â””â”€â”€ README.md                   # Usage guide
```

## ğŸ¯ Success Criteria

1. âœ… **Working Gladia Integration**: Can transcribe audio using Gladia API - **DONE**
2. âœ… **Working AssemblyAI Integration**: Can transcribe audio using AssemblyAI API - **DONE**
3. âœ… **Unified Interface**: Single `VoiceRouter` class that works with both - **DONE**
4. âœ… **Type Safety**: Full TypeScript support with generated types - **DONE**
5. âœ… **Documentation**: Generated docs showing usage for each provider - **DONE**
6. â³ **Tests**: Integration tests for each provider - **TODO**

## ğŸš€ Next Steps

### âœ… Completed (Dec 8, 2025)
1. âœ… Fix orval config to use `mode: "single"`
2. âœ… Generate Gladia types successfully
3. âœ… Create base provider interface
4. âœ… Build first Gladia adapter
5. âœ… Add AssemblyAI adapter
6. âœ… Build VoiceRouter bridge
7. âœ… Generate comprehensive documentation

### Immediate (Now)
1. Add integration tests for both adapters
2. Update main README with new Voice Router architecture
3. Add usage examples and guides
4. Test with real API keys

### Short-term (This Week)
1. Add Deepgram adapter (manual types or find spec)
2. Add error handling tests
3. Performance testing and optimization
4. Create migration guide from Meeting BaaS v1/v2

### Medium-term (Next Week)
1. Add more providers (Rev.ai, Speechmatics)
2. Add streaming transcription support
3. Publish v6.0.0 as Voice Router SDK
4. Update package metadata and branding

## â“ Open Questions

1. **Package Name**: Keep `@meeting-baas/sdk` or rename to `@voice-router/sdk`?
2. **API Key Management**: Single config object or per-provider?
   ```typescript
   // Option A: Single config
   new VoiceRouter({
     gladia: { api_key: '...' },
     assemblyai: { api_key: '...' }
   })

   // Option B: Per-provider
   new VoiceRouter('gladia', { api_key: '...' })
   ```
3. **Provider Selection**: Auto-detect, explicit, or round-robin?
4. **Streaming Support**: All providers or optional feature?

